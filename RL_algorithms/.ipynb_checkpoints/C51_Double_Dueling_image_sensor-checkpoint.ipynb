{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRL Based Self Driving Car Control (Image + Sensor)\n",
    "\n",
    "## Double DQN with C51 and Dueling Architecture\n",
    "\n",
    "This notebook is DRL code for the project 'DRL based Self Driving Car Control' <br>\n",
    "This version uses both **Image data from camera** and **Sensor data from LIDAR** as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Q\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment path\n",
    "\n",
    "Be sure to set `env_name` to the name of the Unity environment file you want to launch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"../environment/jeju_camp\" # Name of the Unity environment to launch\n",
    "train_mode = True # Whether to run the environment in training or inference mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the environment\n",
    "`UnityEnvironment` launches and begins communication with the environment when instantiated.\n",
    "\n",
    "Environments contain _brains_ which are responsible for deciding the actions of their associated _agents_. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: Brain\n",
      "        Number of Visual Observations (per agent): 1\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 373\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 5\n",
      "        Vector Action descriptions: , , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: Brain\n",
      "        Number of Visual Observations (per agent): 1\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 373\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 5\n",
      "        Vector Action descriptions: , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_name)\n",
    "\n",
    "# Examine environment parameters\n",
    "print(str(env))\n",
    "\n",
    "# Set the default brain to work with\n",
    "default_brain = env.brain_names[0]\n",
    "brain = env.brains[default_brain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the observation and state spaces\n",
    "We can reset the environment to be provided with an initial set of observations and states for all the agents within the environment. In ML-Agents, _states_ refer to a vector of variables corresponding to relevant aspects of the environment for an agent. Likewise, _observations_ refer to a set of relevant pixel-wise visuals for an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor data (LIDAR): \n",
      "[  1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   0.9755246    0.91600198   0.86357307   0.81705666   0.77551937\n",
      "   0.73821479   0.70453942   0.67399871   0.64618438   0.62075633\n",
      "   0.59742886   0.57596022   0.5561446    0.53780544   0.52079082\n",
      "   0.50496876   0.49022466   0.47645816   0.46358114   0.45151567\n",
      "   0.44019303   0.42955208   0.41953811   0.41010255   0.40120158\n",
      "   0.39279586   0.38485005   0.37733197   0.37021253   0.36346549\n",
      "   0.35706681   0.35099453   0.34522879   0.33975118   0.33454502\n",
      "   0.32959491   0.32488668   0.32040724   0.31614468   0.31208783\n",
      "   0.30822647   0.30455115   0.30105308   0.29772413   0.29455668\n",
      "   0.29154381   0.288679     0.28595623   0.28336981   0.2809146\n",
      "   0.27858567   0.27637851   0.27428898   0.27231315   0.27044734\n",
      "   0.26868826   0.26703268   0.26547778   0.26402083   0.26265934\n",
      "   0.26139107   0.26021382   0.25912577   0.25812501   0.25721005\n",
      "   0.25637937   0.25563163   0.25496569   0.25438049   0.25387514\n",
      "   0.25344881   0.25310093   0.25283089   0.25263828   0.25252286\n",
      "   0.25248438   0.25252286   0.25263828   0.25283089   0.25310093\n",
      "   0.25344881   0.25387514   0.25438049   0.25496572   0.25563163\n",
      "   0.25637937   0.25721005   0.25812504   0.25912577   0.26021382\n",
      "   0.2613911    0.26265937   0.26402086   0.26547781   0.26703271\n",
      "   0.26868829   0.27044743   0.27231318   0.27428904   0.27637854\n",
      "   0.27858567   0.28091457   0.28336984   0.2859562    0.28867906\n",
      "   0.29154381   0.29455668   0.29772413   0.30105308   0.30455118\n",
      "   0.3082265    0.3120878    0.31614468   0.32040721   0.32488671\n",
      "   0.32959491   0.33454508   0.33975121   0.34522879   0.35099462\n",
      "   0.35706681   0.36346555   0.37021261   0.37733203   0.38485011\n",
      "   0.39279595   0.40120178   0.41010267   0.4195382    0.42955217\n",
      "   0.44019303   0.45151576   0.46358114   0.47645825   0.49022475\n",
      "   0.50496876   0.52079082   0.53780544   0.8056162    0.79863602\n",
      "   0.79201484   0.78574008   0.77979958   0.7741822    0.7688778\n",
      "   0.76387662   0.75916994   0.7547493    0.75060725   0.74673665\n",
      "   0.7431308    0.739784     0.73669058   0.73384559   0.73124427\n",
      "   0.72888267   0.72675687   0.72486359   0.7231999    0.72176319\n",
      "   0.72055119   0.71956211   0.71879435   0.71824682   0.71791863\n",
      "   0.71780932   1.           0.73828739   0.73885024   0.7396394\n",
      "   0.74065602   0.74190187   0.74337864   0.74508876   0.74703485\n",
      "   0.72526538   0.72761542   0.73020375   0.73303467   0.73611271\n",
      "   0.73944294   0.74303085   0.74688226   0.7510038    0.75540245\n",
      "   0.76008582   0.76506215   0.77034026   0.77592981   0.78184074\n",
      "   0.78808439   0.79467267   0.80161822   0.80893487   0.52898562\n",
      "   0.51291454   0.49793857   0.48395553   0.47087574   0.45862055\n",
      "   0.44711965   0.4363113    0.42613983   0.41655573   0.40751475\n",
      "   0.399611     0.38823813   0.3806538    0.3734718    0.3666653\n",
      "   0.36021024   0.35408458   0.34826803   0.34274226   0.33749029\n",
      "   0.33249652   0.32774684   0.32322803   0.31892782   0.31483531\n",
      "   0.31093997   0.30723232   0.30370349   0.30034512   0.29714981\n",
      "   0.29411048   0.29122046   0.2884737    0.28881615   0.29910675\n",
      "   0.31025571   0.32237002   0.33557519   0.35001999   0.36588031\n",
      "   0.38336843   0.40274113   0.42431211   0.44846955   0.24207902\n",
      "   0.24091013   0.2398251    0.2388223    0.25435534   0.71093136\n",
      "   0.70863533   0.7065686    0.70472795   0.70311046   0.70171368\n",
      "   0.70053536   0.69957376   0.69882733   0.698295     0.69797587\n",
      "   0.6978696    1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   0.46766621   0.39589906   0.38227844   0.36967266   0.35797733\n",
      "   0.34710175   0.33696681   0.32750422   0.3186529    0.31535536\n",
      "   0.31916118   0.32315952   0.32736021   0.33177397   0.33641231\n",
      "   0.34128767   0.34641343   0.35180423   0.35747606   0.36344635\n",
      "   0.36973414   0.37635988   0.3833462    0.39071813   0.39850292\n",
      "   0.40673083   0.418935     0.41482678   0.42437106   0.43450052\n",
      "   0.44526401   0.45671701   0.46892133   0.48194665   0.49587208\n",
      "   0.51078594   0.59662944   0.57361192   0.57813853   0.58058214\n",
      "   0.57576889   0.57120734   0.58600146   0.61122501   0.63892192\n",
      "   0.66946077   0.78772271   0.8299135    0.89621913   0.95063126\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   0.           0.           0.           1.           0.\n",
      "   0.60000002   0.           0.           0.           0.\n",
      "   0.           0.         -10.        ]\n",
      "Image data (Front Camera): \n",
      "{}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reset the environment\n",
    "env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "\n",
    "# Examine the state space for the default brain\n",
    "print(\"Sensor data (LIDAR): \\n{}\".format(env_info.vector_observations[0]))\n",
    "\n",
    "# Examine the observation space for the default brain\n",
    "Num_obs = len(env_info.visual_observations)\n",
    "\n",
    "print(\"Image data (Front Camera): \\n{}\")\n",
    "if Num_obs > 1:\n",
    "    f, axarr = plt.subplots(1, Num_obs, figsize=(20,10))\n",
    "    for i, observation in enumerate(env_info.visual_observations):\n",
    "        if observation.shape[3] == 3:\n",
    "            axarr[i].imshow(observation[0,:,:,:])\n",
    "            axarr[i].axis('off')\n",
    "        else:\n",
    "            axarr[i].imshow(observation[0,:,:,0])\n",
    "            axarr[i].axis('off')\n",
    "else:\n",
    "    f, axarr = plt.subplots(1, Num_obs)\n",
    "    for i, observation in enumerate(env_info.visual_observations):\n",
    "        if observation.shape[3] == 3:\n",
    "            axarr.imshow(observation[0,:,:,:])\n",
    "            axarr.axis('off')\n",
    "        else:\n",
    "            axarr.imshow(observation[0,:,:,0])\n",
    "            axarr.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "algorithm = 'DDuelingDQN'\n",
    "Num_action = brain.vector_action_space_size\n",
    "\n",
    "# parameter for DQN\n",
    "Num_replay_memory = 100000\n",
    "Num_start_training = 50000\n",
    "Num_training = 1000000\n",
    "Num_update = 10000\n",
    "Num_batch = 32\n",
    "Num_test = 100000\n",
    "Num_skipFrame = 4\n",
    "Num_stackFrame = 4\n",
    "Num_colorChannel = 1\n",
    "\n",
    "Epsilon = 1.0\n",
    "Final_epsilon = 0.1\n",
    "gamma = 0.99\n",
    "Learning_rate = 0.00025\n",
    "\n",
    "# Parameter for LSTM\n",
    "Num_dataSize = 366\n",
    "Num_cellState = 512\n",
    "\n",
    "# C51 Parameters\n",
    "Num_atom = 51\n",
    "V_min = -10.0\n",
    "V_max = 10.0\n",
    "delta_z = (V_max - V_min) / (Num_atom - 1)\n",
    "        \n",
    "# Parameters for network\n",
    "img_size = 80\n",
    "sensor_size = 360\n",
    "\n",
    "first_conv   = [8,8,Num_colorChannel * Num_stackFrame * Num_obs,32]\n",
    "second_conv  = [4,4,32,64]\n",
    "third_conv   = [3,3,64,64]\n",
    "first_dense  = [10*10*64 + Num_cellState, 512]\n",
    "second_dense_state  = [first_dense[1], 1]\n",
    "second_dense_action = [first_dense[1], Num_action * Num_atom]\n",
    "\n",
    "# Path of the network model\n",
    "load_path = '../saved_networks/2018-05-04_10_40_DDuelingDQN_both/model.ckpt'\n",
    "\n",
    "# Parameters for session\n",
    "Num_plot_episode = 5\n",
    "Num_step_save = 50000\n",
    "\n",
    "GPU_fraction = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(xavier_initializer(shape))\n",
    "\n",
    "def bias_variable(shape):\n",
    "\treturn tf.Variable(xavier_initializer(shape))\n",
    "\n",
    "# Xavier Weights initializer\n",
    "def xavier_initializer(shape):\n",
    "\tdim_sum = np.sum(shape)\n",
    "\tif len(shape) == 1:\n",
    "\t\tdim_sum += 1\n",
    "\tbound = np.sqrt(2.0 / dim_sum)\n",
    "\treturn tf.random_uniform(shape, minval=-bound, maxval=bound)\n",
    "\n",
    "# Convolution function\n",
    "def conv2d(x,w, stride):\n",
    "\treturn tf.nn.conv2d(x,w,strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "# Assign network variables to target network\n",
    "def assign_network_to_target():\n",
    "\t# Get trainable variables\n",
    "\ttrainable_variables = tf.trainable_variables()\n",
    "\t# network lstm variables\n",
    "\ttrainable_variables_network = [var for var in trainable_variables if var.name.startswith('network')]\n",
    "\n",
    "\t# target lstm variables\n",
    "\ttrainable_variables_target = [var for var in trainable_variables if var.name.startswith('target')]\n",
    "\n",
    "    # assign network variables to target network\n",
    "\tfor i in range(len(trainable_variables_network)):\n",
    "\t\tsess.run(tf.assign(trainable_variables_target[i], trainable_variables_network[i]))\n",
    "\n",
    "# Code for tensorboard\n",
    "def setup_summary():\n",
    "    episode_speed      = tf.Variable(0.)\n",
    "    episode_overtake   = tf.Variable(0.)\n",
    "    episode_lanechange = tf.Variable(0.)\n",
    "\n",
    "    tf.summary.scalar('Average_Speed/' + str(Num_plot_episode) + 'episodes', episode_speed)\n",
    "    tf.summary.scalar('Average_overtake/' + str(Num_plot_episode) + 'episodes', episode_overtake)\n",
    "    tf.summary.scalar('Average_lanechange/' + str(Num_plot_episode) + 'episodes', episode_lanechange)\n",
    "\n",
    "    summary_vars = [episode_speed, episode_overtake, episode_lanechange]\n",
    "    summary_placeholders = [tf.placeholder(tf.float32) for _ in range(len(summary_vars))]\n",
    "    update_ops = [summary_vars[i].assign(summary_placeholders[i]) for i in range(len(summary_vars))]\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    return summary_placeholders, update_ops, summary_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Input\n",
    "x_image = tf.placeholder(tf.float32, shape = [None, img_size, img_size, Num_colorChannel * Num_stackFrame * Num_obs])\n",
    "x_normalize = (x_image - (255.0/2)) / (255.0/2)\n",
    "\n",
    "x_sensor = tf.placeholder(tf.float32, shape = [None, Num_stackFrame, Num_dataSize])\n",
    "x_unstack = tf.unstack(x_sensor, axis = 1)\n",
    "\n",
    "z = tf.reshape ( tf.range(V_min, V_max + delta_z, delta_z), [1, Num_atom])\n",
    "\n",
    "with tf.variable_scope('network'):\n",
    "    # Convolution variables\n",
    "    w_conv1 = weight_variable(first_conv)\n",
    "    b_conv1 = bias_variable([first_conv[3]])\n",
    "\n",
    "    w_conv2 = weight_variable(second_conv)\n",
    "    b_conv2 = bias_variable([second_conv[3]])\n",
    "\n",
    "    w_conv3 = weight_variable(third_conv)\n",
    "    b_conv3 = bias_variable([third_conv[3]])\n",
    "\n",
    "    # Densely connect layer variables\n",
    "    w_fc1_1 = weight_variable(first_dense)\n",
    "    b_fc1_1 = bias_variable([first_dense[1]])\n",
    "\n",
    "    w_fc1_2 = weight_variable(first_dense)\n",
    "    b_fc1_2 = bias_variable([first_dense[1]])\n",
    "\n",
    "    w_fc2_1 = weight_variable(second_dense_state)\n",
    "    b_fc2_1 = bias_variable([second_dense_state[1]])\n",
    "\n",
    "    w_fc2_2 = weight_variable(second_dense_action)\n",
    "    b_fc2_2 = bias_variable([second_dense_action[1]])\n",
    "    \n",
    "    # LSTM cell\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units = Num_cellState)            \n",
    "    rnn_out, rnn_state = tf.nn.static_rnn(inputs = x_unstack, cell = cell, dtype = tf.float32)\n",
    "    \n",
    "# Network\n",
    "h_conv1 = tf.nn.relu(conv2d(x_normalize, w_conv1, 4) + b_conv1)\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, w_conv2, 2) + b_conv2)\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, w_conv3, 1) + b_conv3)\n",
    "\n",
    "h_pool3_flat = tf.reshape(h_conv3, [-1, 10 * 10 * 64])\n",
    "rnn_out = rnn_out[-1]\n",
    "h_concat = tf.concat([h_pool3_flat, rnn_out], axis = 1)\n",
    "\n",
    "h_fc1_state  = tf.nn.relu(tf.matmul(h_concat, w_fc1_1)+b_fc1_1)\n",
    "h_fc1_action = tf.nn.relu(tf.matmul(h_concat, w_fc1_2)+b_fc1_2)\n",
    "\n",
    "h_fc2_state  = tf.matmul(h_fc1_state,  w_fc2_1)+b_fc2_1\n",
    "h_fc2_action = tf.matmul(h_fc1_action, w_fc2_2)+b_fc2_2\n",
    "\n",
    "h_fc2_advantage = tf.subtract(h_fc2_action, tf.reduce_mean(h_fc2_action))\n",
    "\n",
    "# Get Q value for each action\n",
    "logits = tf.add(h_fc2_state, h_fc2_advantage)\n",
    "logits_reshape = tf.reshape(logits, [-1, Num_action, Num_atom])\n",
    "p_action = tf.nn.softmax(logits_reshape)\n",
    "z_action = tf.tile(z, [tf.shape(logits_reshape)[0] * tf.shape(logits_reshape)[1], 1])\n",
    "z_action = tf.reshape(z_action, [-1, Num_action, Num_atom])\n",
    "Q_action = tf.reduce_sum(tf.multiply(z_action, p_action), axis = 2)\n",
    "\n",
    "with tf.variable_scope('target'):\n",
    "    # Convolution variables target\n",
    "    w_conv1_target = weight_variable(first_conv)\n",
    "    b_conv1_target = bias_variable([first_conv[3]])\n",
    "\n",
    "    w_conv2_target = weight_variable(second_conv)\n",
    "    b_conv2_target = bias_variable([second_conv[3]])\n",
    "\n",
    "    w_conv3_target = weight_variable(third_conv)\n",
    "    b_conv3_target = bias_variable([third_conv[3]])\n",
    "\n",
    "    # Densely connect layer variables target\n",
    "    w_fc1_1_target = weight_variable(first_dense)\n",
    "    b_fc1_1_target = bias_variable([first_dense[1]])\n",
    "\n",
    "    w_fc1_2_target = weight_variable(first_dense)\n",
    "    b_fc1_2_target = bias_variable([first_dense[1]])\n",
    "\n",
    "    w_fc2_1_target = weight_variable(second_dense_state)\n",
    "    b_fc2_1_target = bias_variable([second_dense_state[1]])\n",
    "\n",
    "    w_fc2_2_target = weight_variable(second_dense_action)\n",
    "    b_fc2_2_target = bias_variable([second_dense_action[1]])\n",
    "\n",
    "    # LSTM cell\n",
    "    cell_target = tf.contrib.rnn.BasicLSTMCell(num_units = Num_cellState)            \n",
    "    rnn_out_target, rnn_state_target = tf.nn.static_rnn(inputs = x_unstack, cell = cell_target, dtype = tf.float32)\n",
    "    \n",
    "# Target Network\n",
    "h_conv1_target = tf.nn.relu(conv2d(x_normalize, w_conv1_target, 4) + b_conv1_target)\n",
    "h_conv2_target = tf.nn.relu(conv2d(h_conv1_target, w_conv2_target, 2) + b_conv2_target)\n",
    "h_conv3_target = tf.nn.relu(conv2d(h_conv2_target, w_conv3_target, 1) + b_conv3_target)\n",
    "\n",
    "h_pool3_flat_target = tf.reshape(h_conv3_target, [-1, 10 * 10 * 64])\n",
    "rnn_out_target = rnn_out_target[-1]\n",
    "h_concat_target = tf.concat([h_pool3_flat_target, rnn_out_target], axis = 1)\n",
    "\n",
    "h_fc1_state_target  = tf.nn.relu(tf.matmul(h_concat_target, w_fc1_1_target)+b_fc1_1_target)\n",
    "h_fc1_action_target = tf.nn.relu(tf.matmul(h_concat_target, w_fc1_2_target)+b_fc1_2_target)\n",
    "\n",
    "h_fc2_state_target  = tf.matmul(h_fc1_state_target,  w_fc2_1_target)+b_fc2_1_target\n",
    "h_fc2_action_target = tf.matmul(h_fc1_action_target, w_fc2_2_target)+b_fc2_2_target\n",
    "\n",
    "h_fc2_advantage_target = tf.subtract(h_fc2_action_target, tf.reduce_mean(h_fc2_action_target))\n",
    "\n",
    "# Get Q value for each action\n",
    "logits_target = tf.add(h_fc2_state_target, h_fc2_advantage_target)\n",
    "logits_reshape_target = tf.reshape(logits_target, [-1, Num_action, Num_atom])\n",
    "p_action_target = tf.nn.softmax(logits_reshape_target)\n",
    "z_action_target = tf.tile(z, [tf.shape(logits_reshape_target)[0] * tf.shape(logits_reshape_target)[1], 1])\n",
    "z_action_target = tf.reshape(z_action, [-1, Num_action, Num_atom])\n",
    "Q_action_target = tf.reduce_sum(tf.multiply(z_action_target, p_action_target), axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and Train\n",
    "m_loss = tf.placeholder(tf.float32, shape = [Num_batch, Num_atom])\n",
    "action_binary_loss = tf.placeholder(tf.float32, shape = [None, Num_action * Num_atom])\n",
    "logit_valid_loss = tf.multiply(logits, action_binary_loss)\n",
    "\n",
    "diagonal = tf.ones([Num_atom])\n",
    "diag = tf.diag(diagonal)\n",
    "diag = tf.tile(diag, [Num_action, 1])\n",
    "\n",
    "logit_final_loss = tf.matmul(logit_valid_loss, diag)\n",
    "p_loss = tf.nn.softmax(logit_final_loss)\n",
    "\n",
    "Loss = - tf.reduce_mean(tf.reduce_sum(tf.multiply(m_loss, tf.log(p_loss + 1e-20)), axis = 1))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate = Learning_rate, epsilon = 1e-02).minimize(Loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize variables\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = GPU_fraction\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training or Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference? / Training?(1=Inference/2=Training): 2\n"
     ]
    }
   ],
   "source": [
    "# Load the file if the saved file exists\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# check_save = 1\n",
    "check_save = input('Inference? / Training?(1=Inference/2=Training): ')\n",
    "\n",
    "if check_save == '1':\n",
    "    # Directly start inference\n",
    "    Num_start_training = 0\n",
    "    Num_training = 0\n",
    "    \n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, load_path)\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "# date - hour - minute of training time\n",
    "date_time = str(datetime.date.today()) + '_' + str(datetime.datetime.now().hour) + '_' + str(datetime.datetime.now().minute)\n",
    "\n",
    "# Make folder for save data\n",
    "os.makedirs('../saved_networks/' + date_time + '_' + algorithm + '_both')\n",
    "\n",
    "# Summary for tensorboard\n",
    "summary_placeholders, update_ops, summary_op = setup_summary()\n",
    "summary_writer = tf.summary.FileWriter('../saved_networks/' + date_time + '_' + algorithm + '_both', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize input \n",
    "def input_initialization(env_info):\n",
    "    # Observation\n",
    "    observation_stack_obs = np.zeros([img_size, img_size, Num_colorChannel * Num_obs])\n",
    "    \n",
    "    for i in range(Num_obs):\n",
    "        observation = 255 * env_info.visual_observations[i]\n",
    "        observation = np.uint8(observation)\n",
    "        observation = np.reshape(observation, (observation.shape[1], observation.shape[2], 3))\n",
    "        observation = cv2.resize(observation, (img_size, img_size))\n",
    "\n",
    "        if Num_colorChannel == 1:\n",
    "            observation = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY)\n",
    "            observation = np.reshape(observation, (img_size, img_size))\n",
    "\n",
    "        if Num_colorChannel == 3:\n",
    "            observation_stack_obs[:,:, Num_colorChannel * i: Num_colorChannel * (i+1)] = observation\n",
    "        else:\n",
    "            observation_stack_obs[:,:, i] = observation\n",
    "\n",
    "    observation_set = []\n",
    "\n",
    "    # State\n",
    "    state = env_info.vector_observations[0][:-7]\n",
    "    state_set = []\n",
    "        \n",
    "    for i in range(Num_skipFrame * Num_stackFrame):\n",
    "        observation_set.append(observation_stack_obs)\n",
    "        state_set.append(state)\n",
    "    \n",
    "    # Stack the frame according to the number of skipping and stacking frames using observation set\n",
    "    observation_stack = np.zeros((img_size, img_size, Num_colorChannel * Num_stackFrame * Num_obs))\n",
    "    state_stack = np.zeros((Num_stackFrame, Num_dataSize))\n",
    "    \n",
    "    for stack_frame in range(Num_stackFrame):\n",
    "        observation_stack[:,:,Num_obs * stack_frame: Num_obs * (stack_frame+1)] = observation_set[-1 - (Num_skipFrame * stack_frame)]\n",
    "        state_stack[(Num_stackFrame - 1) - stack_frame, :] = state_set[-1 - (Num_skipFrame * stack_frame)]\n",
    "    \n",
    "    observation_stack = np.uint8(observation_stack)\n",
    "    state_stack = np.uint8(state_stack)\n",
    "    \n",
    "    return observation_stack, observation_set, state_stack, state_set\n",
    "\n",
    "# Resize input information \n",
    "def resize_input(env_info, observation_set, state_set):\n",
    "    # Stack observation according to the number of observations\n",
    "    observation_stack_obs = np.zeros([img_size, img_size, Num_colorChannel * Num_obs])\n",
    "\n",
    "    for i in range(Num_obs):\n",
    "        observation = 255 * env_info.visual_observations[i]\n",
    "        observation = np.uint8(observation)\n",
    "        observation = np.reshape(observation, (observation.shape[1], observation.shape[2], 3))\n",
    "        observation = cv2.resize(observation, (img_size, img_size))\n",
    "        \n",
    "        if Num_colorChannel == 1:\n",
    "            observation = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY)\n",
    "            observation = np.reshape(observation, (img_size, img_size))\n",
    "\n",
    "        if Num_colorChannel == 3:\n",
    "            observation_stack_obs[:,:, Num_colorChannel * i: Num_colorChannel * (i+1)] = observation\n",
    "        else:\n",
    "            observation_stack_obs[:,:,i] = observation\n",
    "    \n",
    "    # Add observations to the observation_set\n",
    "    observation_set.append(observation_stack_obs)\n",
    "    \n",
    "    # State \n",
    "    state = env_info.vector_observations[0][:-7]\n",
    "\n",
    "    # Add state to the state_set\n",
    "    state_set.append(state)\n",
    "    \n",
    "    # Stack the frame according to the number of skipping and stacking frames using observation set\n",
    "    observation_stack = np.zeros((img_size, img_size, Num_colorChannel * Num_stackFrame * Num_obs))\n",
    "    state_stack = np.zeros((Num_stackFrame, Num_dataSize))\n",
    "\n",
    "    for stack_frame in range(Num_stackFrame):\n",
    "        observation_stack[:,:,Num_obs * stack_frame: Num_obs * (stack_frame+1)] = observation_set[-1 - (Num_skipFrame * stack_frame)]\n",
    "        state_stack[(Num_stackFrame - 1) - stack_frame, :] = state_set[-1 - (Num_skipFrame * stack_frame)]\n",
    "\n",
    "    del observation_set[0]\n",
    "    del state_set[0]\n",
    "    \n",
    "    observation_stack = np.uint8(observation_stack)\n",
    "    state_stack = np.uint8(state_stack)\n",
    "        \n",
    "    return observation_stack, observation_set, state_stack, state_set\n",
    "\n",
    "# Get progress according to the number of steps\n",
    "def get_progress(step, Epsilon):\n",
    "    if step <= Num_start_training:\n",
    "        # Observation\n",
    "        progress = 'Observing'\n",
    "        train_mode = True\n",
    "        Epsilon = 1\n",
    "    elif step <= Num_start_training + Num_training:\n",
    "        # Training\n",
    "        progress = 'Training'\n",
    "        train_mode = True\n",
    "        \n",
    "        # Decrease the epsilon value\n",
    "        if Epsilon > Final_epsilon:\n",
    "            Epsilon -= 1.0/Num_training\n",
    "    elif step < Num_start_training + Num_training + Num_test:\n",
    "        # Testing\n",
    "        progress = 'Testing'\n",
    "        train_mode = False\n",
    "        Epsilon = 0\n",
    "    else:\n",
    "        # Finished\n",
    "        progress = 'Finished'\n",
    "        train_mode = False\n",
    "        Epsilon = 0\n",
    "        \n",
    "    return progress, train_mode, Epsilon \n",
    "\n",
    "# Select action according to the progress of training\n",
    "def select_action(progress, sess, observation_stack, state_stack, Epsilon):\n",
    "    if progress == \"Observing\":\n",
    "        # Random action \n",
    "        Q_value = 0\n",
    "        action = np.zeros([Num_action])\n",
    "        action[random.randint(0, Num_action - 1)] = 1.0\n",
    "    elif progress == \"Training\":\n",
    "        # if random value(0-1) is smaller than Epsilon, action is random. \n",
    "        # Otherwise, action is the one which has the max Q value\n",
    "        if random.random() < Epsilon:\n",
    "            Q_value = 0\n",
    "            action = np.zeros([Num_action])\n",
    "            action[random.randint(0, Num_action - 1)] = 1\n",
    "        else:\n",
    "            Q_value = Q_action.eval(feed_dict={x_image: [observation_stack], x_sensor: [state_stack]})\n",
    "            action = np.zeros([Num_action])\n",
    "            action[np.argmax(Q_value)] = 1\n",
    "    else:\n",
    "        # Max Q action \n",
    "        Q_value = Q_action.eval(feed_dict={x_image: [observation_stack], x_sensor: [state_stack]})\n",
    "        action = np.zeros([Num_action])\n",
    "        action[np.argmax(Q_value)] = 1\n",
    "        \n",
    "    return action, Q_value\n",
    "\n",
    "def train(Replay_memory, sess, step):\n",
    "    # Select minibatch\n",
    "    minibatch =  random.sample(Replay_memory, Num_batch)\n",
    "\n",
    "    # Save the each batch data\n",
    "    observation_batch      = [batch[0] for batch in minibatch]\n",
    "    state_batch            = [batch[1] for batch in minibatch]\n",
    "    action_batch           = [batch[2] for batch in minibatch]\n",
    "    reward_batch           = [batch[3] for batch in minibatch]\n",
    "    observation_next_batch = [batch[4] for batch in minibatch]\n",
    "    state_next_batch       = [batch[5] for batch in minibatch]\n",
    "    terminal_batch \t       = [batch[6] for batch in minibatch]\n",
    "\n",
    "    # Update target network according to the Num_update value\n",
    "    if step % Num_update == 0:\n",
    "        assign_network_to_target()\n",
    "    \n",
    "    ####################################### Double Q Learning part #######################################\n",
    "    # Get target values\n",
    "    y_batch = []\n",
    "    \n",
    "    # Selecting actions\n",
    "#     Q_network = output.eval(feed_dict = {x_image: observation_next_batch, x_sensor: state_next_batch})\n",
    "\n",
    "    Q_batch = Q_action.eval(feed_dict = {x_image: observation_next_batch, x_sensor: state_next_batch})\n",
    "    p_batch = p_action_target.eval(feed_dict = {x_image: observation_next_batch, x_sensor: state_next_batch})\n",
    "    z_batch = z.eval()\n",
    "        \n",
    "    a_max = []\n",
    "    for i in range(Q_batch.shape[0]):\n",
    "        a_max.append(np.argmax(Q_batch[i]))\n",
    "\n",
    "    # Evaluation\n",
    "    p_batch_target = p_action_target.eval(feed_dict = {x_image: observation_next_batch, x_sensor: state_next_batch})\n",
    "    \n",
    "    m_batch = np.zeros([Num_batch, Num_atom])\n",
    "    for i in range(len(minibatch)):\n",
    "        action_max = np.argmax(Q_batch[i, :])\n",
    "        if terminal_batch[i]:\n",
    "            Tz = reward_batch[i]\n",
    "\n",
    "            # Bounding Tz\n",
    "            if Tz >= V_max:\n",
    "                Tz = V_max\n",
    "            elif Tz <= V_min:\n",
    "                Tz = V_min\n",
    "\n",
    "            b = (Tz - V_min) / delta_z\n",
    "            l = np.int32(np.floor(b))\n",
    "            u = np.int32(np.ceil(b))\n",
    "\n",
    "            m_batch[i, l] += (u - b)\n",
    "            m_batch[i, u] += (b - l)\n",
    "        else:\n",
    "            for j in range(Num_atom):\n",
    "                Tz = reward_batch[i] + gamma * z_batch[0,j]\n",
    "\n",
    "                # Bounding Tz\n",
    "                if Tz >= V_max:\n",
    "                    Tz = V_max\n",
    "                elif Tz <= V_min:\n",
    "                    Tz = V_min\n",
    "\n",
    "                b = (Tz - V_min) / delta_z\n",
    "                l = np.int32(np.floor(b))\n",
    "                u = np.int32(np.ceil(b))\n",
    "\n",
    "                m_batch[i, l] += p_batch_target[i, a_max[i], j] * (u - b)\n",
    "                m_batch[i, u] += p_batch_target[i, a_max[i], j] * (b - l)\n",
    "\n",
    "        sum_m_batch = np.sum(m_batch[i,:])\n",
    "        for j in range(Num_atom):\n",
    "            m_batch[i,j] = m_batch[i,j] / sum_m_batch\n",
    "\n",
    "    action_binary = np.zeros([Num_batch, Num_action * Num_atom])\n",
    "\n",
    "    for i in range(len(action_batch)):\n",
    "        action_batch_max = np.argmax(action_batch[i])\n",
    "        action_binary[i, Num_atom * action_batch_max : Num_atom * (action_batch_max + 1)] = 1\n",
    "\n",
    "    _, loss = sess.run([train_step, Loss],\n",
    "                        feed_dict = {x_image: observation_next_batch, \n",
    "                                     x_sensor: state_next_batch, \n",
    "                                     m_loss: m_batch, \n",
    "                                     action_binary_loss: action_binary})\n",
    "    ######################################################################################################\n",
    "\n",
    "# Experience Replay \n",
    "def Experience_Replay(progress, Replay_memory, obs_stack, s_stack, action, reward, next_obs_stack, next_s_stack, terminal):\n",
    "    if progress != 'Testing':\n",
    "        # If length of replay memeory is more than the setting value then remove the first one\n",
    "        if len(Replay_memory) > Num_replay_memory:\n",
    "            del Replay_memory[0]\n",
    "\n",
    "        # Save experience to the Replay memory\n",
    "        Replay_memory.append([obs_stack, s_stack, action, reward, next_obs_stack, next_s_stack, terminal])\n",
    "    else:\n",
    "        # Empty the replay memory if testing\n",
    "        Replay_memory = []\n",
    "    \n",
    "    return Replay_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "Replay_memory = []\n",
    "\n",
    "step = 1\n",
    "score = 0\n",
    "score_board = 0\n",
    "\n",
    "episode = 0\n",
    "step_per_episode = 0\n",
    "\n",
    "speed_list = []\n",
    "overtake_list = []\n",
    "lanechange_list = []\n",
    "\n",
    "train_mode = True\n",
    "env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "\n",
    "observation_stack, observation_set, state_stack, state_set = input_initialization(env_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3778 / episode: 0 / progress: Observing / epsilon: 1 / score: 1262.686646334827\n",
      "step: 5552 / episode: 0 / progress: Observing / epsilon: 1 / score: 456.495314180851\n",
      "step: 10670 / episode: 0 / progress: Observing / epsilon: 1 / score: 883.7547171488404\n",
      "step: 15222 / episode: 0 / progress: Observing / epsilon: 1 / score: 1416.0203598216176\n",
      "step: 20042 / episode: 0 / progress: Observing / epsilon: 1 / score: 1105.6547597572207\n",
      "step: 24803 / episode: 0 / progress: Observing / epsilon: 1 / score: 1176.2950584068894\n",
      "step: 29341 / episode: 0 / progress: Observing / epsilon: 1 / score: 1341.817975729704\n",
      "step: 31484 / episode: 0 / progress: Observing / epsilon: 1 / score: 397.04768016934395\n",
      "step: 36190 / episode: 0 / progress: Observing / epsilon: 1 / score: 1349.8171183541417\n",
      "step: 40958 / episode: 0 / progress: Observing / epsilon: 1 / score: 1255.1516719162464\n",
      "step: 45785 / episode: 0 / progress: Observing / epsilon: 1 / score: 1070.1808090880513\n",
      "step: 50202 / episode: 0 / progress: Training / epsilon: 0.9997989999999942 / score: 1502.7597682476044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Q\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:215: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 54822 / episode: 1 / progress: Training / epsilon: 0.9951789999998614 / score: 1309.5795969218016\n",
      "step: 57095 / episode: 2 / progress: Training / epsilon: 0.992905999999796 / score: 692.3885727748275\n",
      "step: 61758 / episode: 3 / progress: Training / epsilon: 0.9882429999996619 / score: 1235.24727217108\n",
      "step: 66617 / episode: 4 / progress: Training / epsilon: 0.9833839999995222 / score: 1040.0449554398656\n",
      "step: 71638 / episode: 5 / progress: Training / epsilon: 0.9783629999993778 / score: 979.0096921250224\n",
      "step: 72201 / episode: 6 / progress: Training / epsilon: 0.9777999999993616 / score: 148.21839679777622\n",
      "step: 77240 / episode: 7 / progress: Training / epsilon: 0.9727609999992167 / score: 1034.7541055679321\n",
      "step: 80978 / episode: 8 / progress: Training / epsilon: 0.9690229999991092 / score: 458.422555655241\n",
      "step: 85603 / episode: 9 / progress: Training / epsilon: 0.9643979999989762 / score: 1388.2830215618014\n",
      "step: 90534 / episode: 10 / progress: Training / epsilon: 0.9594669999988344 / score: 1039.0044924020767\n",
      "step: 95222 / episode: 11 / progress: Training / epsilon: 0.9547789999986996 / score: 1174.8374550491571\n",
      "step: 99816 / episode: 12 / progress: Training / epsilon: 0.9501849999985675 / score: 1305.9170148074627\n",
      "step: 101256 / episode: 13 / progress: Training / epsilon: 0.9487449999985261 / score: 151.08298411220312\n",
      "step: 102636 / episode: 14 / progress: Training / epsilon: 0.9473649999984864 / score: 246.3763660788536\n",
      "step: 105277 / episode: 15 / progress: Training / epsilon: 0.9447239999984105 / score: 720.5115519538522\n",
      "step: 109082 / episode: 16 / progress: Training / epsilon: 0.9409189999983011 / score: 1048.968448534608\n",
      "step: 109663 / episode: 17 / progress: Training / epsilon: 0.9403379999982844 / score: 55.53857895731926\n",
      "step: 114315 / episode: 18 / progress: Training / epsilon: 0.9356859999981506 / score: 1131.9680297225714\n",
      "step: 118941 / episode: 19 / progress: Training / epsilon: 0.9310599999980176 / score: 1245.4876538217068\n",
      "step: 124015 / episode: 20 / progress: Training / epsilon: 0.9259859999978717 / score: 893.8899278044701\n",
      "step: 126725 / episode: 21 / progress: Training / epsilon: 0.9232759999977938 / score: 990.1285133734345\n",
      "step: 131587 / episode: 22 / progress: Training / epsilon: 0.9184139999976539 / score: 881.9607136175036\n",
      "step: 135053 / episode: 23 / progress: Training / epsilon: 0.9149479999975543 / score: 1134.6169377863407\n",
      "step: 136399 / episode: 24 / progress: Training / epsilon: 0.9136019999975156 / score: 153.17499192804098\n",
      "step: 141291 / episode: 25 / progress: Training / epsilon: 0.9087099999973749 / score: 1023.9266107082367\n",
      "step: 145883 / episode: 26 / progress: Training / epsilon: 0.9041179999972428 / score: 1384.0247872769833\n",
      "step: 150544 / episode: 27 / progress: Training / epsilon: 0.8994569999971088 / score: 1094.1999114081264\n",
      "step: 155339 / episode: 28 / progress: Training / epsilon: 0.8946619999969709 / score: 1197.5197920054197\n",
      "step: 159071 / episode: 29 / progress: Training / epsilon: 0.8909299999968636 / score: 867.3602389842272\n",
      "step: 163329 / episode: 30 / progress: Training / epsilon: 0.8866719999967412 / score: 642.1247308179736\n",
      "step: 167370 / episode: 31 / progress: Training / epsilon: 0.882630999996625 / score: 1170.8503929898143\n",
      "step: 169895 / episode: 32 / progress: Training / epsilon: 0.8801059999965524 / score: 470.73630118370056\n",
      "step: 174462 / episode: 33 / progress: Training / epsilon: 0.875538999996421 / score: 1322.51914511621\n",
      "step: 179291 / episode: 34 / progress: Training / epsilon: 0.8707099999962822 / score: 1012.227124735713\n",
      "step: 182906 / episode: 35 / progress: Training / epsilon: 0.8670949999961782 / score: 589.4233701080084\n",
      "step: 183183 / episode: 36 / progress: Training / epsilon: 0.8668179999961703 / score: 141.78004944324493\n",
      "step: 187873 / episode: 37 / progress: Training / epsilon: 0.8621279999960354 / score: 1147.7836277857423\n",
      "step: 192495 / episode: 38 / progress: Training / epsilon: 0.8575059999959025 / score: 1202.3860647827387\n",
      "step: 196089 / episode: 39 / progress: Training / epsilon: 0.8539119999957991 / score: 637.6338043138385\n",
      "step: 200526 / episode: 40 / progress: Training / epsilon: 0.8494749999956716 / score: 1587.5060137659311\n",
      "step: 205134 / episode: 41 / progress: Training / epsilon: 0.844866999995539 / score: 1125.2938774451613\n",
      "step: 209659 / episode: 42 / progress: Training / epsilon: 0.8403419999954089 / score: 1274.6223609149456\n",
      "step: 214045 / episode: 43 / progress: Training / epsilon: 0.8359559999952828 / score: 979.8596418574452\n",
      "step: 218793 / episode: 44 / progress: Training / epsilon: 0.8312079999951463 / score: 999.0684915333986\n",
      "step: 223383 / episode: 45 / progress: Training / epsilon: 0.8266179999950143 / score: 1379.9552335739136\n",
      "step: 225535 / episode: 46 / progress: Training / epsilon: 0.8244659999949524 / score: 171.1042414009571\n",
      "step: 230322 / episode: 47 / progress: Training / epsilon: 0.8196789999948147 / score: 1047.5481988564134\n",
      "step: 235042 / episode: 48 / progress: Training / epsilon: 0.814958999994679 / score: 1007.826738871634\n",
      "step: 239958 / episode: 49 / progress: Training / epsilon: 0.8100429999945377 / score: 1010.9162220582366\n",
      "step: 244892 / episode: 50 / progress: Training / epsilon: 0.8051089999943958 / score: 974.118698745966\n",
      "step: 249548 / episode: 51 / progress: Training / epsilon: 0.8004529999942619 / score: 1201.315327771008\n",
      "step: 254218 / episode: 52 / progress: Training / epsilon: 0.7957829999941276 / score: 1154.8884428739548\n",
      "step: 257905 / episode: 53 / progress: Training / epsilon: 0.7920959999940216 / score: 563.6239968687296\n",
      "step: 261840 / episode: 54 / progress: Training / epsilon: 0.7881609999939084 / score: 1102.8363772332668\n",
      "step: 262984 / episode: 55 / progress: Training / epsilon: 0.7870169999938755 / score: 366.4389349669218\n",
      "step: 267108 / episode: 56 / progress: Training / epsilon: 0.7828929999937569 / score: 799.6671981066465\n",
      "step: 271732 / episode: 57 / progress: Training / epsilon: 0.778268999993624 / score: 1196.1491920277476\n",
      "step: 273955 / episode: 58 / progress: Training / epsilon: 0.77604599999356 / score: 518.7970350980759\n",
      "step: 278950 / episode: 59 / progress: Training / epsilon: 0.7710509999934164 / score: 1027.2467706501484\n",
      "step: 283908 / episode: 60 / progress: Training / epsilon: 0.7660929999932738 / score: 883.5834224894643\n",
      "step: 288523 / episode: 61 / progress: Training / epsilon: 0.7614779999931411 / score: 1276.031087346375\n",
      "step: 293247 / episode: 62 / progress: Training / epsilon: 0.7567539999930053 / score: 1138.620195992291\n",
      "step: 298012 / episode: 63 / progress: Training / epsilon: 0.7519889999928683 / score: 1154.352860443294\n",
      "step: 302853 / episode: 64 / progress: Training / epsilon: 0.7471479999927291 / score: 938.8677683472633\n",
      "step: 307720 / episode: 65 / progress: Training / epsilon: 0.7422809999925891 / score: 987.2733848541975\n",
      "step: 309079 / episode: 66 / progress: Training / epsilon: 0.74092199999255 / score: 516.4718200713396\n",
      "step: 314117 / episode: 67 / progress: Training / epsilon: 0.7358839999924052 / score: 960.2539463713765\n",
      "step: 319136 / episode: 68 / progress: Training / epsilon: 0.7308649999922608 / score: 867.7533393129706\n",
      "step: 323019 / episode: 69 / progress: Training / epsilon: 0.7269819999921492 / score: 970.968509465456\n",
      "step: 327927 / episode: 70 / progress: Training / epsilon: 0.722073999992008 / score: 1044.4565239101648\n",
      "step: 331964 / episode: 71 / progress: Training / epsilon: 0.718036999991892 / score: 535.6695733070374\n",
      "step: 336776 / episode: 72 / progress: Training / epsilon: 0.7132249999917536 / score: 950.106148391962\n",
      "step: 341764 / episode: 73 / progress: Training / epsilon: 0.7082369999916102 / score: 842.5917767435312\n",
      "step: 346664 / episode: 74 / progress: Training / epsilon: 0.7033369999914693 / score: 974.5061194822192\n",
      "step: 351712 / episode: 75 / progress: Training / epsilon: 0.6982889999913241 / score: 895.9439174160361\n",
      "step: 356546 / episode: 76 / progress: Training / epsilon: 0.6934549999911851 / score: 967.7691329345107\n",
      "step: 360105 / episode: 77 / progress: Training / epsilon: 0.6898959999910828 / score: 562.4810318946838\n",
      "step: 364745 / episode: 78 / progress: Training / epsilon: 0.6852559999909493 / score: 1200.967428818345\n",
      "step: 369441 / episode: 79 / progress: Training / epsilon: 0.6805599999908143 / score: 1251.9051023721695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 374033 / episode: 80 / progress: Training / epsilon: 0.6759679999906822 / score: 1198.9491466358304\n",
      "step: 378523 / episode: 81 / progress: Training / epsilon: 0.6714779999905531 / score: 1389.2647273167968\n",
      "step: 379818 / episode: 82 / progress: Training / epsilon: 0.6701829999905159 / score: 247.09771566092968\n",
      "step: 384639 / episode: 83 / progress: Training / epsilon: 0.6653619999903773 / score: 1026.8412184938788\n",
      "step: 389354 / episode: 84 / progress: Training / epsilon: 0.6606469999902417 / score: 1151.7848256081343\n",
      "step: 393889 / episode: 85 / progress: Training / epsilon: 0.6561119999901113 / score: 918.122352167964\n",
      "step: 398819 / episode: 86 / progress: Training / epsilon: 0.6511819999899695 / score: 908.7882938459516\n",
      "step: 401078 / episode: 87 / progress: Training / epsilon: 0.6489229999899045 / score: 414.972089394927\n",
      "step: 406027 / episode: 88 / progress: Training / epsilon: 0.6439739999897622 / score: 934.524875998497\n",
      "step: 410774 / episode: 89 / progress: Training / epsilon: 0.6392269999896257 / score: 1060.8443700373173\n",
      "step: 415873 / episode: 90 / progress: Training / epsilon: 0.6341279999894791 / score: 730.1989886239171\n",
      "step: 418842 / episode: 91 / progress: Training / epsilon: 0.6311589999893937 / score: 477.5372392013669\n",
      "step: 421637 / episode: 92 / progress: Training / epsilon: 0.6283639999893134 / score: 668.5884283035994\n",
      "step: 426447 / episode: 93 / progress: Training / epsilon: 0.623553999989175 / score: 1018.7013362124562\n",
      "step: 431309 / episode: 94 / progress: Training / epsilon: 0.6186919999890352 / score: 965.7503620386124\n",
      "step: 436242 / episode: 95 / progress: Training / epsilon: 0.6137589999888934 / score: 925.1591073349118\n",
      "step: 441227 / episode: 96 / progress: Training / epsilon: 0.60877399998875 / score: 917.0807259306312\n",
      "step: 446032 / episode: 97 / progress: Training / epsilon: 0.6039689999886119 / score: 931.9505980238318\n",
      "step: 450749 / episode: 98 / progress: Training / epsilon: 0.5992519999884762 / score: 1234.562240742147\n",
      "step: 455474 / episode: 99 / progress: Training / epsilon: 0.5945269999883404 / score: 1260.067686252296\n",
      "step: 459937 / episode: 100 / progress: Training / epsilon: 0.590063999988212 / score: 1430.4433611556888\n",
      "step: 464773 / episode: 101 / progress: Training / epsilon: 0.585227999988073 / score: 1197.7636384144425\n",
      "step: 469763 / episode: 102 / progress: Training / epsilon: 0.5802379999879295 / score: 788.7012664079666\n",
      "step: 474558 / episode: 103 / progress: Training / epsilon: 0.5754429999877916 / score: 1056.6875148564577\n",
      "step: 478199 / episode: 104 / progress: Training / epsilon: 0.5718019999876869 / score: 1053.3002240732312\n",
      "step: 480225 / episode: 105 / progress: Training / epsilon: 0.5697759999876286 / score: 275.1672423630953\n",
      "step: 485202 / episode: 106 / progress: Training / epsilon: 0.5647989999874855 / score: 862.3708769008517\n",
      "step: 490048 / episode: 107 / progress: Training / epsilon: 0.5599529999873462 / score: 881.5056617110968\n",
      "step: 492040 / episode: 108 / progress: Training / epsilon: 0.5579609999872889 / score: 293.1010398566723\n",
      "step: 497261 / episode: 109 / progress: Training / epsilon: 0.5527399999871387 / score: 615.7375366836786\n",
      "step: 502202 / episode: 110 / progress: Training / epsilon: 0.5477989999869967 / score: 902.8806423693895\n",
      "step: 506966 / episode: 111 / progress: Training / epsilon: 0.5430349999868597 / score: 1133.3096337541938\n",
      "step: 511723 / episode: 112 / progress: Training / epsilon: 0.5382779999867229 / score: 1015.2586780712008\n",
      "step: 516501 / episode: 113 / progress: Training / epsilon: 0.5334999999865855 / score: 1055.3965688869357\n",
      "step: 521464 / episode: 114 / progress: Training / epsilon: 0.5285369999864428 / score: 768.39909735322\n",
      "step: 526277 / episode: 115 / progress: Training / epsilon: 0.5237239999863044 / score: 1065.4643500894308\n",
      "step: 530888 / episode: 116 / progress: Training / epsilon: 0.5191129999861718 / score: 1347.872529141605\n",
      "step: 535984 / episode: 117 / progress: Training / epsilon: 0.5140169999860252 / score: 720.8997223004699\n",
      "step: 539907 / episode: 118 / progress: Training / epsilon: 0.5100939999859124 / score: 703.2187881395221\n",
      "step: 541297 / episode: 119 / progress: Training / epsilon: 0.5087039999858725 / score: 214.19636022299528\n",
      "step: 546068 / episode: 120 / progress: Training / epsilon: 0.5039329999857353 / score: 1054.6468936055899\n",
      "step: 550828 / episode: 121 / progress: Training / epsilon: 0.49917299998564435 / score: 1059.988270752132\n",
      "step: 553990 / episode: 122 / progress: Training / epsilon: 0.49601099998572895 / score: 635.161774776876\n",
      "step: 558752 / episode: 123 / progress: Training / epsilon: 0.49124899998585636 / score: 1168.4382987767458\n",
      "step: 563613 / episode: 124 / progress: Training / epsilon: 0.4863879999859864 / score: 923.0710079744458\n",
      "step: 566426 / episode: 125 / progress: Training / epsilon: 0.4835749999860617 / score: 689.3525566235185\n",
      "step: 571272 / episode: 126 / progress: Training / epsilon: 0.47872899998619134 / score: 963.412705540657\n",
      "step: 576124 / episode: 127 / progress: Training / epsilon: 0.47387699998632116 / score: 983.7422019988298\n",
      "step: 577570 / episode: 128 / progress: Training / epsilon: 0.47243099998635985 / score: 342.33761014789343\n",
      "step: 582370 / episode: 129 / progress: Training / epsilon: 0.46763099998648827 / score: 1042.9072889909148\n",
      "step: 587252 / episode: 130 / progress: Training / epsilon: 0.4627489999866189 / score: 1022.070127941668\n",
      "step: 592115 / episode: 131 / progress: Training / epsilon: 0.457885999986749 / score: 1042.8338067606091\n",
      "step: 593621 / episode: 132 / progress: Training / epsilon: 0.4563799999867893 / score: 160.87012914568186\n",
      "step: 597209 / episode: 133 / progress: Training / epsilon: 0.4527919999868853 / score: 661.339171461761\n",
      "step: 602356 / episode: 134 / progress: Training / epsilon: 0.447644999987023 / score: 704.36692982167\n",
      "step: 606411 / episode: 135 / progress: Training / epsilon: 0.4435899999871315 / score: 461.54535407572985\n",
      "step: 611020 / episode: 136 / progress: Training / epsilon: 0.4389809999872548 / score: 1354.0081181004643\n",
      "step: 615921 / episode: 137 / progress: Training / epsilon: 0.43407999998738594 / score: 850.3878643512726\n",
      "step: 620710 / episode: 138 / progress: Training / epsilon: 0.4292909999875141 / score: 1079.7036352455616\n",
      "step: 625820 / episode: 139 / progress: Training / epsilon: 0.4241809999876508 / score: 619.8398335799575\n",
      "step: 629363 / episode: 140 / progress: Training / epsilon: 0.4206379999877456 / score: 480.8283584341407\n",
      "step: 634025 / episode: 141 / progress: Training / epsilon: 0.4159759999878703 / score: 1182.2666066288948\n",
      "step: 638932 / episode: 142 / progress: Training / epsilon: 0.4110689999880016 / score: 847.4731914177537\n",
      "step: 643681 / episode: 143 / progress: Training / epsilon: 0.4063199999881287 / score: 1138.6048619672656\n",
      "step: 648638 / episode: 144 / progress: Training / epsilon: 0.4013629999882613 / score: 866.278090544045\n",
      "step: 652491 / episode: 145 / progress: Training / epsilon: 0.3975099999883644 / score: 475.5581191405654\n",
      "step: 657776 / episode: 146 / progress: Training / epsilon: 0.3922249999885058 / score: 491.2931357100606\n",
      "step: 662714 / episode: 147 / progress: Training / epsilon: 0.3872869999886379 / score: 909.4777239263058\n",
      "step: 665940 / episode: 148 / progress: Training / epsilon: 0.3840609999887242 / score: 570.7851667031646\n",
      "step: 670721 / episode: 149 / progress: Training / epsilon: 0.37927999998885215 / score: 1004.9050781950355\n",
      "step: 675955 / episode: 150 / progress: Training / epsilon: 0.3740459999889922 / score: 585.3840524181724\n",
      "step: 680711 / episode: 151 / progress: Training / epsilon: 0.36928999998911943 / score: 1076.483918003738\n",
      "step: 685561 / episode: 152 / progress: Training / epsilon: 0.3644399999892492 / score: 965.7533139511943\n",
      "step: 690647 / episode: 153 / progress: Training / epsilon: 0.3593539999893853 / score: 681.2009118422866\n",
      "step: 695819 / episode: 154 / progress: Training / epsilon: 0.35418199998952365 / score: 662.3166650086641\n",
      "step: 700917 / episode: 155 / progress: Training / epsilon: 0.34908399998966005 / score: 666.6207821667194\n",
      "step: 706058 / episode: 156 / progress: Training / epsilon: 0.3439429999897976 / score: 629.5581548810005\n",
      "step: 710685 / episode: 157 / progress: Training / epsilon: 0.3393159999899214 / score: 192.18208837509155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 715524 / episode: 158 / progress: Training / epsilon: 0.33447699999005087 / score: 888.1456834599376\n",
      "step: 719150 / episode: 159 / progress: Training / epsilon: 0.3308509999901479 / score: 694.8992411196232\n",
      "step: 724309 / episode: 160 / progress: Training / epsilon: 0.3256919999902859 / score: 567.0393107458949\n",
      "step: 729269 / episode: 161 / progress: Training / epsilon: 0.3207319999904186 / score: 926.538961455226\n",
      "step: 734134 / episode: 162 / progress: Training / epsilon: 0.3158669999905488 / score: 942.4490308910608\n",
      "step: 739363 / episode: 163 / progress: Training / epsilon: 0.3106379999906887 / score: 587.0213850140572\n",
      "step: 744178 / episode: 164 / progress: Training / epsilon: 0.3058229999908175 / score: 984.2278048917651\n",
      "step: 748860 / episode: 165 / progress: Training / epsilon: 0.3011409999909428 / score: 1102.7704442888498\n",
      "step: 753554 / episode: 166 / progress: Training / epsilon: 0.2964469999910684 / score: 1157.2281854376197\n",
      "step: 758420 / episode: 167 / progress: Training / epsilon: 0.2915809999911986 / score: 914.4774337410927\n",
      "step: 763462 / episode: 168 / progress: Training / epsilon: 0.2865389999913335 / score: 689.8925480172038\n",
      "step: 768877 / episode: 169 / progress: Training / epsilon: 0.28112399999147836 / score: 233.46697314083576\n",
      "step: 770320 / episode: 170 / progress: Training / epsilon: 0.27968099999151697 / score: 480.02703139930964\n",
      "step: 775524 / episode: 171 / progress: Training / epsilon: 0.2744769999916562 / score: 545.3231693282723\n",
      "step: 778411 / episode: 172 / progress: Training / epsilon: 0.27158999999173344 / score: 405.50108221173286\n",
      "step: 783158 / episode: 173 / progress: Training / epsilon: 0.26684299999186045 / score: 1096.8400223329663\n",
      "step: 784656 / episode: 174 / progress: Training / epsilon: 0.26534499999190053 / score: 63.873766861855984\n",
      "step: 789810 / episode: 175 / progress: Training / epsilon: 0.26019099999203843 / score: 683.6252275034785\n",
      "step: 794555 / episode: 176 / progress: Training / epsilon: 0.2554459999921654 / score: 1103.1134438887239\n",
      "step: 799955 / episode: 177 / progress: Training / epsilon: 0.25004599999230986 / score: 303.56748040765524\n",
      "step: 805150 / episode: 178 / progress: Training / epsilon: 0.24485099999230592 / score: 557.3438154086471\n",
      "step: 809175 / episode: 179 / progress: Training / epsilon: 0.2408259999923019 / score: 778.5186874195933\n",
      "step: 814018 / episode: 180 / progress: Training / epsilon: 0.23598299999229705 / score: 1004.0335025712848\n",
      "step: 818715 / episode: 181 / progress: Training / epsilon: 0.23128599999229235 / score: 1167.0609425455332\n",
      "step: 823864 / episode: 182 / progress: Training / epsilon: 0.2261369999922872 / score: 571.0418651327491\n",
      "step: 828890 / episode: 183 / progress: Training / epsilon: 0.22111099999228218 / score: 783.6231009066105\n",
      "step: 834105 / episode: 184 / progress: Training / epsilon: 0.21589599999227696 / score: 522.5566762760282\n",
      "step: 838820 / episode: 185 / progress: Training / epsilon: 0.21118099999227224 / score: 1166.3751232847571\n",
      "step: 843698 / episode: 186 / progress: Training / epsilon: 0.20630299999226737 / score: 881.6544708237052\n",
      "step: 848511 / episode: 187 / progress: Training / epsilon: 0.20148999999226255 / score: 1043.9464525133371\n",
      "step: 853313 / episode: 188 / progress: Training / epsilon: 0.19668799999225775 / score: 1031.7241606637836\n",
      "step: 857971 / episode: 189 / progress: Training / epsilon: 0.1920299999922531 / score: 1137.6894741654396\n",
      "step: 863057 / episode: 190 / progress: Training / epsilon: 0.186943999992248 / score: 717.6356971263885\n",
      "step: 867917 / episode: 191 / progress: Training / epsilon: 0.18208399999224315 / score: 898.8061016723514\n",
      "step: 872881 / episode: 192 / progress: Training / epsilon: 0.17711999999223818 / score: 834.0883141085505\n",
      "step: 876245 / episode: 193 / progress: Training / epsilon: 0.17375599999223482 / score: 211.38349384069443\n",
      "step: 877449 / episode: 194 / progress: Training / epsilon: 0.1725519999922336 / score: 215.97805659472942\n",
      "step: 879038 / episode: 195 / progress: Training / epsilon: 0.17096299999223202 / score: 187.99624639749527\n",
      "step: 884139 / episode: 196 / progress: Training / epsilon: 0.16586199999222692 / score: 687.5026628375053\n",
      "step: 888526 / episode: 197 / progress: Training / epsilon: 0.16147499999222253 / score: 1600.2353341802955\n",
      "step: 893496 / episode: 198 / progress: Training / epsilon: 0.15650499999221756 / score: 807.809848099947\n",
      "step: 898696 / episode: 199 / progress: Training / epsilon: 0.15130499999221236 / score: 316.61354380100965\n",
      "step: 904049 / episode: 200 / progress: Training / epsilon: 0.145951999992207 / score: 448.52490527927876\n",
      "step: 909477 / episode: 201 / progress: Training / epsilon: 0.14052399999220158 / score: 272.09585766494274\n",
      "step: 914542 / episode: 202 / progress: Training / epsilon: 0.13545899999219652 / score: 691.2692175507545\n",
      "step: 919710 / episode: 203 / progress: Training / epsilon: 0.13029099999219135 / score: 578.9591406732798\n",
      "step: 924823 / episode: 204 / progress: Training / epsilon: 0.12517799999218623 / score: 621.0330762565136\n",
      "step: 929625 / episode: 205 / progress: Training / epsilon: 0.12037599999218143 / score: 991.9229993000627\n",
      "step: 935004 / episode: 206 / progress: Training / epsilon: 0.11499699999217605 / score: 342.90181101858616\n",
      "step: 939724 / episode: 207 / progress: Training / epsilon: 0.11027699999217133 / score: 1071.3330979794264\n",
      "step: 944675 / episode: 208 / progress: Training / epsilon: 0.10532599999216638 / score: 828.3047458231449\n",
      "step: 949909 / episode: 209 / progress: Training / epsilon: 0.10009199999216115 / score: 562.5790904164314\n",
      "step: 954997 / episode: 210 / progress: Training / epsilon: 0.09999999999216105 / score: 739.3565165996552\n",
      "step: 959945 / episode: 211 / progress: Training / epsilon: 0.09999999999216105 / score: 857.7442300915718\n",
      "step: 965112 / episode: 212 / progress: Training / epsilon: 0.09999999999216105 / score: 565.5479309856892\n",
      "step: 970435 / episode: 213 / progress: Training / epsilon: 0.09999999999216105 / score: 388.87497621774673\n",
      "step: 975665 / episode: 214 / progress: Training / epsilon: 0.09999999999216105 / score: 615.6862560808659\n",
      "step: 980784 / episode: 215 / progress: Training / epsilon: 0.09999999999216105 / score: 726.776097856462\n",
      "step: 985636 / episode: 216 / progress: Training / epsilon: 0.09999999999216105 / score: 1004.9993119612336\n",
      "step: 990843 / episode: 217 / progress: Training / epsilon: 0.09999999999216105 / score: 546.1061335653067\n",
      "step: 996268 / episode: 218 / progress: Training / epsilon: 0.09999999999216105 / score: 282.47585940361023\n",
      "step: 1001391 / episode: 219 / progress: Training / epsilon: 0.09999999999216105 / score: 602.6415996551514\n",
      "step: 1006345 / episode: 220 / progress: Training / epsilon: 0.09999999999216105 / score: 812.188400156796\n",
      "step: 1011518 / episode: 221 / progress: Training / epsilon: 0.09999999999216105 / score: 566.0263195633888\n",
      "step: 1016614 / episode: 222 / progress: Training / epsilon: 0.09999999999216105 / score: 751.8689822554588\n",
      "step: 1021558 / episode: 223 / progress: Training / epsilon: 0.09999999999216105 / score: 820.8184928521514\n",
      "step: 1026859 / episode: 224 / progress: Training / epsilon: 0.09999999999216105 / score: 428.3750340938568\n",
      "step: 1031834 / episode: 225 / progress: Training / epsilon: 0.09999999999216105 / score: 838.5114108026028\n",
      "step: 1036874 / episode: 226 / progress: Training / epsilon: 0.09999999999216105 / score: 718.3980541601777\n",
      "step: 1041907 / episode: 227 / progress: Training / epsilon: 0.09999999999216105 / score: 732.3099633604288\n",
      "step: 1047341 / episode: 228 / progress: Training / epsilon: 0.09999999999216105 / score: 297.49672170728445\n",
      "Model saved in file: ../saved_networks/2018-08-02_14_12_DDuelingDQN_both/model.ckpt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b5b107961e0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Select Actions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservation_stack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_stack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEpsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0maction_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-678b3a429437>\u001b[0m in \u001b[0;36mselect_action\u001b[1;34m(progress, sess, observation_stack, state_stack, Epsilon)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;31m# Max Q action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mQ_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx_image\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mobservation_stack\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_sensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstate_stack\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mNum_action\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "check_plot = 0\n",
    "\n",
    "# Training & Testing\n",
    "while True:\n",
    "   \n",
    "    # Get Progress, train mode\n",
    "    progress, train_mode, Epsilon  = get_progress(step, Epsilon)\n",
    "    \n",
    "    # Select Actions \n",
    "    action, Q_value = select_action(progress, sess, observation_stack, state_stack, Epsilon)\n",
    "    action_in = [np.argmax(action)]\n",
    "    \n",
    "    # Get information for plotting\n",
    "    vehicle_speed  = 100 * env_info.vector_observations[0][-8]\n",
    "    num_overtake   = env_info.vector_observations[0][-7]\n",
    "    num_lanechange = env_info.vector_observations[0][-6]\n",
    "    \n",
    "    # Get information for update\n",
    "    env_info = env.step(action_in)[default_brain]\n",
    "\n",
    "    next_observation_stack, observation_set, next_state_stack, state_set = resize_input(env_info, observation_set, state_set) \n",
    "    reward = env_info.rewards[0]\n",
    "    terminal = env_info.local_done[0]\n",
    "    \n",
    "    if progress == 'Training':\n",
    "        # Train!! \n",
    "        train(Replay_memory, sess, step)\n",
    "\n",
    "        # Save the variables to disk.\n",
    "        if step == Num_start_training + Num_training:\n",
    "            save_path = saver.save(sess, '../saved_networks/' + date_time + '_' + algorithm + '_both' + \"/model.ckpt\")\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "    # If progress is finished -> close! \n",
    "    if progress == 'Finished':\n",
    "        print('Finished!!')\n",
    "        env.close()\n",
    "        break\n",
    "        \n",
    "    Replay_memory = Experience_Replay(progress, \n",
    "                                      Replay_memory, \n",
    "                                      observation_stack, \n",
    "                                      state_stack,\n",
    "                                      action, \n",
    "                                      reward, \n",
    "                                      next_observation_stack,\n",
    "                                      next_state_stack,\n",
    "                                      terminal)\n",
    "    \n",
    "    # Update information\n",
    "    step += 1\n",
    "    score += reward\n",
    "    step_per_episode += 1\n",
    "    \n",
    "    observation_stack = next_observation_stack\n",
    "    state_stack = next_state_stack\n",
    "    \n",
    "    # Update tensorboard\n",
    "    if progress != 'Observing':\n",
    "        speed_list.append(vehicle_speed)\n",
    "        \n",
    "        if episode % Num_plot_episode == 0 and check_plot == 1 and episode != 0:\n",
    "            avg_speed      = sum(speed_list) / len(speed_list)\n",
    "            avg_overtake   = sum(overtake_list) / len(overtake_list)\n",
    "            avg_lanechange = sum(lanechange_list) / len(lanechange_list)\n",
    "            \n",
    "            tensorboard_info = [avg_speed, avg_overtake, avg_lanechange]\n",
    "            for i in range(len(tensorboard_info)):\n",
    "                sess.run(update_ops[i], feed_dict = {summary_placeholders[i]: float(tensorboard_info[i])})\n",
    "            summary_str = sess.run(summary_op)\n",
    "            summary_writer.add_summary(summary_str, step)\n",
    "            score_board = 0\n",
    "            \n",
    "            speed_list = []\n",
    "            overtake_list = []\n",
    "            lanechange_list = []\n",
    "\n",
    "            check_plot = 0\n",
    "            \n",
    "    # If terminal is True\n",
    "    if terminal == True:\n",
    "        # Print informations\n",
    "        print('step: ' + str(step) + ' / '  + 'episode: ' + str(episode) + ' / ' + 'progress: ' + progress  + ' / ' + 'epsilon: ' + str(Epsilon)  +' / ' + 'score: ' + str(score))\n",
    "\n",
    "        check_plot = 1\n",
    "\n",
    "        if progress != 'Observing':\n",
    "            episode += 1\n",
    "            \n",
    "            score_board += score\n",
    "            overtake_list.append(num_overtake)\n",
    "            lanechange_list.append(num_lanechange)\n",
    "        \n",
    "            \n",
    "        score = 0\n",
    "        step_per_episode = 0\n",
    "\n",
    "        # Initialize game state\n",
    "        env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "        observation_stack, observation_set, state_stack, state_set = input_initialization(env_info)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
