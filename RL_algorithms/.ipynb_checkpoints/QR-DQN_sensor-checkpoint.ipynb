{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRL Based Self Driving Car Control (Sensor)\n",
    "\n",
    "## Distributional Reinforcement Learning with Quantile Regression\n",
    "\n",
    "This notebook is DRL code for the project 'DRL based Self Driving Car Control' <br>\n",
    "This version uses **Sensor data from LIDAR** as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Q\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment path\n",
    "\n",
    "Be sure to set `env_name` to the name of the Unity environment file you want to launch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"../windows/windows\" # Name of the Unity environment to launch\n",
    "train_mode = True # Whether to run the environment in training or inference mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the environment\n",
    "`UnityEnvironment` launches and begins communication with the environment when instantiated.\n",
    "\n",
    "Environments contain _brains_ which are responsible for deciding the actions of their associated _agents_. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: Brain\n",
      "        Number of Visual Observations (per agent): 1\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 373\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 5\n",
      "        Vector Action descriptions: , , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: Brain\n",
      "        Number of Visual Observations (per agent): 1\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 373\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 5\n",
      "        Vector Action descriptions: , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_name)\n",
    "\n",
    "# Examine environment parameters\n",
    "print(str(env))\n",
    "\n",
    "# Set the default brain to work with\n",
    "default_brain = env.brain_names[0]\n",
    "brain = env.brains[default_brain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the observation and state spaces\n",
    "We can reset the environment to be provided with an initial set of observations and states for all the agents within the environment. In ML-Agents, _states_ refer to a vector of variables corresponding to relevant aspects of the environment for an agent. Likewise, _observations_ refer to a set of relevant pixel-wise visuals for an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor data (LIDAR): \n",
      "[  1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   0.9755246    0.91600198   0.86357307   0.81705666   0.77551937\n",
      "   0.73821479   0.70453942   0.67399871   0.64618438   0.62075633\n",
      "   0.59742886   0.57596022   0.5561446    0.53780544   0.52079082\n",
      "   0.50496876   0.49022466   0.47645816   0.46358114   0.45151567\n",
      "   0.44019303   0.42955208   0.41953811   0.41010255   0.40120158\n",
      "   0.39279586   0.38485005   0.37733197   0.37021253   0.36346549\n",
      "   0.35706681   0.35099453   0.34522879   0.33975118   0.33454502\n",
      "   0.32959491   0.32488668   0.32040724   0.31614468   0.31208783\n",
      "   0.30822647   0.30455115   0.30105308   0.29772413   0.29455668\n",
      "   0.29154381   0.288679     0.28595623   0.28336981   0.2809146\n",
      "   0.27858567   0.27637851   0.27428898   0.27231315   0.27044734\n",
      "   0.26868826   0.26703268   0.26547778   0.26402083   0.26265934\n",
      "   0.26139107   0.26021382   0.25912577   0.25812501   0.25721005\n",
      "   0.25637937   0.25563163   0.25496569   0.25438049   0.25387514\n",
      "   0.25344881   0.25310093   0.25283089   0.25263828   0.25252286\n",
      "   0.25248438   0.25252286   0.25263828   0.25283089   0.25310093\n",
      "   0.25344881   0.25387514   0.25438049   0.25496572   0.25563163\n",
      "   0.25637937   0.25721005   0.25812504   0.25912577   0.26021382\n",
      "   0.2613911    0.26265937   0.26402086   0.26547781   0.26703271\n",
      "   0.26868829   0.27044743   0.27231318   0.27428904   0.27637854\n",
      "   0.27858567   0.28091457   0.28336984   0.2859562    0.28867906\n",
      "   0.29154381   0.29455668   0.29772413   0.30105308   0.30455118\n",
      "   0.3082265    0.3120878    0.31614468   0.32040721   0.32488671\n",
      "   0.32959491   0.33454508   0.33975121   0.34522879   0.35099462\n",
      "   0.35706681   0.36346555   0.37021261   0.37733203   0.38485011\n",
      "   0.39279595   0.40120178   0.41010267   0.4195382    0.42955217\n",
      "   0.44019303   0.45151576   0.46358114   0.47645825   0.49022475\n",
      "   0.50496876   0.52079082   0.53780544   0.8056162    0.79863602\n",
      "   0.79201484   0.78574008   0.77979958   0.7741822    0.7688778\n",
      "   0.76387662   0.75916994   0.7547493    0.75060725   0.74673665\n",
      "   0.7431308    0.739784     0.73669058   0.73384559   0.73124427\n",
      "   0.72888267   0.72675687   0.72486359   0.7231999    0.72176319\n",
      "   0.72055119   0.71956211   0.71879435   0.71824682   0.71791863\n",
      "   0.71780932   1.           0.73828739   0.73885024   0.7396394\n",
      "   0.74065602   0.74190187   0.74337864   0.74508876   0.74703485\n",
      "   0.72526538   0.72761542   0.73020375   0.73303467   0.73611271\n",
      "   0.73944294   0.74303085   0.74688226   0.7510038    0.75540245\n",
      "   0.76008582   0.76506215   0.77034026   0.77592981   0.78184074\n",
      "   0.78808439   0.79467267   0.80161822   0.80893487   0.52898562\n",
      "   0.51291454   0.49793857   0.48395553   0.47087574   0.45862055\n",
      "   0.44711965   0.4363113    0.42613983   0.41655573   0.40751475\n",
      "   0.399611     0.38823813   0.3806538    0.3734718    0.3666653\n",
      "   0.36021024   0.35408458   0.34826803   0.34274226   0.33749029\n",
      "   0.33249652   0.32774684   0.32322803   0.31892782   0.31483531\n",
      "   0.31093997   0.30723232   0.30370349   0.30034512   0.29714981\n",
      "   0.29411048   0.29122046   0.2884737    0.28881615   0.29910675\n",
      "   0.31025571   0.32237002   0.33557519   0.35001999   0.36588031\n",
      "   0.38336843   0.40274113   0.42431211   0.44846955   0.24207902\n",
      "   0.24091013   0.2398251    0.2388223    0.25435534   0.71093136\n",
      "   0.70863533   0.7065686    0.70472795   0.70311046   0.70171368\n",
      "   0.70053536   0.69957376   0.69882733   0.698295     0.69797587\n",
      "   0.6978696    1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   0.46766621   0.39589906   0.38227844   0.36967266   0.35797733\n",
      "   0.34710175   0.33696681   0.32750422   0.3186529    0.31535536\n",
      "   0.31916118   0.32315952   0.32736021   0.33177397   0.33641231\n",
      "   0.34128767   0.34641343   0.35180423   0.35747606   0.36344635\n",
      "   0.36973414   0.37635988   0.3833462    0.39071813   0.39850292\n",
      "   0.40673083   0.418935     0.41482678   0.42437106   0.43450052\n",
      "   0.44526401   0.45671701   0.46892133   0.48194665   0.49587208\n",
      "   0.51078594   0.59662944   0.57361192   0.57813853   0.58058214\n",
      "   0.57576889   0.57120734   0.58600146   0.61122501   0.63892192\n",
      "   0.66946077   0.78772271   0.8299135    0.89621913   0.95063126\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   0.           0.           0.           1.           0.\n",
      "   0.60000002   0.           0.           0.           0.\n",
      "   0.           0.         -10.        ]\n",
      "Image data (Front Camera): \n",
      "{}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reset the environment\n",
    "env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "\n",
    "# Examine the state space for the default brain\n",
    "print(\"Sensor data (LIDAR): \\n{}\".format(env_info.vector_observations[0]))\n",
    "\n",
    "# Examine the observation space for the default brain\n",
    "Num_obs = len(env_info.visual_observations)\n",
    "\n",
    "print(\"Image data (Front Camera): \\n{}\")\n",
    "if Num_obs > 1:\n",
    "    f, axarr = plt.subplots(1, Num_obs, figsize=(20,10))\n",
    "    for i, observation in enumerate(env_info.visual_observations):\n",
    "        if observation.shape[3] == 3:\n",
    "            axarr[i].imshow(observation[0,:,:,:])\n",
    "            axarr[i].axis('off')\n",
    "        else:\n",
    "            axarr[i].imshow(observation[0,:,:,0])\n",
    "            axarr[i].axis('off')\n",
    "else:\n",
    "    f, axarr = plt.subplots(1, Num_obs)\n",
    "    for i, observation in enumerate(env_info.visual_observations):\n",
    "        if observation.shape[3] == 3:\n",
    "            axarr.imshow(observation[0,:,:,:])\n",
    "            axarr.axis('off')\n",
    "        else:\n",
    "            axarr.imshow(observation[0,:,:,0])\n",
    "            axarr.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "algorithm = 'QR-DQN'\n",
    "Num_action = brain.vector_action_space_size\n",
    "\n",
    "# QR-DQN Parameter\n",
    "Num_quantile = 51\n",
    "        \n",
    "# parameter for DQN\n",
    "Num_replay_memory = 100000\n",
    "Num_start_training = 50000\n",
    "Num_training = 1000000\n",
    "Num_update = 10000\n",
    "Num_batch = 32\n",
    "Num_test = 100000\n",
    "Num_skipFrame = 4\n",
    "Num_stackFrame = 4\n",
    "Num_colorChannel = 1\n",
    "\n",
    "Epsilon = 1.0\n",
    "Final_epsilon = 0.1\n",
    "Gamma = 0.99\n",
    "Learning_rate = 0.00005\n",
    "\n",
    "# Parameter for LSTM\n",
    "Num_dataSize = 366\n",
    "Num_cellState = 512\n",
    "\n",
    "# Parameters for network\n",
    "img_size = 80\n",
    "sensor_size = 360\n",
    "\n",
    "first_dense  = [Num_cellState, 512]\n",
    "second_dense = [first_dense[1], Num_action * Num_quantile]\n",
    "\n",
    "# Path of the network model\n",
    "load_path = '../saved_networks/2018-09-12_0_19_QR-DQN_sensor/model.ckpt'\n",
    "\n",
    "# Parameters for session\n",
    "Num_plot_episode = 5\n",
    "Num_step_save = 50000\n",
    "\n",
    "GPU_fraction = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(xavier_initializer(shape))\n",
    "\n",
    "def bias_variable(shape):\n",
    "\treturn tf.Variable(xavier_initializer(shape))\n",
    "\n",
    "# Xavier Weights initializer\n",
    "def xavier_initializer(shape):\n",
    "\tdim_sum = np.sum(shape)\n",
    "\tif len(shape) == 1:\n",
    "\t\tdim_sum += 1\n",
    "\tbound = np.sqrt(2.0 / dim_sum)\n",
    "\treturn tf.random_uniform(shape, minval=-bound, maxval=bound)\n",
    "\n",
    "# Assign network variables to target network\n",
    "def assign_network_to_target():\n",
    "\t# Get trainable variables\n",
    "\ttrainable_variables = tf.trainable_variables()\n",
    "\t# network lstm variables\n",
    "\ttrainable_variables_network = [var for var in trainable_variables if var.name.startswith('network')]\n",
    "\n",
    "\t# target lstm variables\n",
    "\ttrainable_variables_target = [var for var in trainable_variables if var.name.startswith('target')]\n",
    "\n",
    "    # assign network variables to target network\n",
    "\tfor i in range(len(trainable_variables_network)):\n",
    "\t\tsess.run(tf.assign(trainable_variables_target[i], trainable_variables_network[i]))\n",
    "\n",
    "# Code for tensorboard\n",
    "def setup_summary():\n",
    "    episode_speed      = tf.Variable(0.)\n",
    "    episode_overtake   = tf.Variable(0.)\n",
    "    episode_lanechange = tf.Variable(0.)\n",
    "\n",
    "    tf.summary.scalar('Average_Speed/' + str(Num_plot_episode) + 'episodes', episode_speed)\n",
    "    tf.summary.scalar('Average_overtake/' + str(Num_plot_episode) + 'episodes', episode_overtake)\n",
    "    tf.summary.scalar('Average_lanechange/' + str(Num_plot_episode) + 'episodes', episode_lanechange)\n",
    "\n",
    "    summary_vars = [episode_speed, episode_overtake, episode_lanechange]\n",
    "    summary_placeholders = [tf.placeholder(tf.float32) for _ in range(len(summary_vars))]\n",
    "    update_ops = [summary_vars[i].assign(summary_placeholders[i]) for i in range(len(summary_vars))]\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    return summary_placeholders, update_ops, summary_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x_sensor = tf.placeholder(tf.float32, shape = [None, Num_stackFrame, Num_dataSize])\n",
    "x_unstack = tf.unstack(x_sensor, axis = 1)\n",
    "\n",
    "with tf.variable_scope('network'):\n",
    "\n",
    "    # LSTM cell\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units = Num_cellState)            \n",
    "    rnn_out, rnn_state = tf.nn.static_rnn(inputs = x_unstack, cell = cell, dtype = tf.float32)\n",
    "    \n",
    "    # Densely connect layer variables\n",
    "    w_fc1 = weight_variable(first_dense)\n",
    "    b_fc1 = bias_variable([first_dense[1]])\n",
    "\n",
    "    w_fc2 = weight_variable(second_dense)\n",
    "    b_fc2 = bias_variable([second_dense[1]])\n",
    "    \n",
    "    \n",
    "# Network\n",
    "rnn_out = rnn_out[-1]\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(rnn_out, w_fc1)+b_fc1)\n",
    "\n",
    "# Get Q value for each action\n",
    "logits = tf.matmul(h_fc1, w_fc2) + b_fc2\n",
    "logits_reshape = tf.reshape(logits, [-1, Num_action, Num_quantile])\n",
    "Q_action = tf.reduce_sum(tf.multiply(1/Num_quantile, logits_reshape), axis = 2)\n",
    "\n",
    "with tf.variable_scope('target'):\n",
    "    # LSTM cell\n",
    "    cell_target = tf.contrib.rnn.BasicLSTMCell(num_units = Num_cellState)            \n",
    "    rnn_out_target, rnn_state_target = tf.nn.static_rnn(inputs = x_unstack, cell = cell_target, dtype = tf.float32)\n",
    "\n",
    "    # Densely connect layer variables target\n",
    "    w_fc1_target = weight_variable(first_dense)\n",
    "    b_fc1_target = bias_variable([first_dense[1]])\n",
    "\n",
    "    w_fc2_target = weight_variable(second_dense)\n",
    "    b_fc2_target = bias_variable([second_dense[1]])\n",
    "    \n",
    "# Target Network\n",
    "rnn_out_target = rnn_out_target[-1]\n",
    "\n",
    "h_fc1_target  = tf.nn.relu(tf.matmul(rnn_out_target, w_fc1_target)+b_fc1_target)\n",
    "\n",
    "# Get Q value for each action\n",
    "logits_target = tf.matmul(h_fc1_target, w_fc2_target) + b_fc2_target\n",
    "logits_reshape_target = tf.reshape(logits_target, [-1, Num_action, Num_quantile])\n",
    "Q_action_target = tf.reduce_sum(tf.multiply(1/Num_quantile, logits_reshape_target), axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and Train\n",
    "theta_loss = tf.placeholder(tf.float32, shape = [None, Num_quantile])\n",
    "action_binary_loss = tf.placeholder(tf.float32, shape = [None, Num_action, Num_quantile])\n",
    "\n",
    "# Get valid logits \n",
    "logit_valid = tf.multiply(logits_reshape, action_binary_loss)\n",
    "logit_valid_nonzero = tf.reduce_sum(logit_valid, axis = 1)\n",
    "\n",
    "# Stack i and j\n",
    "theta_loss_tile = tf.tile(tf.expand_dims(theta_loss, axis=2), [1, 1, Num_quantile])\n",
    "logit_valid_tile = tf.tile(tf.expand_dims(logit_valid_nonzero, axis=1), [1, Num_quantile, 1])\n",
    "\n",
    "error_loss = theta_loss_tile - logit_valid_tile\n",
    "\n",
    "# Get Huber loss\n",
    "Huber_loss = tf.losses.huber_loss(theta_loss_tile, logit_valid_tile, reduction = tf.losses.Reduction.NONE)\n",
    "\n",
    "# Get tau\n",
    "min_tau = 1/(2*Num_quantile)\n",
    "max_tau = (2*(Num_quantile-1)+3)/(2*Num_quantile)\n",
    "tau = tf.reshape (tf.range(min_tau, max_tau, 1/Num_quantile), [1, Num_quantile])\n",
    "inv_tau = 1.0 - tau \n",
    "\n",
    "# Get Loss\n",
    "Loss = tf.where(tf.less(error_loss, 0.0), inv_tau * Huber_loss, tau * Huber_loss)\n",
    "Loss = tf.reduce_mean(tf.reduce_sum(tf.reduce_mean(Loss, axis = 2), axis = 1))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate = Learning_rate, epsilon = 1e-02/Num_batch).minimize(Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize variables\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = GPU_fraction\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training or Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference? / Training?(1=Inference/2=Training): 2\n"
     ]
    }
   ],
   "source": [
    "# Load the file if the saved file exists\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# check_save = 1\n",
    "check_save = input('Inference? / Training?(1=Inference/2=Training): ')\n",
    "\n",
    "if check_save == '1':\n",
    "    # Directly start inference\n",
    "    Num_start_training = 0\n",
    "    Num_training = 0\n",
    "    \n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, load_path)\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "# date - hour - minute of training time\n",
    "date_time = str(datetime.date.today()) + '_' + str(datetime.datetime.now().hour) + '_' + str(datetime.datetime.now().minute)\n",
    "\n",
    "# Make folder for save data\n",
    "os.makedirs('../saved_networks/' + date_time + '_' + algorithm + '_sensor')\n",
    "\n",
    "# Summary for tensorboard\n",
    "summary_placeholders, update_ops, summary_op = setup_summary()\n",
    "summary_writer = tf.summary.FileWriter('../saved_networks/' + date_time + '_' + algorithm + '_sensor', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize input \n",
    "def state_initialization(env_info):    \n",
    "    state = env_info.vector_observations[0][:-7]\n",
    "\n",
    "    state_set = []\n",
    "\n",
    "    for i in range(Num_skipFrame * Num_stackFrame):\n",
    "        state_set.append(state)\n",
    "    \n",
    "    # Stack the frame according to the number of skipping and stacking frames using observation set\n",
    "    state_stack = np.zeros((Num_stackFrame, Num_dataSize))\n",
    "    for stack_frame in range(Num_stackFrame):\n",
    "        state_stack[(Num_stackFrame - 1) - stack_frame, :] = state_set[-1 - (Num_skipFrame * stack_frame)]\n",
    "\n",
    "    state_stack = np.uint8(state_stack)\n",
    "\n",
    "    return state_stack, state_set\n",
    "\n",
    "# Resize input information \n",
    "def resize_state(env_info, state_set):\n",
    "    state = env_info.vector_observations[0][:-7]\n",
    "\n",
    "    # Add state to the state_set\n",
    "    state_set.append(state)\n",
    "    \n",
    "    # Stack the frame according to the number of skipping and stacking frames using observation set\n",
    "    state_stack = np.zeros((Num_stackFrame, Num_dataSize))\n",
    "    for stack_frame in range(Num_stackFrame):\n",
    "        state_stack[(Num_stackFrame - 1) - stack_frame, :] = state_set[-1 - (Num_skipFrame * stack_frame)]\n",
    "        \n",
    "    del state_set[0]\n",
    "\n",
    "    state_stack = np.uint8(state_stack)\n",
    "    \n",
    "    return state_stack, state_set\n",
    "\n",
    "# Get progress according to the number of steps\n",
    "def get_progress(step, Epsilon):\n",
    "    if step <= Num_start_training:\n",
    "        # Observation\n",
    "        progress = 'Observing'\n",
    "        train_mode = True\n",
    "        Epsilon = 1\n",
    "    elif step <= Num_start_training + Num_training:\n",
    "        # Training\n",
    "        progress = 'Training'\n",
    "        train_mode = True\n",
    "        \n",
    "        # Decrease the epsilon value\n",
    "        if Epsilon > Final_epsilon:\n",
    "            Epsilon -= 1.0/Num_training\n",
    "    elif step < Num_start_training + Num_training + Num_test:\n",
    "        # Testing\n",
    "        progress = 'Testing'\n",
    "        train_mode = False\n",
    "        Epsilon = 0\n",
    "    else:\n",
    "        # Finished\n",
    "        progress = 'Finished'\n",
    "        train_mode = False\n",
    "        Epsilon = 0\n",
    "        \n",
    "    return progress, train_mode, Epsilon \n",
    "\n",
    "# Select action according to the progress of training\n",
    "def select_action(progress, sess, observation_stack, Epsilon):\n",
    "    if progress == \"Observing\":\n",
    "        # Random action \n",
    "        Q_value = 0\n",
    "        action = np.zeros([Num_action])\n",
    "        action[random.randint(0, Num_action - 1)] = 1.0\n",
    "    elif progress == \"Training\":\n",
    "        # if random value(0-1) is smaller than Epsilon, action is random. \n",
    "        # Otherwise, action is the one which has the max Q value\n",
    "        if random.random() < Epsilon:\n",
    "            Q_value = 0\n",
    "            action = np.zeros([Num_action])\n",
    "            action[random.randint(0, Num_action - 1)] = 1\n",
    "        else:\n",
    "            Q_value = Q_action.eval(feed_dict={x_sensor: [state_stack]})\n",
    "            action = np.zeros([Num_action])\n",
    "            action[np.argmax(Q_value)] = 1\n",
    "    else:\n",
    "        # Max Q action \n",
    "        Q_value = Q_action.eval(feed_dict={x_sensor: [state_stack]})\n",
    "        action = np.zeros([Num_action])\n",
    "        action[np.argmax(Q_value)] = 1\n",
    "        \n",
    "    return action, Q_value\n",
    "\n",
    "def train(Replay_memory, sess, step):\n",
    "    # Select minibatch\n",
    "    minibatch =  random.sample(Replay_memory, Num_batch)\n",
    "\n",
    "    # Save the each batch data\n",
    "    state_batch      = [batch[0] for batch in minibatch]\n",
    "    action_batch     = [batch[1] for batch in minibatch]\n",
    "    reward_batch     = [batch[2] for batch in minibatch]\n",
    "    state_next_batch = [batch[3] for batch in minibatch]\n",
    "    terminal_batch \t = [batch[4] for batch in minibatch]\n",
    "\n",
    "    # Update target network according to the Num_update value\n",
    "    if step % Num_update == 0:\n",
    "        assign_network_to_target()\n",
    "    \n",
    "    \n",
    "    # Get Target\n",
    "    Q_batch = Q_action.eval(feed_dict = {x_sensor: state_next_batch})\n",
    "    theta_batch = logits_reshape_target.eval(feed_dict = {x_sensor: state_next_batch})\n",
    "\n",
    "    theta_target = []\n",
    "\n",
    "    for i in range(len(minibatch)):\n",
    "        theta_target.append([])\n",
    "        for j in range(Num_quantile):\n",
    "            if terminal_batch[i] == True:\n",
    "                theta_target[i].append(reward_batch[i])\n",
    "            else:\n",
    "                theta_target[i].append(reward_batch[i] + Gamma * theta_batch[i, np.argmax(Q_batch[i]), j])\n",
    "\n",
    "    # Calculate action binary\n",
    "    action_binary = np.zeros([Num_batch, Num_action, Num_quantile])\n",
    "\n",
    "    for i in range(len(action_batch)):\n",
    "        action_batch_max = np.argmax(action_batch[i])\n",
    "        action_binary[i, action_batch_max, :] = 1\n",
    "\n",
    "    _, loss = sess.run([train_step, Loss],feed_dict = {x_sensor: state_batch,\n",
    "                                                       theta_loss: theta_target, \n",
    "                                                       action_binary_loss: action_binary})\n",
    "\n",
    "# Experience Replay \n",
    "def Experience_Replay(progress, Replay_memory, state_stack, action, reward, next_state_stack, terminal):\n",
    "    if progress != 'Testing':\n",
    "        # If length of replay memeory is more than the setting value then remove the first one\n",
    "        if len(Replay_memory) > Num_replay_memory:\n",
    "            del Replay_memory[0]\n",
    "\n",
    "        # Save experience to the Replay memory\n",
    "        Replay_memory.append([state_stack, action, reward, next_state_stack, terminal])\n",
    "    else:\n",
    "        # Empty the replay memory if testing\n",
    "        Replay_memory = []\n",
    "    \n",
    "    return Replay_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "Replay_memory = []\n",
    "\n",
    "step = 1\n",
    "score = 0\n",
    "score_board = 0\n",
    "\n",
    "episode = 0\n",
    "step_per_episode = 0\n",
    "\n",
    "speed_list = []\n",
    "overtake_list = []\n",
    "lanechange_list = []\n",
    "\n",
    "train_mode = True\n",
    "env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "\n",
    "state_stack, state_set = state_initialization(env_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 862 / episode: 0 / progress: Observing / epsilon: 1 / score: 325.32984664291143\n",
      "step: 3899 / episode: 0 / progress: Observing / epsilon: 1 / score: 994.9806437194347\n",
      "step: 8404 / episode: 0 / progress: Observing / epsilon: 1 / score: 1787.8040898144245\n",
      "step: 9463 / episode: 0 / progress: Observing / epsilon: 1 / score: 507.43336346000433\n",
      "step: 13927 / episode: 0 / progress: Observing / epsilon: 1 / score: 1803.0707785487175\n",
      "step: 15602 / episode: 0 / progress: Observing / epsilon: 1 / score: 672.7394289523363\n",
      "step: 18779 / episode: 0 / progress: Observing / epsilon: 1 / score: 1176.567547813058\n",
      "step: 23573 / episode: 0 / progress: Observing / epsilon: 1 / score: 1456.7774658501148\n",
      "step: 28500 / episode: 0 / progress: Observing / epsilon: 1 / score: 1326.2779063731432\n",
      "step: 30847 / episode: 0 / progress: Observing / epsilon: 1 / score: 819.0524793043733\n",
      "step: 35000 / episode: 0 / progress: Observing / epsilon: 1 / score: 1623.0093853026628\n",
      "step: 35820 / episode: 0 / progress: Observing / epsilon: 1 / score: 306.80283684283495\n",
      "step: 37784 / episode: 0 / progress: Observing / epsilon: 1 / score: 450.9121874347329\n",
      "step: 42543 / episode: 0 / progress: Observing / epsilon: 1 / score: 1503.0451498776674\n",
      "step: 47361 / episode: 0 / progress: Observing / epsilon: 1 / score: 1451.3451027199626\n",
      "step: 51928 / episode: 0 / progress: Training / epsilon: 0.9980729999999446 / score: 1681.761196769774\n",
      "step: 56703 / episode: 1 / progress: Training / epsilon: 0.9932979999998073 / score: 1354.760536506772\n",
      "step: 58809 / episode: 2 / progress: Training / epsilon: 0.9911919999997467 / score: 713.7494749575853\n",
      "step: 63280 / episode: 3 / progress: Training / epsilon: 0.9867209999996182 / score: 1816.6550354212523\n",
      "step: 67730 / episode: 4 / progress: Training / epsilon: 0.9822709999994902 / score: 1847.5363826528192\n",
      "step: 69946 / episode: 5 / progress: Training / epsilon: 0.9800549999994265 / score: 1266.5824803858995\n",
      "step: 74538 / episode: 6 / progress: Training / epsilon: 0.9754629999992944 / score: 1678.5795219317079\n",
      "step: 79080 / episode: 7 / progress: Training / epsilon: 0.9709209999991638 / score: 1724.1466423645616\n",
      "step: 83658 / episode: 8 / progress: Training / epsilon: 0.9663429999990322 / score: 1678.8079008460045\n",
      "step: 88027 / episode: 9 / progress: Training / epsilon: 0.9619739999989065 / score: 1918.234124392271\n",
      "step: 92305 / episode: 10 / progress: Training / epsilon: 0.9576959999987835 / score: 2012.6006842553616\n",
      "step: 96841 / episode: 11 / progress: Training / epsilon: 0.9531599999986531 / score: 1744.9502138495445\n",
      "step: 101166 / episode: 12 / progress: Training / epsilon: 0.9488349999985287 / score: 1968.0455450117588\n",
      "step: 105549 / episode: 13 / progress: Training / epsilon: 0.9444519999984027 / score: 1902.016644217074\n",
      "step: 106157 / episode: 14 / progress: Training / epsilon: 0.9438439999983852 / score: 320.9473271816969\n",
      "step: 108944 / episode: 15 / progress: Training / epsilon: 0.941056999998305 / score: 1104.039517402649\n",
      "step: 110206 / episode: 16 / progress: Training / epsilon: 0.9397949999982688 / score: 549.469959653914\n",
      "step: 115048 / episode: 17 / progress: Training / epsilon: 0.9349529999981295 / score: 1445.9584759995341\n",
      "step: 117431 / episode: 18 / progress: Training / epsilon: 0.932569999998061 / score: 1145.0372749119997\n",
      "step: 121826 / episode: 19 / progress: Training / epsilon: 0.9281749999979346 / score: 1889.2764871641994\n",
      "step: 126368 / episode: 20 / progress: Training / epsilon: 0.923632999997804 / score: 1767.1459734141827\n",
      "step: 131269 / episode: 21 / progress: Training / epsilon: 0.9187319999976631 / score: 1357.6393020749092\n",
      "step: 135555 / episode: 22 / progress: Training / epsilon: 0.9144459999975398 / score: 2030.939159579575\n",
      "step: 139930 / episode: 23 / progress: Training / epsilon: 0.910070999997414 / score: 1920.059646435082\n",
      "step: 141193 / episode: 24 / progress: Training / epsilon: 0.9088079999973777 / score: 493.5376776829362\n",
      "step: 142046 / episode: 25 / progress: Training / epsilon: 0.9079549999973532 / score: 392.6098663806915\n",
      "step: 142263 / episode: 26 / progress: Training / epsilon: 0.907737999997347 / score: 78.49619244784117\n",
      "step: 146830 / episode: 27 / progress: Training / epsilon: 0.9031709999972156 / score: 1695.8942581042647\n",
      "step: 151027 / episode: 28 / progress: Training / epsilon: 0.8989739999970949 / score: 2148.711537182331\n",
      "step: 154276 / episode: 29 / progress: Training / epsilon: 0.8957249999970015 / score: 1249.1878741011024\n",
      "step: 158566 / episode: 30 / progress: Training / epsilon: 0.8914349999968781 / score: 2024.4498470276594\n",
      "step: 163132 / episode: 31 / progress: Training / epsilon: 0.8868689999967468 / score: 1734.6370058059692\n",
      "step: 163637 / episode: 32 / progress: Training / epsilon: 0.8863639999967323 / score: 315.0593423768878\n",
      "step: 164208 / episode: 33 / progress: Training / epsilon: 0.8857929999967159 / score: 380.01803378015757\n",
      "step: 165924 / episode: 34 / progress: Training / epsilon: 0.8840769999966666 / score: 900.5572319105268\n",
      "step: 170433 / episode: 35 / progress: Training / epsilon: 0.8795679999965369 / score: 1793.6558162495494\n",
      "step: 172001 / episode: 36 / progress: Training / epsilon: 0.8779999999964918 / score: 567.2721333801746\n",
      "step: 174767 / episode: 37 / progress: Training / epsilon: 0.8752339999964123 / score: 1287.5122601985931\n",
      "step: 175278 / episode: 38 / progress: Training / epsilon: 0.8747229999963976 / score: 231.2425328269601\n",
      "step: 179760 / episode: 39 / progress: Training / epsilon: 0.8702409999962687 / score: 1818.3521374613047\n",
      "step: 184033 / episode: 40 / progress: Training / epsilon: 0.8659679999961458 / score: 2034.293531537056\n",
      "step: 188001 / episode: 41 / progress: Training / epsilon: 0.8619999999960317 / score: 2363.493379049003\n",
      "step: 191638 / episode: 42 / progress: Training / epsilon: 0.8583629999959271 / score: 1704.0964181795716\n",
      "step: 195899 / episode: 43 / progress: Training / epsilon: 0.8541019999958046 / score: 2048.6321639046073\n",
      "step: 200042 / episode: 44 / progress: Training / epsilon: 0.8499589999956855 / score: 2184.257388845086\n",
      "step: 202151 / episode: 45 / progress: Training / epsilon: 0.8478499999956248 / score: 863.4193268567324\n",
      "step: 206078 / episode: 46 / progress: Training / epsilon: 0.8439229999955119 / score: 2401.0401434376836\n",
      "step: 210336 / episode: 47 / progress: Training / epsilon: 0.8396649999953895 / score: 2052.410575337708\n",
      "step: 214715 / episode: 48 / progress: Training / epsilon: 0.8352859999952635 / score: 1941.331893414259\n",
      "step: 218876 / episode: 49 / progress: Training / epsilon: 0.8311249999951439 / score: 2167.0376710370183\n",
      "step: 223072 / episode: 50 / progress: Training / epsilon: 0.8269289999950232 / score: 2119.7892113775015\n",
      "step: 226411 / episode: 51 / progress: Training / epsilon: 0.8235899999949272 / score: 1497.8957772180438\n",
      "step: 228540 / episode: 52 / progress: Training / epsilon: 0.821460999994866 / score: 1470.36537040025\n",
      "step: 232755 / episode: 53 / progress: Training / epsilon: 0.8172459999947448 / score: 2101.33157274127\n",
      "step: 236821 / episode: 54 / progress: Training / epsilon: 0.8131799999946279 / score: 2249.28208386153\n",
      "step: 237146 / episode: 55 / progress: Training / epsilon: 0.8128549999946185 / score: 157.99999533593655\n",
      "step: 240930 / episode: 56 / progress: Training / epsilon: 0.8090709999945097 / score: 1024.4891000837088\n",
      "step: 245049 / episode: 57 / progress: Training / epsilon: 0.8049519999943913 / score: 2210.1255318671465\n",
      "step: 245411 / episode: 58 / progress: Training / epsilon: 0.8045899999943809 / score: 183.12061677128077\n",
      "step: 249824 / episode: 59 / progress: Training / epsilon: 0.800176999994254 / score: 1881.8433318212628\n",
      "step: 253928 / episode: 60 / progress: Training / epsilon: 0.7960729999941359 / score: 2246.954505689442\n",
      "step: 256942 / episode: 61 / progress: Training / epsilon: 0.7930589999940493 / score: 1679.0014762058854\n",
      "step: 261238 / episode: 62 / progress: Training / epsilon: 0.7887629999939257 / score: 2024.787743397057\n",
      "step: 264153 / episode: 63 / progress: Training / epsilon: 0.7858479999938419 / score: 1778.2930383756757\n",
      "step: 268188 / episode: 64 / progress: Training / epsilon: 0.7818129999937259 / score: 2297.155281238258\n",
      "step: 271939 / episode: 65 / progress: Training / epsilon: 0.778061999993618 / score: 1531.8270955607295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 276090 / episode: 66 / progress: Training / epsilon: 0.7739109999934987 / score: 2191.4319356307387\n",
      "step: 277390 / episode: 67 / progress: Training / epsilon: 0.7726109999934613 / score: 644.1897202953696\n",
      "step: 281748 / episode: 68 / progress: Training / epsilon: 0.768252999993336 / score: 1963.0120188593864\n",
      "step: 286761 / episode: 69 / progress: Training / epsilon: 0.7632399999931918 / score: 1267.9587285518646\n",
      "step: 291170 / episode: 70 / progress: Training / epsilon: 0.758830999993065 / score: 1906.939151726663\n",
      "step: 294989 / episode: 71 / progress: Training / epsilon: 0.7550119999929552 / score: 1719.8135519102216\n",
      "step: 299544 / episode: 72 / progress: Training / epsilon: 0.7504569999928242 / score: 1739.878077097237\n",
      "step: 301491 / episode: 73 / progress: Training / epsilon: 0.7485099999927682 / score: 1253.6979319751263\n",
      "step: 305732 / episode: 74 / progress: Training / epsilon: 0.7442689999926463 / score: 2088.17047393322\n",
      "step: 309895 / episode: 75 / progress: Training / epsilon: 0.7401059999925266 / score: 2152.9898695126176\n",
      "step: 311734 / episode: 76 / progress: Training / epsilon: 0.7382669999924737 / score: 956.4172418639064\n",
      "step: 313376 / episode: 77 / progress: Training / epsilon: 0.7366249999924265 / score: 465.42261146754026\n",
      "step: 317524 / episode: 78 / progress: Training / epsilon: 0.7324769999923072 / score: 2180.8822543621063\n",
      "step: 321401 / episode: 79 / progress: Training / epsilon: 0.7285999999921957 / score: 2473.165220424533\n",
      "step: 324804 / episode: 80 / progress: Training / epsilon: 0.7251969999920979 / score: 1705.3604884296656\n",
      "step: 329030 / episode: 81 / progress: Training / epsilon: 0.7209709999919763 / score: 2094.7405717372894\n",
      "step: 333041 / episode: 82 / progress: Training / epsilon: 0.716959999991861 / score: 2329.26283005625\n",
      "step: 335160 / episode: 83 / progress: Training / epsilon: 0.7148409999918001 / score: 1301.2553619369864\n",
      "step: 338018 / episode: 84 / progress: Training / epsilon: 0.7119829999917179 / score: 1527.258356615901\n",
      "step: 342205 / episode: 85 / progress: Training / epsilon: 0.7077959999915975 / score: 2133.2062873616815\n",
      "step: 346249 / episode: 86 / progress: Training / epsilon: 0.7037519999914812 / score: 2300.0914259552956\n",
      "step: 350654 / episode: 87 / progress: Training / epsilon: 0.6993469999913545 / score: 1903.3748715370893\n",
      "step: 352444 / episode: 88 / progress: Training / epsilon: 0.697556999991303 / score: 935.7739773318172\n",
      "step: 353306 / episode: 89 / progress: Training / epsilon: 0.6966949999912783 / score: 573.7789123281837\n",
      "step: 354815 / episode: 90 / progress: Training / epsilon: 0.6951859999912349 / score: 976.940120793879\n",
      "step: 357528 / episode: 91 / progress: Training / epsilon: 0.6924729999911569 / score: 1104.3752107322216\n",
      "step: 359698 / episode: 92 / progress: Training / epsilon: 0.6903029999910945 / score: 1185.852248236537\n",
      "step: 361180 / episode: 93 / progress: Training / epsilon: 0.6888209999910518 / score: 1002.3290009126067\n",
      "step: 365129 / episode: 94 / progress: Training / epsilon: 0.6848719999909383 / score: 2394.9077025279403\n",
      "step: 369231 / episode: 95 / progress: Training / epsilon: 0.6807699999908203 / score: 2231.956961326301\n",
      "step: 373440 / episode: 96 / progress: Training / epsilon: 0.6765609999906993 / score: 2107.0285022854805\n",
      "step: 377525 / episode: 97 / progress: Training / epsilon: 0.6724759999905818 / score: 2251.81915166229\n",
      "step: 381708 / episode: 98 / progress: Training / epsilon: 0.6682929999904615 / score: 2125.519811615348\n",
      "step: 382433 / episode: 99 / progress: Training / epsilon: 0.6675679999904407 / score: 436.6063399091363\n",
      "step: 386574 / episode: 100 / progress: Training / epsilon: 0.6634269999903216 / score: 2191.4799404367805\n",
      "step: 388325 / episode: 101 / progress: Training / epsilon: 0.6616759999902713 / score: 787.1189955025911\n",
      "step: 392195 / episode: 102 / progress: Training / epsilon: 0.65780599999016 / score: 2470.9955291599035\n",
      "step: 396634 / episode: 103 / progress: Training / epsilon: 0.6533669999900323 / score: 1866.4941770583391\n",
      "step: 400720 / episode: 104 / progress: Training / epsilon: 0.6492809999899148 / score: 2237.6924820244312\n",
      "step: 403510 / episode: 105 / progress: Training / epsilon: 0.6464909999898346 / score: 1286.1904690936208\n",
      "step: 406129 / episode: 106 / progress: Training / epsilon: 0.6438719999897593 / score: 1274.8227105289698\n",
      "step: 410004 / episode: 107 / progress: Training / epsilon: 0.6399969999896479 / score: 2471.816256441176\n",
      "step: 413119 / episode: 108 / progress: Training / epsilon: 0.6368819999895583 / score: 1794.8339595496655\n",
      "step: 417394 / episode: 109 / progress: Training / epsilon: 0.6326069999894354 / score: 1931.7360556274652\n",
      "step: 418148 / episode: 110 / progress: Training / epsilon: 0.6318529999894137 / score: 529.6631542816758\n",
      "step: 419283 / episode: 111 / progress: Training / epsilon: 0.630717999989381 / score: 867.5565814524889\n",
      "step: 423530 / episode: 112 / progress: Training / epsilon: 0.6264709999892589 / score: 2069.901063852012\n",
      "step: 424071 / episode: 113 / progress: Training / epsilon: 0.6259299999892434 / score: 357.43212512135506\n",
      "step: 424365 / episode: 114 / progress: Training / epsilon: 0.6256359999892349 / score: 241.80240462720394\n",
      "step: 427076 / episode: 115 / progress: Training / epsilon: 0.622924999989157 / score: 1335.042302340269\n",
      "step: 428314 / episode: 116 / progress: Training / epsilon: 0.6216869999891214 / score: 299.50647177547216\n",
      "step: 432350 / episode: 117 / progress: Training / epsilon: 0.6176509999890053 / score: 2307.1314567774534\n",
      "step: 436282 / episode: 118 / progress: Training / epsilon: 0.6137189999888922 / score: 2416.8156656846404\n",
      "step: 440348 / episode: 119 / progress: Training / epsilon: 0.6096529999887753 / score: 2260.90541690588\n",
      "step: 443280 / episode: 120 / progress: Training / epsilon: 0.606720999988691 / score: 2007.8534298166633\n",
      "step: 447444 / episode: 121 / progress: Training / epsilon: 0.6025569999885713 / score: 2182.15194734931\n",
      "step: 451690 / episode: 122 / progress: Training / epsilon: 0.5983109999884492 / score: 2075.4876537770033\n",
      "step: 453404 / episode: 123 / progress: Training / epsilon: 0.5965969999883999 / score: 1334.646316818893\n",
      "step: 454071 / episode: 124 / progress: Training / epsilon: 0.5959299999883807 / score: 438.68972523510456\n",
      "step: 454163 / episode: 125 / progress: Training / epsilon: 0.595837999988378 / score: 69.67499911785126\n",
      "step: 454505 / episode: 126 / progress: Training / epsilon: 0.5954959999883682 / score: 273.1609417498112\n",
      "step: 454893 / episode: 127 / progress: Training / epsilon: 0.5951079999883571 / score: 319.04377350211143\n",
      "step: 458875 / episode: 128 / progress: Training / epsilon: 0.5911259999882426 / score: 2380.3765227124095\n",
      "step: 462896 / episode: 129 / progress: Training / epsilon: 0.5871049999881269 / score: 2339.632685095072\n",
      "step: 466772 / episode: 130 / progress: Training / epsilon: 0.5832289999880155 / score: 2474.6275904923677\n",
      "step: 470546 / episode: 131 / progress: Training / epsilon: 0.579454999987907 / score: 2588.653633646667\n",
      "step: 474556 / episode: 132 / progress: Training / epsilon: 0.5754449999877916 / score: 2327.2062889412045\n",
      "step: 476756 / episode: 133 / progress: Training / epsilon: 0.5732449999877284 / score: 1533.7567238211632\n",
      "step: 479050 / episode: 134 / progress: Training / epsilon: 0.5709509999876624 / score: 1653.7717481702566\n",
      "step: 480631 / episode: 135 / progress: Training / epsilon: 0.569369999987617 / score: 917.2261358201504\n",
      "step: 484344 / episode: 136 / progress: Training / epsilon: 0.5656569999875102 / score: 2662.728990390897\n",
      "step: 488756 / episode: 137 / progress: Training / epsilon: 0.5612449999873833 / score: 1893.215290531516\n",
      "step: 490560 / episode: 138 / progress: Training / epsilon: 0.5594409999873314 / score: 1407.6530067175627\n",
      "step: 491498 / episode: 139 / progress: Training / epsilon: 0.5585029999873045 / score: 743.0006252974272\n",
      "step: 493037 / episode: 140 / progress: Training / epsilon: 0.5569639999872602 / score: 961.9154324606061\n",
      "step: 494486 / episode: 141 / progress: Training / epsilon: 0.5555149999872185 / score: 1000.5194239169359\n",
      "step: 498522 / episode: 142 / progress: Training / epsilon: 0.5514789999871025 / score: 2311.1744959652424\n",
      "step: 500024 / episode: 143 / progress: Training / epsilon: 0.5499769999870593 / score: 690.7495759427547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 501165 / episode: 144 / progress: Training / epsilon: 0.5488359999870265 / score: 765.8441655635834\n",
      "step: 502502 / episode: 145 / progress: Training / epsilon: 0.547498999986988 / score: 835.6465135887265\n",
      "step: 504930 / episode: 146 / progress: Training / epsilon: 0.5450709999869182 / score: 1587.6531090512872\n",
      "step: 508542 / episode: 147 / progress: Training / epsilon: 0.5414589999868143 / score: 2769.4688491150737\n",
      "step: 512479 / episode: 148 / progress: Training / epsilon: 0.5375219999867011 / score: 2428.8884813115\n",
      "step: 515824 / episode: 149 / progress: Training / epsilon: 0.534176999986605 / score: 1872.5880395621061\n",
      "step: 518538 / episode: 150 / progress: Training / epsilon: 0.5314629999865269 / score: 1544.707005172968\n",
      "step: 518850 / episode: 151 / progress: Training / epsilon: 0.5311509999865179 / score: 274.27917301654816\n",
      "step: 520423 / episode: 152 / progress: Training / epsilon: 0.5295779999864727 / score: 1179.2604548409581\n",
      "step: 523042 / episode: 153 / progress: Training / epsilon: 0.5269589999863974 / score: 1131.1745414286852\n",
      "step: 524295 / episode: 154 / progress: Training / epsilon: 0.5257059999863614 / score: 809.1026556417346\n",
      "step: 527042 / episode: 155 / progress: Training / epsilon: 0.5229589999862824 / score: 1240.8116835728288\n",
      "step: 531205 / episode: 156 / progress: Training / epsilon: 0.5187959999861627 / score: 2170.0285625755787\n",
      "step: 533611 / episode: 157 / progress: Training / epsilon: 0.5163899999860935 / score: 1533.4787316322327\n",
      "step: 537485 / episode: 158 / progress: Training / epsilon: 0.5125159999859821 / score: 2358.5579862445593\n",
      "step: 541560 / episode: 159 / progress: Training / epsilon: 0.5084409999858649 / score: 2260.5908806324005\n",
      "step: 545233 / episode: 160 / progress: Training / epsilon: 0.5047679999857593 / score: 2716.9874460548162\n",
      "step: 547877 / episode: 161 / progress: Training / epsilon: 0.5021239999856832 / score: 1733.0760727971792\n",
      "step: 551799 / episode: 162 / progress: Training / epsilon: 0.49820199998567033 / score: 2443.0039175897837\n",
      "step: 555692 / episode: 163 / progress: Training / epsilon: 0.4943089999857745 / score: 2455.664896763861\n",
      "step: 559332 / episode: 164 / progress: Training / epsilon: 0.4906689999858719 / score: 2741.5357887148857\n",
      "step: 563501 / episode: 165 / progress: Training / epsilon: 0.4864999999859834 / score: 2156.4177190586925\n",
      "step: 567007 / episode: 166 / progress: Training / epsilon: 0.4829939999860772 / score: 1971.0650158897042\n",
      "step: 570889 / episode: 167 / progress: Training / epsilon: 0.4791119999861811 / score: 2478.057604700327\n",
      "step: 574905 / episode: 168 / progress: Training / epsilon: 0.47509599998628854 / score: 2322.165927775204\n",
      "step: 575658 / episode: 169 / progress: Training / epsilon: 0.4743429999863087 / score: 648.7050462141633\n",
      "step: 579345 / episode: 170 / progress: Training / epsilon: 0.47065599998640734 / score: 2698.880754031241\n",
      "step: 582832 / episode: 171 / progress: Training / epsilon: 0.46716899998650063 / score: 2175.480337999761\n",
      "step: 584679 / episode: 172 / progress: Training / epsilon: 0.46532199998655005 / score: 773.1077024713159\n",
      "step: 585080 / episode: 173 / progress: Training / epsilon: 0.4649209999865608 / score: 346.42018324136734\n",
      "step: 587016 / episode: 174 / progress: Training / epsilon: 0.4629849999866126 / score: 1636.323168233037\n",
      "step: 590928 / episode: 175 / progress: Training / epsilon: 0.45907299998671725 / score: 2460.6959627866745\n",
      "step: 593867 / episode: 176 / progress: Training / epsilon: 0.4561339999867959 / score: 2209.5984557420015\n",
      "step: 597811 / episode: 177 / progress: Training / epsilon: 0.4521899999869014 / score: 2411.6849555894732\n",
      "step: 601126 / episode: 178 / progress: Training / epsilon: 0.4488749999869901 / score: 1981.3841082975268\n",
      "step: 601343 / episode: 179 / progress: Training / epsilon: 0.4486579999869959 / score: 152.7499973475933\n",
      "step: 601996 / episode: 180 / progress: Training / epsilon: 0.4480049999870134 / score: 542.94805919379\n",
      "step: 603505 / episode: 181 / progress: Training / epsilon: 0.44649599998705375 / score: 1230.0480701848865\n",
      "step: 605411 / episode: 182 / progress: Training / epsilon: 0.44458999998710474 / score: 1052.157281048596\n",
      "step: 609070 / episode: 183 / progress: Training / epsilon: 0.44093099998720264 / score: 2714.8432280644774\n",
      "step: 610168 / episode: 184 / progress: Training / epsilon: 0.439832999987232 / score: 826.7396726459265\n",
      "step: 614107 / episode: 185 / progress: Training / epsilon: 0.4358939999873374 / score: 2426.837558545172\n",
      "step: 615654 / episode: 186 / progress: Training / epsilon: 0.4343469999873788 / score: 634.0356171131134\n",
      "step: 619717 / episode: 187 / progress: Training / epsilon: 0.4302839999874875 / score: 2288.8337965235114\n",
      "step: 623538 / episode: 188 / progress: Training / epsilon: 0.42646299998758974 / score: 2539.5921387448907\n",
      "step: 625213 / episode: 189 / progress: Training / epsilon: 0.42478799998763456 / score: 1388.774899944663\n",
      "step: 626648 / episode: 190 / progress: Training / epsilon: 0.42335299998767295 / score: 886.963515996933\n",
      "step: 627363 / episode: 191 / progress: Training / epsilon: 0.4226379999876921 / score: 390.8142207711935\n",
      "step: 627818 / episode: 192 / progress: Training / epsilon: 0.42218299998770425 / score: 351.10208436101675\n",
      "step: 628249 / episode: 193 / progress: Training / epsilon: 0.4217519999877158 / score: 322.41840843111277\n",
      "step: 632421 / episode: 194 / progress: Training / epsilon: 0.4175799999878274 / score: 2147.678906790912\n",
      "step: 633073 / episode: 195 / progress: Training / epsilon: 0.41692799998784486 / score: 569.5415119677782\n",
      "step: 634177 / episode: 196 / progress: Training / epsilon: 0.4158239999878744 / score: 877.7356219440699\n",
      "step: 637978 / episode: 197 / progress: Training / epsilon: 0.4120229999879761 / score: 2584.6644542366266\n",
      "step: 641643 / episode: 198 / progress: Training / epsilon: 0.40835799998807415 / score: 2697.065957315266\n",
      "step: 641820 / episode: 199 / progress: Training / epsilon: 0.4081809999880789 / score: 148.73493149876595\n",
      "step: 641982 / episode: 200 / progress: Training / epsilon: 0.4080189999880832 / score: 130.6499971151352\n",
      "step: 646117 / episode: 201 / progress: Training / epsilon: 0.40388399998819385 / score: 2189.0570737943053\n",
      "step: 646461 / episode: 202 / progress: Training / epsilon: 0.40353999998820306 / score: 252.03783781826496\n",
      "step: 647601 / episode: 203 / progress: Training / epsilon: 0.40239999998823356 / score: 719.6164842918515\n",
      "step: 650200 / episode: 204 / progress: Training / epsilon: 0.3998009999883031 / score: 1562.7450736761093\n",
      "step: 651326 / episode: 205 / progress: Training / epsilon: 0.3986749999883332 / score: 879.9424443021417\n",
      "step: 652417 / episode: 206 / progress: Training / epsilon: 0.3975839999883624 / score: 841.2151674181223\n",
      "step: 656593 / episode: 207 / progress: Training / epsilon: 0.39340799998847414 / score: 2153.4711210802197\n",
      "step: 657586 / episode: 208 / progress: Training / epsilon: 0.3924149999885007 / score: 693.1551989465952\n",
      "step: 658079 / episode: 209 / progress: Training / epsilon: 0.3919219999885139 / score: 373.4821301996708\n",
      "step: 658705 / episode: 210 / progress: Training / epsilon: 0.39129599998853065 / score: 318.027872890234\n",
      "step: 660960 / episode: 211 / progress: Training / epsilon: 0.389040999988591 / score: 1388.2262883260846\n",
      "step: 661321 / episode: 212 / progress: Training / epsilon: 0.38867999998860064 / score: 283.0982023999095\n",
      "step: 664875 / episode: 213 / progress: Training / epsilon: 0.38512599998869573 / score: 2846.820871554315\n",
      "step: 666156 / episode: 214 / progress: Training / epsilon: 0.38384499998873 / score: 749.569820471108\n",
      "step: 667350 / episode: 215 / progress: Training / epsilon: 0.38265099998876195 / score: 1000.9499035775661\n",
      "step: 669124 / episode: 216 / progress: Training / epsilon: 0.3808769999888094 / score: 1098.6311651393771\n",
      "step: 670065 / episode: 217 / progress: Training / epsilon: 0.3799359999888346 / score: 434.9788252040744\n",
      "step: 670205 / episode: 218 / progress: Training / epsilon: 0.37979599998883834 / score: 111.7999991774559\n",
      "step: 671169 / episode: 219 / progress: Training / epsilon: 0.37883199998886413 / score: 621.0468642190099\n",
      "step: 674910 / episode: 220 / progress: Training / epsilon: 0.3750909999889642 / score: 2627.426774352789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 678392 / episode: 221 / progress: Training / epsilon: 0.3716089999890574 / score: 2918.7326989397407\n",
      "step: 680795 / episode: 222 / progress: Training / epsilon: 0.3692059999891217 / score: 1439.5618174821138\n",
      "step: 681945 / episode: 223 / progress: Training / epsilon: 0.36805599998915245 / score: 739.83027613163\n",
      "step: 683487 / episode: 224 / progress: Training / epsilon: 0.3665139999891937 / score: 1114.3860497400165\n",
      "step: 687719 / episode: 225 / progress: Training / epsilon: 0.36228199998930694 / score: 2104.536870867014\n",
      "step: 688166 / episode: 226 / progress: Training / epsilon: 0.3618349999893189 / score: 165.50755089521408\n",
      "step: 691944 / episode: 227 / progress: Training / epsilon: 0.35805699998942 / score: 2600.205956593156\n",
      "step: 693677 / episode: 228 / progress: Training / epsilon: 0.35632399998946634 / score: 1283.7492667734623\n",
      "step: 695035 / episode: 229 / progress: Training / epsilon: 0.3549659999895027 / score: 838.4936497211456\n",
      "step: 698893 / episode: 230 / progress: Training / epsilon: 0.3511079999896059 / score: 2513.5883517339826\n",
      "step: 702600 / episode: 231 / progress: Training / epsilon: 0.3474009999897051 / score: 2669.761340856552\n",
      "step: 707174 / episode: 232 / progress: Training / epsilon: 0.34282699998982746 / score: 1712.7346123680472\n",
      "step: 707685 / episode: 233 / progress: Training / epsilon: 0.34231599998984114 / score: 437.1553132086992\n",
      "step: 711423 / episode: 234 / progress: Training / epsilon: 0.33857799998994115 / score: 2632.1603134945035\n",
      "step: 712388 / episode: 235 / progress: Training / epsilon: 0.33761299998996697 / score: 493.2169706374407\n",
      "step: 715520 / episode: 236 / progress: Training / epsilon: 0.33448099999005076 / score: 1929.4013395607471\n",
      "step: 715896 / episode: 237 / progress: Training / epsilon: 0.3341049999900608 / score: 172.20591508597136\n",
      "step: 720745 / episode: 238 / progress: Training / epsilon: 0.32925599999019056 / score: 1475.1283075809479\n",
      "step: 721606 / episode: 239 / progress: Training / epsilon: 0.3283949999902136 / score: 708.728302821517\n",
      "step: 725468 / episode: 240 / progress: Training / epsilon: 0.32453299999031693 / score: 2520.7824345752597\n",
      "step: 726209 / episode: 241 / progress: Training / epsilon: 0.32379199999033675 / score: 519.0614694282413\n",
      "step: 729025 / episode: 242 / progress: Training / epsilon: 0.3209759999904121 / score: 2102.135445572436\n",
      "step: 731402 / episode: 243 / progress: Training / epsilon: 0.3185989999904757 / score: 1686.7363048121333\n",
      "step: 733795 / episode: 244 / progress: Training / epsilon: 0.3162059999905397 / score: 1884.5985240116715\n",
      "step: 735515 / episode: 245 / progress: Training / epsilon: 0.31448599999058574 / score: 1365.7701638489962\n",
      "step: 739302 / episode: 246 / progress: Training / epsilon: 0.31069899999068706 / score: 2578.584354840219\n",
      "step: 740689 / episode: 247 / progress: Training / epsilon: 0.3093119999907242 / score: 633.2690570428967\n",
      "step: 741446 / episode: 248 / progress: Training / epsilon: 0.3085549999907444 / score: 667.7377959787846\n",
      "step: 742755 / episode: 249 / progress: Training / epsilon: 0.30724599999077945 / score: 820.2372543290257\n",
      "step: 744792 / episode: 250 / progress: Training / epsilon: 0.30520899999083395 / score: 900.0419173166156\n",
      "step: 747552 / episode: 251 / progress: Training / epsilon: 0.3024489999909078 / score: 1534.7191825956106\n",
      "step: 750893 / episode: 252 / progress: Training / epsilon: 0.2991079999909972 / score: 1789.6304844468832\n",
      "step: 754286 / episode: 253 / progress: Training / epsilon: 0.29571499999108797 / score: 1199.9474523440003\n",
      "step: 758226 / episode: 254 / progress: Training / epsilon: 0.2917749999911934 / score: 2419.7776874378324\n",
      "step: 762047 / episode: 255 / progress: Training / epsilon: 0.2879539999912956 / score: 2585.059000879526\n",
      "step: 766174 / episode: 256 / progress: Training / epsilon: 0.28382699999140604 / score: 2234.416472040117\n",
      "step: 770291 / episode: 257 / progress: Training / epsilon: 0.2797099999915162 / score: 2237.4278822541237\n",
      "step: 770533 / episode: 258 / progress: Training / epsilon: 0.27946799999152266 / score: 171.8229209035635\n",
      "step: 774213 / episode: 259 / progress: Training / epsilon: 0.2757879999916211 / score: 2714.51460724324\n",
      "step: 774391 / episode: 260 / progress: Training / epsilon: 0.2756099999916259 / score: 144.22499859333038\n",
      "step: 775661 / episode: 261 / progress: Training / epsilon: 0.27433999999165987 / score: 892.7479554340243\n",
      "step: 780041 / episode: 262 / progress: Training / epsilon: 0.26995999999177706 / score: 1946.4042038396\n",
      "step: 780775 / episode: 263 / progress: Training / epsilon: 0.2692259999917967 / score: 553.0537344813347\n",
      "step: 782291 / episode: 264 / progress: Training / epsilon: 0.26770999999183726 / score: 942.5787106752396\n",
      "step: 786274 / episode: 265 / progress: Training / epsilon: 0.2637269999919438 / score: 2382.5608205497265\n",
      "step: 788594 / episode: 266 / progress: Training / epsilon: 0.2614069999920059 / score: 1654.9983124285936\n",
      "step: 789987 / episode: 267 / progress: Training / epsilon: 0.26001399999204317 / score: 993.5450243130326\n",
      "step: 790871 / episode: 268 / progress: Training / epsilon: 0.2591299999920668 / score: 723.7102023884654\n",
      "step: 791391 / episode: 269 / progress: Training / epsilon: 0.25860999999208073 / score: 425.3857426121831\n",
      "step: 795071 / episode: 270 / progress: Training / epsilon: 0.2549299999921792 / score: 2213.4568543210626\n",
      "step: 796651 / episode: 271 / progress: Training / epsilon: 0.25334999999222146 / score: 1161.161719866097\n",
      "step: 800288 / episode: 272 / progress: Training / epsilon: 0.24971299999231078 / score: 2765.0862578079104\n",
      "step: 804011 / episode: 273 / progress: Training / epsilon: 0.24598999999230706 / score: 2700.6396951451898\n",
      "step: 806200 / episode: 274 / progress: Training / epsilon: 0.24380099999230487 / score: 1401.6219874247909\n",
      "step: 810453 / episode: 275 / progress: Training / epsilon: 0.23954799999230061 / score: 2078.423220641911\n",
      "step: 811528 / episode: 276 / progress: Training / epsilon: 0.23847299999229954 / score: 476.92782497406006\n",
      "step: 812792 / episode: 277 / progress: Training / epsilon: 0.23720899999229828 / score: 911.1524218842387\n",
      "step: 815400 / episode: 278 / progress: Training / epsilon: 0.23460099999229567 / score: 1878.9229546412826\n",
      "step: 817395 / episode: 279 / progress: Training / epsilon: 0.23260599999229367 / score: 1281.8414879962802\n",
      "step: 819413 / episode: 280 / progress: Training / epsilon: 0.23058799999229165 / score: 1565.6130245923996\n",
      "step: 821546 / episode: 281 / progress: Training / epsilon: 0.22845499999228952 / score: 1779.7691260799766\n",
      "step: 825552 / episode: 282 / progress: Training / epsilon: 0.22444899999228551 / score: 2361.456485249102\n",
      "step: 826001 / episode: 283 / progress: Training / epsilon: 0.22399999999228506 / score: 325.2692725211382\n",
      "step: 826203 / episode: 284 / progress: Training / epsilon: 0.22379799999228486 / score: 174.75000029802322\n",
      "step: 829870 / episode: 285 / progress: Training / epsilon: 0.2201309999922812 / score: 2738.8743919208646\n",
      "step: 832669 / episode: 286 / progress: Training / epsilon: 0.2173319999922784 / score: 1991.175394743681\n",
      "step: 836626 / episode: 287 / progress: Training / epsilon: 0.21337499999227444 / score: 2417.3248560652137\n",
      "step: 837698 / episode: 288 / progress: Training / epsilon: 0.21230299999227337 / score: 600.7337713837624\n",
      "step: 839365 / episode: 289 / progress: Training / epsilon: 0.2106359999922717 / score: 1234.2395368516445\n",
      "step: 843319 / episode: 290 / progress: Training / epsilon: 0.20668199999226775 / score: 2411.3112488761544\n",
      "step: 848083 / episode: 291 / progress: Training / epsilon: 0.20191799999226298 / score: 1559.8435681834817\n",
      "step: 851782 / episode: 292 / progress: Training / epsilon: 0.19821899999225928 / score: 2699.9748730137944\n",
      "step: 854594 / episode: 293 / progress: Training / epsilon: 0.19540699999225647 / score: 1642.6253266334534\n",
      "step: 858321 / episode: 294 / progress: Training / epsilon: 0.19167999999225274 / score: 2655.539492331445\n",
      "step: 861885 / episode: 295 / progress: Training / epsilon: 0.18811599999224918 / score: 2827.398742981255\n",
      "step: 863213 / episode: 296 / progress: Training / epsilon: 0.18678799999224785 / score: 1061.0064778327942\n",
      "step: 863711 / episode: 297 / progress: Training / epsilon: 0.18628999999224735 / score: 319.6458389759064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 865035 / episode: 298 / progress: Training / epsilon: 0.18496599999224603 / score: 1073.5945069044828\n",
      "step: 865186 / episode: 299 / progress: Training / epsilon: 0.18481499999224588 / score: 110.94999784231186\n",
      "step: 865498 / episode: 300 / progress: Training / epsilon: 0.18450299999224556 / score: 260.65000215917826\n",
      "step: 869205 / episode: 301 / progress: Training / epsilon: 0.18079599999224186 / score: 2703.32048176229\n",
      "step: 872772 / episode: 302 / progress: Training / epsilon: 0.1772289999922383 / score: 2831.0347807630897\n",
      "step: 873775 / episode: 303 / progress: Training / epsilon: 0.1762259999922373 / score: 673.1144886016846\n",
      "step: 874395 / episode: 304 / progress: Training / epsilon: 0.17560599999223667 / score: 404.7193110138178\n",
      "step: 876505 / episode: 305 / progress: Training / epsilon: 0.17349599999223456 / score: 811.9012403041124\n",
      "step: 878461 / episode: 306 / progress: Training / epsilon: 0.1715399999922326 / score: 1393.2692289799452\n",
      "step: 882414 / episode: 307 / progress: Training / epsilon: 0.16758699999222865 / score: 2179.904298104346\n",
      "step: 882598 / episode: 308 / progress: Training / epsilon: 0.16740299999222846 / score: 145.3749994635582\n",
      "step: 886538 / episode: 309 / progress: Training / epsilon: 0.16346299999222452 / score: 2404.918319746852\n",
      "step: 886730 / episode: 310 / progress: Training / epsilon: 0.16327099999222433 / score: 167.35234060883522\n",
      "step: 887645 / episode: 311 / progress: Training / epsilon: 0.16235599999222342 / score: 455.2265888750553\n",
      "step: 891398 / episode: 312 / progress: Training / epsilon: 0.15860299999221966 / score: 2638.9881876185536\n",
      "step: 895411 / episode: 313 / progress: Training / epsilon: 0.15458999999221565 / score: 2378.110807105899\n",
      "step: 895597 / episode: 314 / progress: Training / epsilon: 0.15440399999221546 / score: 157.32788637280464\n",
      "step: 899466 / episode: 315 / progress: Training / epsilon: 0.1505349999922116 / score: 2509.4955235794187\n",
      "step: 903894 / episode: 316 / progress: Training / epsilon: 0.14610699999220716 / score: 1920.6790630817413\n",
      "step: 905397 / episode: 317 / progress: Training / epsilon: 0.14460399999220566 / score: 947.6065404713154\n",
      "step: 906895 / episode: 318 / progress: Training / epsilon: 0.14310599999220416 / score: 1178.2148548960686\n",
      "step: 911069 / episode: 319 / progress: Training / epsilon: 0.1389319999922 / score: 2207.7674338519573\n",
      "step: 915041 / episode: 320 / progress: Training / epsilon: 0.13495999999219602 / score: 2382.699278101325\n",
      "step: 916673 / episode: 321 / progress: Training / epsilon: 0.13332799999219438 / score: 1478.3939660936594\n",
      "step: 917697 / episode: 322 / progress: Training / epsilon: 0.13230399999219336 / score: 585.4959281086922\n",
      "step: 917830 / episode: 323 / progress: Training / epsilon: 0.13217099999219323 / score: 117.99999988079071\n",
      "step: 918897 / episode: 324 / progress: Training / epsilon: 0.13110399999219216 / score: 972.8629427552223\n",
      "step: 920977 / episode: 325 / progress: Training / epsilon: 0.12902399999219008 / score: 1028.0805236324668\n",
      "step: 923189 / episode: 326 / progress: Training / epsilon: 0.12681199999218787 / score: 1578.6034164950252\n",
      "step: 927735 / episode: 327 / progress: Training / epsilon: 0.12226599999218332 / score: 1775.453489139676\n",
      "step: 930575 / episode: 328 / progress: Training / epsilon: 0.11942599999218048 / score: 2045.4194797426462\n",
      "step: 933794 / episode: 329 / progress: Training / epsilon: 0.11620699999217726 / score: 2461.6557481512427\n",
      "step: 937760 / episode: 330 / progress: Training / epsilon: 0.1122409999921733 / score: 2430.0622915923595\n",
      "step: 938747 / episode: 331 / progress: Training / epsilon: 0.11125399999217231 / score: 734.4427847340703\n",
      "step: 941581 / episode: 332 / progress: Training / epsilon: 0.10841999999216947 / score: 2213.2365426942706\n",
      "step: 942717 / episode: 333 / progress: Training / epsilon: 0.10728399999216834 / score: 850.4207310602069\n",
      "step: 944622 / episode: 334 / progress: Training / epsilon: 0.10537899999216643 / score: 924.3909578174353\n",
      "step: 949295 / episode: 335 / progress: Training / epsilon: 0.10070599999216176 / score: 1626.4163083657622\n",
      "step: 950092 / episode: 336 / progress: Training / epsilon: 0.09999999999216105 / score: 695.8847977295518\n",
      "step: 951237 / episode: 337 / progress: Training / epsilon: 0.09999999999216105 / score: 672.4242962226272\n",
      "step: 954364 / episode: 338 / progress: Training / epsilon: 0.09999999999216105 / score: 2106.834629096091\n",
      "step: 956618 / episode: 339 / progress: Training / epsilon: 0.09999999999216105 / score: 1416.6307881772518\n",
      "step: 960532 / episode: 340 / progress: Training / epsilon: 0.09999999999216105 / score: 2466.4669820442796\n",
      "step: 961800 / episode: 341 / progress: Training / epsilon: 0.09999999999216105 / score: 1065.838666535914\n",
      "step: 962845 / episode: 342 / progress: Training / epsilon: 0.09999999999216105 / score: 973.4641416221857\n",
      "step: 965410 / episode: 343 / progress: Training / epsilon: 0.09999999999216105 / score: 1408.5181012749672\n",
      "step: 969046 / episode: 344 / progress: Training / epsilon: 0.09999999999216105 / score: 2801.123312704265\n",
      "step: 971744 / episode: 345 / progress: Training / epsilon: 0.09999999999216105 / score: 2082.8958098217845\n",
      "step: 973349 / episode: 346 / progress: Training / epsilon: 0.09999999999216105 / score: 1052.483321800828\n",
      "step: 977369 / episode: 347 / progress: Training / epsilon: 0.09999999999216105 / score: 2370.164864875376\n",
      "step: 977718 / episode: 348 / progress: Training / epsilon: 0.09999999999216105 / score: 228.89544252306223\n",
      "step: 980750 / episode: 349 / progress: Training / epsilon: 0.09999999999216105 / score: 1841.418566994369\n",
      "step: 981370 / episode: 350 / progress: Training / epsilon: 0.09999999999216105 / score: 570.4828173220158\n",
      "step: 985543 / episode: 351 / progress: Training / epsilon: 0.09999999999216105 / score: 2180.701493792236\n",
      "step: 986568 / episode: 352 / progress: Training / epsilon: 0.09999999999216105 / score: 729.0359109044075\n",
      "step: 989535 / episode: 353 / progress: Training / epsilon: 0.09999999999216105 / score: 1812.9768719375134\n",
      "step: 993368 / episode: 354 / progress: Training / epsilon: 0.09999999999216105 / score: 2543.994343623519\n",
      "step: 997687 / episode: 355 / progress: Training / epsilon: 0.09999999999216105 / score: 2007.810338549316\n",
      "step: 999653 / episode: 356 / progress: Training / epsilon: 0.09999999999216105 / score: 988.2424879670143\n",
      "step: 1001130 / episode: 357 / progress: Training / epsilon: 0.09999999999216105 / score: 841.1685764938593\n",
      "step: 1004368 / episode: 358 / progress: Training / epsilon: 0.09999999999216105 / score: 1193.500687226653\n",
      "step: 1004665 / episode: 359 / progress: Training / epsilon: 0.09999999999216105 / score: 229.37499520927668\n",
      "step: 1005601 / episode: 360 / progress: Training / epsilon: 0.09999999999216105 / score: 850.4524366781116\n",
      "step: 1007623 / episode: 361 / progress: Training / epsilon: 0.09999999999216105 / score: 906.1938667595387\n",
      "step: 1011485 / episode: 362 / progress: Training / epsilon: 0.09999999999216105 / score: 2511.6103125438094\n",
      "step: 1014559 / episode: 363 / progress: Training / epsilon: 0.09999999999216105 / score: 1278.256240643561\n",
      "step: 1018059 / episode: 364 / progress: Training / epsilon: 0.09999999999216105 / score: 2933.2294461652637\n",
      "step: 1018430 / episode: 365 / progress: Training / epsilon: 0.09999999999216105 / score: 295.8223401606083\n",
      "step: 1022294 / episode: 366 / progress: Training / epsilon: 0.09999999999216105 / score: 2508.307951629162\n",
      "step: 1022507 / episode: 367 / progress: Training / epsilon: 0.09999999999216105 / score: 127.64655508100986\n",
      "step: 1026510 / episode: 368 / progress: Training / epsilon: 0.09999999999216105 / score: 2373.6398012787104\n",
      "step: 1028778 / episode: 369 / progress: Training / epsilon: 0.09999999999216105 / score: 1175.523216754198\n",
      "step: 1032473 / episode: 370 / progress: Training / epsilon: 0.09999999999216105 / score: 2718.7665702849627\n",
      "step: 1036681 / episode: 371 / progress: Training / epsilon: 0.09999999999216105 / score: 2145.302949823439\n",
      "step: 1037584 / episode: 372 / progress: Training / epsilon: 0.09999999999216105 / score: 627.699095018208\n",
      "step: 1041439 / episode: 373 / progress: Training / epsilon: 0.09999999999216105 / score: 2512.514022529125\n",
      "step: 1042103 / episode: 374 / progress: Training / epsilon: 0.09999999999216105 / score: 528.5977872535586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1043180 / episode: 375 / progress: Training / epsilon: 0.09999999999216105 / score: 676.8387708365917\n",
      "step: 1046968 / episode: 376 / progress: Training / epsilon: 0.09999999999216105 / score: 2627.2148921340704\n",
      "step: 1047337 / episode: 377 / progress: Training / epsilon: 0.09999999999216105 / score: 257.40000185370445\n",
      "Model saved in file: ../saved_networks/2018-09-12_10_51_QR-DQN_sensor/model.ckpt\n",
      "step: 1051656 / episode: 378 / progress: Testing / epsilon: 0 / score: 2027.580434024334\n",
      "step: 1056408 / episode: 379 / progress: Testing / epsilon: 0 / score: 1593.6117691993713\n",
      "step: 1061527 / episode: 380 / progress: Testing / epsilon: 0 / score: 1243.9288613125682\n",
      "step: 1066221 / episode: 381 / progress: Testing / epsilon: 0 / score: 1754.6309095546603\n",
      "step: 1068612 / episode: 382 / progress: Testing / epsilon: 0 / score: 1200.5079557448626\n",
      "step: 1073231 / episode: 383 / progress: Testing / epsilon: 0 / score: 1804.9289307072759\n",
      "step: 1077647 / episode: 384 / progress: Testing / epsilon: 0 / score: 2023.949497424066\n",
      "step: 1082355 / episode: 385 / progress: Testing / epsilon: 0 / score: 1696.7813089191914\n",
      "step: 1086199 / episode: 386 / progress: Testing / epsilon: 0 / score: 2582.824111826718\n",
      "step: 1091293 / episode: 387 / progress: Testing / epsilon: 0 / score: 1366.6684341579676\n",
      "step: 1095608 / episode: 388 / progress: Testing / epsilon: 0 / score: 2106.2406510040164\n",
      "step: 1100063 / episode: 389 / progress: Testing / epsilon: 0 / score: 1954.0009574219584\n",
      "step: 1103983 / episode: 390 / progress: Testing / epsilon: 0 / score: 2525.745897553861\n",
      "step: 1108519 / episode: 391 / progress: Testing / epsilon: 0 / score: 1900.2873628363013\n",
      "step: 1113436 / episode: 392 / progress: Testing / epsilon: 0 / score: 1486.2839169204235\n",
      "step: 1117270 / episode: 393 / progress: Testing / epsilon: 0 / score: 2595.062687881291\n",
      "step: 1121572 / episode: 394 / progress: Testing / epsilon: 0 / score: 2115.905753917992\n",
      "step: 1121705 / episode: 395 / progress: Testing / epsilon: 0 / score: 119.95000010728836\n",
      "step: 1125768 / episode: 396 / progress: Testing / epsilon: 0 / score: 2364.247868858278\n",
      "step: 1130396 / episode: 397 / progress: Testing / epsilon: 0 / score: 1769.9417477622628\n",
      "step: 1134868 / episode: 398 / progress: Testing / epsilon: 0 / score: 1967.2836477458477\n",
      "step: 1135640 / episode: 399 / progress: Testing / epsilon: 0 / score: 505.5258984565735\n",
      "step: 1139931 / episode: 400 / progress: Testing / epsilon: 0 / score: 2149.4385803863406\n",
      "step: 1143816 / episode: 401 / progress: Testing / epsilon: 0 / score: 1713.8049250394106\n",
      "step: 1147925 / episode: 402 / progress: Testing / epsilon: 0 / score: 2302.1187744364142\n",
      "Finished!!\n"
     ]
    }
   ],
   "source": [
    "check_plot = 0\n",
    "\n",
    "# Training & Testing\n",
    "while True:\n",
    "   \n",
    "    # Get Progress, train mode\n",
    "    progress, train_mode, Epsilon  = get_progress(step, Epsilon)\n",
    "    \n",
    "    # Select Actions \n",
    "    action, Q_value = select_action(progress, sess, state_stack, Epsilon)\n",
    "    action_in = [np.argmax(action)]\n",
    "    \n",
    "    # Get information for plotting\n",
    "    vehicle_speed  = 100 * env_info.vector_observations[0][-8]\n",
    "    num_overtake   = env_info.vector_observations[0][-7]\n",
    "    num_lanechange = env_info.vector_observations[0][-6]\n",
    "    \n",
    "    # Get information for update\n",
    "    env_info = env.step(action_in)[default_brain]\n",
    "\n",
    "    next_state_stack, state_set = resize_state(env_info, state_set) \n",
    "    reward = env_info.rewards[0]\n",
    "    terminal = env_info.local_done[0]\n",
    "    \n",
    "    if progress == 'Training':\n",
    "        # Train!! \n",
    "        train(Replay_memory, sess, step)\n",
    "\n",
    "        # Save the variables to disk.\n",
    "        if step == Num_start_training + Num_training:\n",
    "            save_path = saver.save(sess, '../saved_networks/' + date_time + '_' + algorithm + '_sensor' + \"/model.ckpt\")\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "    # If progress is finished -> close! \n",
    "    if progress == 'Finished':\n",
    "        print('Finished!!')\n",
    "        env.close()\n",
    "        break\n",
    "        \n",
    "    Replay_memory = Experience_Replay(progress, \n",
    "                                      Replay_memory, \n",
    "                                      state_stack,\n",
    "                                      action, \n",
    "                                      reward, \n",
    "                                      next_state_stack,\n",
    "                                      terminal)\n",
    "    \n",
    "    # Update information\n",
    "    step += 1\n",
    "    score += reward\n",
    "    step_per_episode += 1\n",
    "    \n",
    "    state_stack = next_state_stack\n",
    "    \n",
    "    # Update tensorboard\n",
    "    if progress != 'Observing':\n",
    "        speed_list.append(vehicle_speed)\n",
    "        \n",
    "        if episode % Num_plot_episode == 0 and check_plot == 1 and episode != 0:\n",
    "            avg_speed      = sum(speed_list) / len(speed_list)\n",
    "            avg_overtake   = sum(overtake_list) / len(overtake_list)\n",
    "            avg_lanechange = sum(lanechange_list) / len(lanechange_list)\n",
    "            \n",
    "            tensorboard_info = [avg_speed, avg_overtake, avg_lanechange]\n",
    "            for i in range(len(tensorboard_info)):\n",
    "                sess.run(update_ops[i], feed_dict = {summary_placeholders[i]: float(tensorboard_info[i])})\n",
    "            summary_str = sess.run(summary_op)\n",
    "            summary_writer.add_summary(summary_str, step)\n",
    "            score_board = 0\n",
    "            \n",
    "            speed_list = []\n",
    "            overtake_list = []\n",
    "            lanechange_list = []\n",
    "\n",
    "            check_plot = 0\n",
    "            \n",
    "    # If terminal is True\n",
    "    if terminal == True:\n",
    "        # Print informations\n",
    "        print('step: ' + str(step) + ' / '  + 'episode: ' + str(episode) + ' / ' + 'progress: ' + progress  + ' / ' + 'epsilon: ' + str(Epsilon)  +' / ' + 'score: ' + str(score))\n",
    "\n",
    "        check_plot = 1\n",
    "\n",
    "        if progress != 'Observing':\n",
    "            episode += 1\n",
    "            \n",
    "            score_board += score\n",
    "            overtake_list.append(num_overtake)\n",
    "            lanechange_list.append(num_lanechange)\n",
    "        \n",
    "            \n",
    "        score = 0\n",
    "        step_per_episode = 0\n",
    "\n",
    "        # Initialize game state\n",
    "        env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "        state_stack, state_set = state_initialization(env_info)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
