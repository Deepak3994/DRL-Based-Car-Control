{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRL Based Self Driving Car Control (Sensor)\n",
    "\n",
    "## Distributional Reinforcement Learning with Quantile Regression\n",
    "\n",
    "This notebook is DRL code for the project 'DRL based Self Driving Car Control' <br>\n",
    "This version uses **Sensor data from LIDAR** as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Q\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment path\n",
    "\n",
    "Be sure to set `env_name` to the name of the Unity environment file you want to launch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"../windows/windows\" # Name of the Unity environment to launch\n",
    "train_mode = True # Whether to run the environment in training or inference mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the environment\n",
    "`UnityEnvironment` launches and begins communication with the environment when instantiated.\n",
    "\n",
    "Environments contain _brains_ which are responsible for deciding the actions of their associated _agents_. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: Brain\n",
      "        Number of Visual Observations (per agent): 1\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 373\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 5\n",
      "        Vector Action descriptions: , , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: Brain\n",
      "        Number of Visual Observations (per agent): 1\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 373\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 5\n",
      "        Vector Action descriptions: , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_name)\n",
    "\n",
    "# Examine environment parameters\n",
    "print(str(env))\n",
    "\n",
    "# Set the default brain to work with\n",
    "default_brain = env.brain_names[0]\n",
    "brain = env.brains[default_brain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the observation and state spaces\n",
    "We can reset the environment to be provided with an initial set of observations and states for all the agents within the environment. In ML-Agents, _states_ refer to a vector of variables corresponding to relevant aspects of the environment for an agent. Likewise, _observations_ refer to a set of relevant pixel-wise visuals for an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor data (LIDAR): \n",
      "[  1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   0.9755246    0.91600198   0.86357307   0.81705666   0.77551937\n",
      "   0.73821479   0.70453942   0.67399871   0.64618438   0.62075633\n",
      "   0.59742886   0.57596022   0.5561446    0.53780544   0.52079082\n",
      "   0.50496876   0.49022466   0.47645816   0.46358114   0.45151567\n",
      "   0.44019303   0.42955208   0.41953811   0.41010255   0.40120158\n",
      "   0.39279586   0.38485005   0.37733197   0.37021253   0.36346549\n",
      "   0.35706681   0.35099453   0.34522879   0.33975118   0.33454502\n",
      "   0.32959491   0.32488668   0.32040724   0.31614468   0.31208783\n",
      "   0.30822647   0.30455115   0.30105308   0.29772413   0.29455668\n",
      "   0.29154381   0.288679     0.28595623   0.28336981   0.2809146\n",
      "   0.27858567   0.27637851   0.27428898   0.27231315   0.27044734\n",
      "   0.26868826   0.26703268   0.26547778   0.26402083   0.26265934\n",
      "   0.26139107   0.26021382   0.25912577   0.25812501   0.25721005\n",
      "   0.25637937   0.25563163   0.25496569   0.25438049   0.25387514\n",
      "   0.25344881   0.25310093   0.25283089   0.25263828   0.25252286\n",
      "   0.25248438   0.25252286   0.25263828   0.25283089   0.25310093\n",
      "   0.25344881   0.25387514   0.25438049   0.25496572   0.25563163\n",
      "   0.25637937   0.25721005   0.25812504   0.25912577   0.26021382\n",
      "   0.2613911    0.26265937   0.26402086   0.26547781   0.26703271\n",
      "   0.26868829   0.27044743   0.27231318   0.27428904   0.27637854\n",
      "   0.27858567   0.28091457   0.28336984   0.2859562    0.28867906\n",
      "   0.29154381   0.29455668   0.29772413   0.30105308   0.30455118\n",
      "   0.3082265    0.3120878    0.31614468   0.32040721   0.32488671\n",
      "   0.32959491   0.33454508   0.33975121   0.34522879   0.35099462\n",
      "   0.35706681   0.36346555   0.37021261   0.37733203   0.38485011\n",
      "   0.39279595   0.40120178   0.41010267   0.4195382    0.42955217\n",
      "   0.44019303   0.45151576   0.46358114   0.47645825   0.49022475\n",
      "   0.50496876   0.52079082   0.53780544   0.8056162    0.79863602\n",
      "   0.79201484   0.78574008   0.77979958   0.7741822    0.7688778\n",
      "   0.76387662   0.75916994   0.7547493    0.75060725   0.74673665\n",
      "   0.7431308    0.739784     0.73669058   0.73384559   0.73124427\n",
      "   0.72888267   0.72675687   0.72486359   0.7231999    0.72176319\n",
      "   0.72055119   0.71956211   0.71879435   0.71824682   0.71791863\n",
      "   0.71780932   1.           0.73828739   0.73885024   0.7396394\n",
      "   0.74065602   0.74190187   0.74337864   0.74508876   0.74703485\n",
      "   0.72526538   0.72761542   0.73020375   0.73303467   0.73611271\n",
      "   0.73944294   0.74303085   0.74688226   0.7510038    0.75540245\n",
      "   0.76008582   0.76506215   0.77034026   0.77592981   0.78184074\n",
      "   0.78808439   0.79467267   0.80161822   0.80893487   0.52898562\n",
      "   0.51291454   0.49793857   0.48395553   0.47087574   0.45862055\n",
      "   0.44711965   0.4363113    0.42613983   0.41655573   0.40751475\n",
      "   0.399611     0.38823813   0.3806538    0.3734718    0.3666653\n",
      "   0.36021024   0.35408458   0.34826803   0.34274226   0.33749029\n",
      "   0.33249652   0.32774684   0.32322803   0.31892782   0.31483531\n",
      "   0.31093997   0.30723232   0.30370349   0.30034512   0.29714981\n",
      "   0.29411048   0.29122046   0.2884737    0.28881615   0.29910675\n",
      "   0.31025571   0.32237002   0.33557519   0.35001999   0.36588031\n",
      "   0.38336843   0.40274113   0.42431211   0.44846955   0.24207902\n",
      "   0.24091013   0.2398251    0.2388223    0.25435534   0.71093136\n",
      "   0.70863533   0.7065686    0.70472795   0.70311046   0.70171368\n",
      "   0.70053536   0.69957376   0.69882733   0.698295     0.69797587\n",
      "   0.6978696    1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   0.46766621   0.39589906   0.38227844   0.36967266   0.35797733\n",
      "   0.34710175   0.33696681   0.32750422   0.3186529    0.31535536\n",
      "   0.31916118   0.32315952   0.32736021   0.33177397   0.33641231\n",
      "   0.34128767   0.34641343   0.35180423   0.35747606   0.36344635\n",
      "   0.36973414   0.37635988   0.3833462    0.39071813   0.39850292\n",
      "   0.40673083   0.418935     0.41482678   0.42437106   0.43450052\n",
      "   0.44526401   0.45671701   0.46892133   0.48194665   0.49587208\n",
      "   0.51078594   0.59662944   0.57361192   0.57813853   0.58058214\n",
      "   0.57576889   0.57120734   0.58600146   0.61122501   0.63892192\n",
      "   0.66946077   0.78772271   0.8299135    0.89621913   0.95063126\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   0.           0.           0.           1.           0.\n",
      "   0.60000002   0.           0.           0.           0.\n",
      "   0.           0.         -10.        ]\n",
      "Image data (Front Camera): \n",
      "{}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reset the environment\n",
    "env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "\n",
    "# Examine the state space for the default brain\n",
    "print(\"Sensor data (LIDAR): \\n{}\".format(env_info.vector_observations[0]))\n",
    "\n",
    "# Examine the observation space for the default brain\n",
    "Num_obs = len(env_info.visual_observations)\n",
    "\n",
    "print(\"Image data (Front Camera): \\n{}\")\n",
    "if Num_obs > 1:\n",
    "    f, axarr = plt.subplots(1, Num_obs, figsize=(20,10))\n",
    "    for i, observation in enumerate(env_info.visual_observations):\n",
    "        if observation.shape[3] == 3:\n",
    "            axarr[i].imshow(observation[0,:,:,:])\n",
    "            axarr[i].axis('off')\n",
    "        else:\n",
    "            axarr[i].imshow(observation[0,:,:,0])\n",
    "            axarr[i].axis('off')\n",
    "else:\n",
    "    f, axarr = plt.subplots(1, Num_obs)\n",
    "    for i, observation in enumerate(env_info.visual_observations):\n",
    "        if observation.shape[3] == 3:\n",
    "            axarr.imshow(observation[0,:,:,:])\n",
    "            axarr.axis('off')\n",
    "        else:\n",
    "            axarr.imshow(observation[0,:,:,0])\n",
    "            axarr.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "algorithm = 'QR-DQN'\n",
    "Num_action = brain.vector_action_space_size\n",
    "\n",
    "# QR-DQN Parameter\n",
    "Num_quantile = 51\n",
    "        \n",
    "# parameter for DQN\n",
    "Num_replay_memory = 100000\n",
    "Num_start_training = 50000\n",
    "Num_training = 1000000\n",
    "Num_update = 10000\n",
    "Num_batch = 32\n",
    "Num_test = 100000\n",
    "Num_skipFrame = 4\n",
    "Num_stackFrame = 4\n",
    "Num_colorChannel = 1\n",
    "\n",
    "Epsilon = 1.0\n",
    "Final_epsilon = 0.1\n",
    "Gamma = 0.99\n",
    "Learning_rate = 0.00005\n",
    "\n",
    "# Parameter for LSTM\n",
    "Num_dataSize = 366\n",
    "Num_cellState = 512\n",
    "\n",
    "# Parameters for network\n",
    "img_size = 80\n",
    "sensor_size = 360\n",
    "\n",
    "first_dense  = [Num_cellState, 512]\n",
    "second_dense = [first_dense[1], Num_action * Num_quantile]\n",
    "\n",
    "# Path of the network model\n",
    "load_path = '../saved_networks/2018-09-12_0_19_QR-DQN_sensor/model.ckpt'\n",
    "\n",
    "# Parameters for session\n",
    "Num_plot_episode = 5\n",
    "Num_step_save = 50000\n",
    "\n",
    "GPU_fraction = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(xavier_initializer(shape))\n",
    "\n",
    "def bias_variable(shape):\n",
    "\treturn tf.Variable(xavier_initializer(shape))\n",
    "\n",
    "# Xavier Weights initializer\n",
    "def xavier_initializer(shape):\n",
    "\tdim_sum = np.sum(shape)\n",
    "\tif len(shape) == 1:\n",
    "\t\tdim_sum += 1\n",
    "\tbound = np.sqrt(2.0 / dim_sum)\n",
    "\treturn tf.random_uniform(shape, minval=-bound, maxval=bound)\n",
    "\n",
    "# Assign network variables to target network\n",
    "def assign_network_to_target():\n",
    "\t# Get trainable variables\n",
    "\ttrainable_variables = tf.trainable_variables()\n",
    "\t# network lstm variables\n",
    "\ttrainable_variables_network = [var for var in trainable_variables if var.name.startswith('network')]\n",
    "\n",
    "\t# target lstm variables\n",
    "\ttrainable_variables_target = [var for var in trainable_variables if var.name.startswith('target')]\n",
    "\n",
    "    # assign network variables to target network\n",
    "\tfor i in range(len(trainable_variables_network)):\n",
    "\t\tsess.run(tf.assign(trainable_variables_target[i], trainable_variables_network[i]))\n",
    "\n",
    "# Code for tensorboard\n",
    "def setup_summary():\n",
    "    episode_speed      = tf.Variable(0.)\n",
    "    episode_overtake   = tf.Variable(0.)\n",
    "    episode_lanechange = tf.Variable(0.)\n",
    "\n",
    "    tf.summary.scalar('Average_Speed/' + str(Num_plot_episode) + 'episodes', episode_speed)\n",
    "    tf.summary.scalar('Average_overtake/' + str(Num_plot_episode) + 'episodes', episode_overtake)\n",
    "    tf.summary.scalar('Average_lanechange/' + str(Num_plot_episode) + 'episodes', episode_lanechange)\n",
    "\n",
    "    summary_vars = [episode_speed, episode_overtake, episode_lanechange]\n",
    "    summary_placeholders = [tf.placeholder(tf.float32) for _ in range(len(summary_vars))]\n",
    "    update_ops = [summary_vars[i].assign(summary_placeholders[i]) for i in range(len(summary_vars))]\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    return summary_placeholders, update_ops, summary_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x_sensor = tf.placeholder(tf.float32, shape = [None, Num_stackFrame, Num_dataSize])\n",
    "x_unstack = tf.unstack(x_sensor, axis = 1)\n",
    "\n",
    "with tf.variable_scope('network'):\n",
    "\n",
    "    # LSTM cell\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units = Num_cellState)            \n",
    "    rnn_out, rnn_state = tf.nn.static_rnn(inputs = x_unstack, cell = cell, dtype = tf.float32)\n",
    "    \n",
    "    # Densely connect layer variables\n",
    "    w_fc1 = weight_variable(first_dense)\n",
    "    b_fc1 = bias_variable([first_dense[1]])\n",
    "\n",
    "    w_fc2 = weight_variable(second_dense)\n",
    "    b_fc2 = bias_variable([second_dense[1]])\n",
    "    \n",
    "    \n",
    "# Network\n",
    "rnn_out = rnn_out[-1]\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(rnn_out, w_fc1)+b_fc1)\n",
    "\n",
    "# Get Q value for each action\n",
    "logits = tf.matmul(h_fc1, w_fc2) + b_fc2\n",
    "logits_reshape = tf.reshape(logits, [-1, Num_action, Num_quantile])\n",
    "Q_action = tf.reduce_sum(tf.multiply(1/Num_quantile, logits_reshape), axis = 2)\n",
    "\n",
    "with tf.variable_scope('target'):\n",
    "    # LSTM cell\n",
    "    cell_target = tf.contrib.rnn.BasicLSTMCell(num_units = Num_cellState)            \n",
    "    rnn_out_target, rnn_state_target = tf.nn.static_rnn(inputs = x_unstack, cell = cell_target, dtype = tf.float32)\n",
    "\n",
    "    # Densely connect layer variables target\n",
    "    w_fc1_target = weight_variable(first_dense)\n",
    "    b_fc1_target = bias_variable([first_dense[1]])\n",
    "\n",
    "    w_fc2_target = weight_variable(second_dense)\n",
    "    b_fc2_target = bias_variable([second_dense[1]])\n",
    "    \n",
    "# Target Network\n",
    "rnn_out_target = rnn_out_target[-1]\n",
    "\n",
    "h_fc1_target  = tf.nn.relu(tf.matmul(rnn_out_target, w_fc1_target)+b_fc1_target)\n",
    "\n",
    "# Get Q value for each action\n",
    "logits_target = tf.matmul(h_fc1_target, w_fc2_target) + b_fc2_target\n",
    "logits_reshape_target = tf.reshape(logits_target, [-1, Num_action, Num_quantile])\n",
    "Q_action_target = tf.reduce_sum(tf.multiply(1/Num_quantile, logits_reshape_target), axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and Train\n",
    "theta_loss = tf.placeholder(tf.float32, shape = [None, Num_quantile])\n",
    "action_binary_loss = tf.placeholder(tf.float32, shape = [None, Num_action, Num_quantile])\n",
    "\n",
    "# Get valid logits \n",
    "logit_valid = tf.multiply(logits_reshape, action_binary_loss)\n",
    "logit_valid_nonzero = tf.reduce_sum(logit_valid, axis = 1)\n",
    "\n",
    "# Stack i and j\n",
    "theta_loss_tile = tf.tile(tf.expand_dims(theta_loss, axis=2), [1, 1, Num_quantile])\n",
    "logit_valid_tile = tf.tile(tf.expand_dims(logit_valid_nonzero, axis=1), [1, Num_quantile, 1])\n",
    "\n",
    "error_loss = theta_loss_tile - logit_valid_tile\n",
    "\n",
    "# Get Huber loss\n",
    "Huber_loss = tf.losses.huber_loss(theta_loss_tile, logit_valid_tile, reduction = tf.losses.Reduction.NONE)\n",
    "\n",
    "# Get tau\n",
    "min_tau = 1/(2*Num_quantile)\n",
    "max_tau = (2*(Num_quantile-1)+3)/(2*Num_quantile)\n",
    "tau = tf.reshape (tf.range(min_tau, max_tau, 1/Num_quantile), [1, Num_quantile])\n",
    "inv_tau = 1.0 - tau \n",
    "\n",
    "# Get Loss\n",
    "Loss = tf.where(tf.less(error_loss, 0.0), inv_tau * Huber_loss, tau * Huber_loss)\n",
    "Loss = tf.reduce_mean(tf.reduce_sum(tf.reduce_mean(Loss, axis = 2), axis = 1))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate = Learning_rate, epsilon = 1e-02/Num_batch).minimize(Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize variables\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = GPU_fraction\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training or Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference? / Training?(1=Inference/2=Training): 2\n"
     ]
    }
   ],
   "source": [
    "# Load the file if the saved file exists\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# check_save = 1\n",
    "check_save = input('Inference? / Training?(1=Inference/2=Training): ')\n",
    "\n",
    "if check_save == '1':\n",
    "    # Directly start inference\n",
    "    Num_start_training = 0\n",
    "    Num_training = 0\n",
    "    \n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, load_path)\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "# date - hour - minute of training time\n",
    "date_time = str(datetime.date.today()) + '_' + str(datetime.datetime.now().hour) + '_' + str(datetime.datetime.now().minute)\n",
    "\n",
    "# Make folder for save data\n",
    "os.makedirs('../saved_networks/' + date_time + '_' + algorithm + '_sensor')\n",
    "\n",
    "# Summary for tensorboard\n",
    "summary_placeholders, update_ops, summary_op = setup_summary()\n",
    "summary_writer = tf.summary.FileWriter('../saved_networks/' + date_time + '_' + algorithm + '_sensor', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize input \n",
    "def state_initialization(env_info):    \n",
    "    state = env_info.vector_observations[0][:-7]\n",
    "\n",
    "    state_set = []\n",
    "\n",
    "    for i in range(Num_skipFrame * Num_stackFrame):\n",
    "        state_set.append(state)\n",
    "    \n",
    "    # Stack the frame according to the number of skipping and stacking frames using observation set\n",
    "    state_stack = np.zeros((Num_stackFrame, Num_dataSize))\n",
    "    for stack_frame in range(Num_stackFrame):\n",
    "        state_stack[(Num_stackFrame - 1) - stack_frame, :] = state_set[-1 - (Num_skipFrame * stack_frame)]\n",
    "\n",
    "    state_stack = np.uint8(state_stack)\n",
    "\n",
    "    return state_stack, state_set\n",
    "\n",
    "# Resize input information \n",
    "def resize_state(env_info, state_set):\n",
    "    state = env_info.vector_observations[0][:-7]\n",
    "\n",
    "    # Add state to the state_set\n",
    "    state_set.append(state)\n",
    "    \n",
    "    # Stack the frame according to the number of skipping and stacking frames using observation set\n",
    "    state_stack = np.zeros((Num_stackFrame, Num_dataSize))\n",
    "    for stack_frame in range(Num_stackFrame):\n",
    "        state_stack[(Num_stackFrame - 1) - stack_frame, :] = state_set[-1 - (Num_skipFrame * stack_frame)]\n",
    "        \n",
    "    del state_set[0]\n",
    "\n",
    "    state_stack = np.uint8(state_stack)\n",
    "    \n",
    "    return state_stack, state_set\n",
    "\n",
    "# Get progress according to the number of steps\n",
    "def get_progress(step, Epsilon):\n",
    "    if step <= Num_start_training:\n",
    "        # Observation\n",
    "        progress = 'Observing'\n",
    "        train_mode = True\n",
    "        Epsilon = 1\n",
    "    elif step <= Num_start_training + Num_training:\n",
    "        # Training\n",
    "        progress = 'Training'\n",
    "        train_mode = True\n",
    "        \n",
    "        # Decrease the epsilon value\n",
    "        if Epsilon > Final_epsilon:\n",
    "            Epsilon -= 1.0/Num_training\n",
    "    elif step < Num_start_training + Num_training + Num_test:\n",
    "        # Testing\n",
    "        progress = 'Testing'\n",
    "        train_mode = False\n",
    "        Epsilon = 0\n",
    "    else:\n",
    "        # Finished\n",
    "        progress = 'Finished'\n",
    "        train_mode = False\n",
    "        Epsilon = 0\n",
    "        \n",
    "    return progress, train_mode, Epsilon \n",
    "\n",
    "# Select action according to the progress of training\n",
    "def select_action(progress, sess, observation_stack, Epsilon):\n",
    "    if progress == \"Observing\":\n",
    "        # Random action \n",
    "        Q_value = 0\n",
    "        action = np.zeros([Num_action])\n",
    "        action[random.randint(0, Num_action - 1)] = 1.0\n",
    "    elif progress == \"Training\":\n",
    "        # if random value(0-1) is smaller than Epsilon, action is random. \n",
    "        # Otherwise, action is the one which has the max Q value\n",
    "        if random.random() < Epsilon:\n",
    "            Q_value = 0\n",
    "            action = np.zeros([Num_action])\n",
    "            action[random.randint(0, Num_action - 1)] = 1\n",
    "        else:\n",
    "            Q_value = Q_action.eval(feed_dict={x_sensor: [state_stack]})\n",
    "            action = np.zeros([Num_action])\n",
    "            action[np.argmax(Q_value)] = 1\n",
    "    else:\n",
    "        # Max Q action \n",
    "        Q_value = Q_action.eval(feed_dict={x_sensor: [state_stack]})\n",
    "        action = np.zeros([Num_action])\n",
    "        action[np.argmax(Q_value)] = 1\n",
    "        \n",
    "    return action, Q_value\n",
    "\n",
    "def train(Replay_memory, sess, step):\n",
    "    # Select minibatch\n",
    "    minibatch =  random.sample(Replay_memory, Num_batch)\n",
    "\n",
    "    # Save the each batch data\n",
    "    state_batch      = [batch[0] for batch in minibatch]\n",
    "    action_batch     = [batch[1] for batch in minibatch]\n",
    "    reward_batch     = [batch[2] for batch in minibatch]\n",
    "    state_next_batch = [batch[3] for batch in minibatch]\n",
    "    terminal_batch \t = [batch[4] for batch in minibatch]\n",
    "\n",
    "    # Update target network according to the Num_update value\n",
    "    if step % Num_update == 0:\n",
    "        assign_network_to_target()\n",
    "    \n",
    "    \n",
    "    # Get Target\n",
    "    Q_batch = Q_action.eval(feed_dict = {x_sensor: state_next_batch})\n",
    "    theta_batch = logits_reshape_target.eval(feed_dict = {x_sensor: state_next_batch})\n",
    "\n",
    "    theta_target = []\n",
    "\n",
    "    for i in range(len(minibatch)):\n",
    "        theta_target.append([])\n",
    "        for j in range(Num_quantile):\n",
    "            if terminal_batch[i] == True:\n",
    "                theta_target[i].append(reward_batch[i])\n",
    "            else:\n",
    "                theta_target[i].append(reward_batch[i] + Gamma * theta_batch[i, np.argmax(Q_batch[i]), j])\n",
    "\n",
    "    # Calculate action binary\n",
    "    action_binary = np.zeros([Num_batch, Num_action, Num_quantile])\n",
    "\n",
    "    for i in range(len(action_batch)):\n",
    "        action_batch_max = np.argmax(action_batch[i])\n",
    "        action_binary[i, action_batch_max, :] = 1\n",
    "\n",
    "    _, loss = sess.run([train_step, Loss],feed_dict = {x_sensor: state_batch,\n",
    "                                                       theta_loss: theta_target, \n",
    "                                                       action_binary_loss: action_binary})\n",
    "\n",
    "# Experience Replay \n",
    "def Experience_Replay(progress, Replay_memory, state_stack, action, reward, next_state_stack, terminal):\n",
    "    if progress != 'Testing':\n",
    "        # If length of replay memeory is more than the setting value then remove the first one\n",
    "        if len(Replay_memory) > Num_replay_memory:\n",
    "            del Replay_memory[0]\n",
    "\n",
    "        # Save experience to the Replay memory\n",
    "        Replay_memory.append([state_stack, action, reward, next_state_stack, terminal])\n",
    "    else:\n",
    "        # Empty the replay memory if testing\n",
    "        Replay_memory = []\n",
    "    \n",
    "    return Replay_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "Replay_memory = []\n",
    "\n",
    "step = 1\n",
    "score = 0\n",
    "score_board = 0\n",
    "\n",
    "episode = 0\n",
    "step_per_episode = 0\n",
    "\n",
    "speed_list = []\n",
    "overtake_list = []\n",
    "lanechange_list = []\n",
    "\n",
    "train_mode = True\n",
    "env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "\n",
    "state_stack, state_set = state_initialization(env_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 4518 / episode: 0 / progress: Observing / epsilon: 1 / score: 1774.4308096468449\n",
      "step: 9223 / episode: 0 / progress: Observing / epsilon: 1 / score: 1561.15655464679\n",
      "step: 10493 / episode: 0 / progress: Observing / epsilon: 1 / score: 468.3725060224533\n",
      "step: 15296 / episode: 0 / progress: Observing / epsilon: 1 / score: 1452.4769280925393\n",
      "step: 18728 / episode: 0 / progress: Observing / epsilon: 1 / score: 984.6319274827838\n",
      "step: 23451 / episode: 0 / progress: Observing / epsilon: 1 / score: 1527.9668709635735\n",
      "step: 24691 / episode: 0 / progress: Observing / epsilon: 1 / score: 298.7393363714218\n",
      "step: 29568 / episode: 0 / progress: Observing / epsilon: 1 / score: 1377.9948867112398\n",
      "step: 32670 / episode: 0 / progress: Observing / epsilon: 1 / score: 1182.637726791203\n",
      "step: 37327 / episode: 0 / progress: Observing / epsilon: 1 / score: 1614.9977910667658\n",
      "step: 41952 / episode: 0 / progress: Observing / epsilon: 1 / score: 1642.6178614646196\n",
      "step: 46829 / episode: 0 / progress: Observing / epsilon: 1 / score: 1381.755805067718\n",
      "step: 47634 / episode: 0 / progress: Observing / epsilon: 1 / score: 290.31790766865015\n",
      "step: 48493 / episode: 0 / progress: Observing / epsilon: 1 / score: 276.34998325258493\n",
      "step: 52203 / episode: 0 / progress: Training / epsilon: 0.9977979999999367 / score: 1136.681589744985\n",
      "step: 56984 / episode: 1 / progress: Training / epsilon: 0.9930169999997992 / score: 1479.5931779891253\n",
      "step: 61753 / episode: 2 / progress: Training / epsilon: 0.9882479999996621 / score: 1505.6959212869406\n",
      "step: 66615 / episode: 3 / progress: Training / epsilon: 0.9833859999995223 / score: 1409.0132970362902\n",
      "step: 69667 / episode: 4 / progress: Training / epsilon: 0.9803339999994345 / score: 1217.2624384239316\n",
      "step: 74184 / episode: 5 / progress: Training / epsilon: 0.9758169999993046 / score: 1769.9012565687299\n",
      "step: 76580 / episode: 6 / progress: Training / epsilon: 0.9734209999992357 / score: 396.4234222397208\n",
      "step: 81482 / episode: 7 / progress: Training / epsilon: 0.9685189999990947 / score: 1359.7266537547112\n",
      "step: 85733 / episode: 8 / progress: Training / epsilon: 0.9642679999989725 / score: 2064.9502471238375\n",
      "step: 90289 / episode: 9 / progress: Training / epsilon: 0.9597119999988415 / score: 1739.8833572864532\n",
      "step: 94553 / episode: 10 / progress: Training / epsilon: 0.9554479999987189 / score: 2055.110790684819\n",
      "step: 95345 / episode: 11 / progress: Training / epsilon: 0.9546559999986961 / score: 394.9541030153632\n",
      "step: 99987 / episode: 12 / progress: Training / epsilon: 0.9500139999985626 / score: 1646.932741202414\n",
      "step: 102610 / episode: 13 / progress: Training / epsilon: 0.9473909999984872 / score: 1046.771007552743\n",
      "step: 106711 / episode: 14 / progress: Training / epsilon: 0.9432899999983693 / score: 1940.6652124971151\n",
      "step: 111247 / episode: 15 / progress: Training / epsilon: 0.9387539999982388 / score: 1746.4015046656132\n",
      "step: 114193 / episode: 16 / progress: Training / epsilon: 0.9358079999981541 / score: 1389.700110733509\n",
      "step: 115766 / episode: 17 / progress: Training / epsilon: 0.9342349999981089 / score: 664.6030255630612\n",
      "step: 118499 / episode: 18 / progress: Training / epsilon: 0.9315019999980303 / score: 1098.1231065019965\n",
      "step: 122809 / episode: 19 / progress: Training / epsilon: 0.9271919999979064 / score: 2001.7300264760852\n",
      "step: 126169 / episode: 20 / progress: Training / epsilon: 0.9238319999978097 / score: 1662.5043468996882\n",
      "step: 129166 / episode: 21 / progress: Training / epsilon: 0.9208349999977236 / score: 976.1663671582937\n",
      "step: 132473 / episode: 22 / progress: Training / epsilon: 0.9175279999976285 / score: 1768.2672346308827\n",
      "step: 133185 / episode: 23 / progress: Training / epsilon: 0.916815999997608 / score: 348.12787115573883\n",
      "step: 137331 / episode: 24 / progress: Training / epsilon: 0.9126699999974888 / score: 1949.5173987448215\n",
      "step: 141561 / episode: 25 / progress: Training / epsilon: 0.9084399999973671 / score: 2083.1207911893725\n",
      "step: 145775 / episode: 26 / progress: Training / epsilon: 0.904225999997246 / score: 2088.7325999215245\n",
      "step: 150108 / episode: 27 / progress: Training / epsilon: 0.8998929999971214 / score: 1963.7590678036213\n",
      "step: 150542 / episode: 28 / progress: Training / epsilon: 0.8994589999971089 / score: 211.96585593372583\n",
      "step: 155059 / episode: 29 / progress: Training / epsilon: 0.894941999996979 / score: 1788.029511526227\n",
      "step: 159443 / episode: 30 / progress: Training / epsilon: 0.8905579999968529 / score: 1921.3921448811889\n",
      "step: 161814 / episode: 31 / progress: Training / epsilon: 0.8881869999967847 / score: 899.5508226454258\n",
      "step: 163925 / episode: 32 / progress: Training / epsilon: 0.886075999996724 / score: 946.4598457887769\n",
      "step: 166984 / episode: 33 / progress: Training / epsilon: 0.8830169999966361 / score: 1390.9437606707215\n",
      "step: 171110 / episode: 34 / progress: Training / epsilon: 0.8788909999965174 / score: 2205.4460415765643\n",
      "step: 175070 / episode: 35 / progress: Training / epsilon: 0.8749309999964036 / score: 2379.9532336741686\n",
      "step: 179303 / episode: 36 / progress: Training / epsilon: 0.8706979999962818 / score: 2098.217691682279\n",
      "step: 181156 / episode: 37 / progress: Training / epsilon: 0.8688449999962286 / score: 1126.249820113182\n",
      "step: 182341 / episode: 38 / progress: Training / epsilon: 0.8676599999961945 / score: 410.94361187517643\n",
      "step: 183850 / episode: 39 / progress: Training / epsilon: 0.8661509999961511 / score: 659.1065204590559\n",
      "step: 184404 / episode: 40 / progress: Training / epsilon: 0.8655969999961352 / score: 282.50902485102415\n",
      "step: 188694 / episode: 41 / progress: Training / epsilon: 0.8613069999960118 / score: 2023.11653791368\n",
      "step: 191525 / episode: 42 / progress: Training / epsilon: 0.8584759999959304 / score: 1650.0625108405948\n",
      "step: 191863 / episode: 43 / progress: Training / epsilon: 0.8581379999959207 / score: 202.87028181552887\n",
      "step: 194552 / episode: 44 / progress: Training / epsilon: 0.8554489999958433 / score: 915.8017700538039\n",
      "step: 198744 / episode: 45 / progress: Training / epsilon: 0.8512569999957228 / score: 2137.0123232901096\n",
      "step: 203149 / episode: 46 / progress: Training / epsilon: 0.8468519999955961 / score: 1909.7315625920892\n",
      "step: 207129 / episode: 47 / progress: Training / epsilon: 0.8428719999954817 / score: 2373.6188565790653\n",
      "step: 208936 / episode: 48 / progress: Training / epsilon: 0.8410649999954297 / score: 1087.6914602294564\n",
      "step: 212855 / episode: 49 / progress: Training / epsilon: 0.837145999995317 / score: 2427.5224697738886\n",
      "step: 215214 / episode: 50 / progress: Training / epsilon: 0.8347869999952492 / score: 1178.9784399345517\n",
      "step: 216312 / episode: 51 / progress: Training / epsilon: 0.8336889999952176 / score: 564.1679051220417\n",
      "step: 220301 / episode: 52 / progress: Training / epsilon: 0.8296999999951029 / score: 2346.3988711237907\n",
      "step: 223712 / episode: 53 / progress: Training / epsilon: 0.8262889999950048 / score: 1737.1754372045398\n",
      "step: 223939 / episode: 54 / progress: Training / epsilon: 0.8260619999949983 / score: 108.10092078149319\n",
      "step: 227802 / episode: 55 / progress: Training / epsilon: 0.8221989999948872 / score: 2483.451453104615\n",
      "step: 231710 / episode: 56 / progress: Training / epsilon: 0.8182909999947748 / score: 2446.7476317360997\n",
      "step: 232541 / episode: 57 / progress: Training / epsilon: 0.8174599999947509 / score: 388.8894042596221\n",
      "step: 234733 / episode: 58 / progress: Training / epsilon: 0.8152679999946879 / score: 1182.905608355999\n",
      "step: 235583 / episode: 59 / progress: Training / epsilon: 0.8144179999946635 / score: 520.7090765461326\n",
      "step: 237429 / episode: 60 / progress: Training / epsilon: 0.8125719999946104 / score: 1214.9743695780635\n",
      "step: 241616 / episode: 61 / progress: Training / epsilon: 0.80838499999449 / score: 2151.486640751362\n",
      "step: 241929 / episode: 62 / progress: Training / epsilon: 0.808071999994481 / score: 215.80839076638222\n",
      "step: 246474 / episode: 63 / progress: Training / epsilon: 0.8035269999943503 / score: 1756.1408601999283\n",
      "step: 246897 / episode: 64 / progress: Training / epsilon: 0.8031039999943381 / score: 296.4120843112469\n",
      "step: 250666 / episode: 65 / progress: Training / epsilon: 0.7993349999942297 / score: 2138.8164824917912\n",
      "step: 254665 / episode: 66 / progress: Training / epsilon: 0.7953359999941148 / score: 2339.1265668421984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 254853 / episode: 67 / progress: Training / epsilon: 0.7951479999941093 / score: 89.35527832061052\n",
      "step: 255946 / episode: 68 / progress: Training / epsilon: 0.7940549999940779 / score: 469.6424149721861\n",
      "step: 256808 / episode: 69 / progress: Training / epsilon: 0.7931929999940531 / score: 522.3373877629638\n",
      "step: 257645 / episode: 70 / progress: Training / epsilon: 0.7923559999940291 / score: 518.8961923271418\n",
      "step: 261904 / episode: 71 / progress: Training / epsilon: 0.7880969999939066 / score: 2056.3571939617395\n",
      "step: 265333 / episode: 72 / progress: Training / epsilon: 0.784667999993808 / score: 1655.9587793946266\n",
      "step: 269950 / episode: 73 / progress: Training / epsilon: 0.7800509999936752 / score: 1667.5962187573314\n",
      "step: 273970 / episode: 74 / progress: Training / epsilon: 0.7760309999935596 / score: 2326.936546690762\n",
      "step: 275725 / episode: 75 / progress: Training / epsilon: 0.7742759999935092 / score: 936.5852511823177\n",
      "step: 280125 / episode: 76 / progress: Training / epsilon: 0.7698759999933826 / score: 1912.7150151133537\n",
      "step: 283913 / episode: 77 / progress: Training / epsilon: 0.7660879999932737 / score: 2568.2605917602777\n",
      "step: 284707 / episode: 78 / progress: Training / epsilon: 0.7652939999932509 / score: 439.03588522970676\n",
      "step: 288749 / episode: 79 / progress: Training / epsilon: 0.7612519999931346 / score: 2306.751899212599\n",
      "step: 292819 / episode: 80 / progress: Training / epsilon: 0.7571819999930176 / score: 2276.2533541321754\n",
      "step: 295751 / episode: 81 / progress: Training / epsilon: 0.7542499999929333 / score: 1635.1518270671368\n",
      "step: 300416 / episode: 82 / progress: Training / epsilon: 0.7495849999927992 / score: 1635.4335936009884\n",
      "step: 300962 / episode: 83 / progress: Training / epsilon: 0.7490389999927834 / score: 315.913960121572\n",
      "step: 304923 / episode: 84 / progress: Training / epsilon: 0.7450779999926695 / score: 2390.967999614775\n",
      "step: 305296 / episode: 85 / progress: Training / epsilon: 0.7447049999926588 / score: 302.4601425230503\n",
      "step: 306942 / episode: 86 / progress: Training / epsilon: 0.7430589999926115 / score: 1041.8042156100273\n",
      "step: 310912 / episode: 87 / progress: Training / epsilon: 0.7390889999924973 / score: 2375.4003066644073\n",
      "step: 315047 / episode: 88 / progress: Training / epsilon: 0.7349539999923784 / score: 2192.7916378751397\n",
      "step: 315909 / episode: 89 / progress: Training / epsilon: 0.7340919999923536 / score: 465.1531117707491\n",
      "step: 316339 / episode: 90 / progress: Training / epsilon: 0.7336619999923413 / score: 280.6521611958742\n",
      "step: 317758 / episode: 91 / progress: Training / epsilon: 0.7322429999923005 / score: 935.508239209652\n",
      "step: 322163 / episode: 92 / progress: Training / epsilon: 0.7278379999921738 / score: 1917.8712749034166\n",
      "step: 323100 / episode: 93 / progress: Training / epsilon: 0.7269009999921469 / score: 577.4303592294455\n",
      "step: 327063 / episode: 94 / progress: Training / epsilon: 0.7229379999920329 / score: 2392.555436819792\n",
      "step: 330989 / episode: 95 / progress: Training / epsilon: 0.71901199999192 / score: 2415.636571146548\n",
      "step: 335246 / episode: 96 / progress: Training / epsilon: 0.7147549999917976 / score: 2077.57395272702\n",
      "step: 339339 / episode: 97 / progress: Training / epsilon: 0.7106619999916799 / score: 2250.132800370455\n",
      "step: 343456 / episode: 98 / progress: Training / epsilon: 0.7065449999915615 / score: 2223.8057716712356\n",
      "step: 347831 / episode: 99 / progress: Training / epsilon: 0.7021699999914357 / score: 1959.6858442425728\n",
      "step: 351285 / episode: 100 / progress: Training / epsilon: 0.6987159999913364 / score: 1955.4279799237847\n",
      "step: 355618 / episode: 101 / progress: Training / epsilon: 0.6943829999912118 / score: 1997.3404514789581\n",
      "step: 359004 / episode: 102 / progress: Training / epsilon: 0.6909969999911144 / score: 1518.4838022887707\n",
      "step: 363094 / episode: 103 / progress: Training / epsilon: 0.6869069999909968 / score: 2256.7111697793007\n",
      "step: 363365 / episode: 104 / progress: Training / epsilon: 0.686635999990989 / score: 195.36735949665308\n",
      "step: 367459 / episode: 105 / progress: Training / epsilon: 0.6825419999908713 / score: 2250.76016253978\n",
      "step: 371184 / episode: 106 / progress: Training / epsilon: 0.6788169999907642 / score: 2657.286038272083\n",
      "step: 375303 / episode: 107 / progress: Training / epsilon: 0.6746979999906457 / score: 2226.3363477662206\n",
      "step: 379944 / episode: 108 / progress: Training / epsilon: 0.6700569999905123 / score: 1667.6390345990658\n",
      "step: 380324 / episode: 109 / progress: Training / epsilon: 0.6696769999905013 / score: 323.87499606609344\n",
      "step: 380855 / episode: 110 / progress: Training / epsilon: 0.6691459999904861 / score: 352.4660373926163\n",
      "step: 384944 / episode: 111 / progress: Training / epsilon: 0.6650569999903685 / score: 2254.8377855345607\n",
      "step: 388775 / episode: 112 / progress: Training / epsilon: 0.6612259999902583 / score: 2540.629129253328\n",
      "step: 391895 / episode: 113 / progress: Training / epsilon: 0.6581059999901686 / score: 1961.2448593452573\n",
      "step: 393117 / episode: 114 / progress: Training / epsilon: 0.6568839999901335 / score: 867.8048639968038\n",
      "step: 397562 / episode: 115 / progress: Training / epsilon: 0.6524389999900057 / score: 1884.949216246605\n",
      "step: 399435 / episode: 116 / progress: Training / epsilon: 0.6505659999899518 / score: 822.3889574930072\n",
      "step: 399617 / episode: 117 / progress: Training / epsilon: 0.6503839999899466 / score: 141.24999889731407\n",
      "step: 403778 / episode: 118 / progress: Training / epsilon: 0.6462229999898269 / score: 2186.3752915486693\n",
      "step: 406067 / episode: 119 / progress: Training / epsilon: 0.6439339999897611 / score: 1623.2891956344247\n",
      "step: 406764 / episode: 120 / progress: Training / epsilon: 0.643236999989741 / score: 586.0725045949221\n",
      "step: 410233 / episode: 121 / progress: Training / epsilon: 0.6397679999896413 / score: 1533.2236014306545\n",
      "step: 414181 / episode: 122 / progress: Training / epsilon: 0.6358199999895278 / score: 2412.383727557957\n",
      "step: 418093 / episode: 123 / progress: Training / epsilon: 0.6319079999894153 / score: 2443.9954257681966\n",
      "step: 420170 / episode: 124 / progress: Training / epsilon: 0.6298309999893555 / score: 1511.7067507952452\n",
      "step: 423419 / episode: 125 / progress: Training / epsilon: 0.6265819999892621 / score: 2367.3621410429478\n",
      "step: 424824 / episode: 126 / progress: Training / epsilon: 0.6251769999892217 / score: 696.8965527936816\n",
      "step: 428720 / episode: 127 / progress: Training / epsilon: 0.6212809999891097 / score: 2466.7490073293447\n",
      "step: 432547 / episode: 128 / progress: Training / epsilon: 0.6174539999889996 / score: 2069.0472244024277\n",
      "step: 433620 / episode: 129 / progress: Training / epsilon: 0.6163809999889688 / score: 685.1422947272658\n",
      "step: 435785 / episode: 130 / progress: Training / epsilon: 0.6142159999889065 / score: 1516.7725437358022\n",
      "step: 440073 / episode: 131 / progress: Training / epsilon: 0.6099279999887832 / score: 2058.6043555885553\n",
      "step: 440676 / episode: 132 / progress: Training / epsilon: 0.6093249999887659 / score: 464.68878042697906\n",
      "step: 444756 / episode: 133 / progress: Training / epsilon: 0.6052449999886486 / score: 2260.937687844038\n",
      "step: 445996 / episode: 134 / progress: Training / epsilon: 0.6040049999886129 / score: 843.4809810891747\n",
      "step: 447931 / episode: 135 / progress: Training / epsilon: 0.6020699999885573 / score: 1240.3065619170666\n",
      "step: 451943 / episode: 136 / progress: Training / epsilon: 0.5980579999884419 / score: 2355.5530839934945\n",
      "step: 455522 / episode: 137 / progress: Training / epsilon: 0.594478999988339 / score: 2808.140098966658\n",
      "step: 459496 / episode: 138 / progress: Training / epsilon: 0.5905049999882247 / score: 2376.9671587720513\n",
      "step: 459941 / episode: 139 / progress: Training / epsilon: 0.5900599999882119 / score: 348.44762539863586\n",
      "step: 460959 / episode: 140 / progress: Training / epsilon: 0.5890419999881826 / score: 461.86801064014435\n",
      "step: 463551 / episode: 141 / progress: Training / epsilon: 0.5864499999881081 / score: 1543.6846085339785\n",
      "step: 467589 / episode: 142 / progress: Training / epsilon: 0.582411999987992 / score: 2311.8477190211415\n",
      "step: 468781 / episode: 143 / progress: Training / epsilon: 0.5812199999879577 / score: 908.3265409395099\n",
      "step: 472805 / episode: 144 / progress: Training / epsilon: 0.577195999987842 / score: 2337.8052673339844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 474913 / episode: 145 / progress: Training / epsilon: 0.5750879999877814 / score: 1199.9221104457974\n",
      "step: 476084 / episode: 146 / progress: Training / epsilon: 0.5739169999877477 / score: 642.1448692083359\n",
      "step: 478771 / episode: 147 / progress: Training / epsilon: 0.5712299999876704 / score: 1713.757760323584\n",
      "step: 479216 / episode: 148 / progress: Training / epsilon: 0.5707849999876576 / score: 317.1966537386179\n",
      "step: 483310 / episode: 149 / progress: Training / epsilon: 0.5666909999875399 / score: 2256.2800573706627\n",
      "step: 487050 / episode: 150 / progress: Training / epsilon: 0.5629509999874324 / score: 2644.7772723138332\n",
      "step: 489057 / episode: 151 / progress: Training / epsilon: 0.5609439999873747 / score: 972.2706998735666\n",
      "step: 493162 / episode: 152 / progress: Training / epsilon: 0.5568389999872566 / score: 2241.3108214214444\n",
      "step: 495461 / episode: 153 / progress: Training / epsilon: 0.5545399999871905 / score: 1771.195482134819\n",
      "step: 499486 / episode: 154 / progress: Training / epsilon: 0.5505149999870748 / score: 2337.9896456450224\n",
      "step: 503140 / episode: 155 / progress: Training / epsilon: 0.5468609999869697 / score: 2215.9053679928184\n",
      "step: 503512 / episode: 156 / progress: Training / epsilon: 0.546488999986959 / score: 291.6881169974804\n",
      "step: 504801 / episode: 157 / progress: Training / epsilon: 0.5451999999869219 / score: 1113.2794248089194\n",
      "step: 505883 / episode: 158 / progress: Training / epsilon: 0.5441179999868908 / score: 734.0712184458971\n",
      "step: 509593 / episode: 159 / progress: Training / epsilon: 0.5404079999867841 / score: 2673.031584843993\n",
      "step: 510512 / episode: 160 / progress: Training / epsilon: 0.5394889999867577 / score: 619.9391456320882\n",
      "step: 511351 / episode: 161 / progress: Training / epsilon: 0.5386499999867336 / score: 543.6539794504642\n",
      "step: 512677 / episode: 162 / progress: Training / epsilon: 0.5373239999866954 / score: 786.6754549592733\n",
      "step: 516735 / episode: 163 / progress: Training / epsilon: 0.5332659999865788 / score: 2313.226907044649\n",
      "step: 517697 / episode: 164 / progress: Training / epsilon: 0.5323039999865511 / score: 770.7705616429448\n",
      "step: 521677 / episode: 165 / progress: Training / epsilon: 0.5283239999864366 / score: 2378.794014401734\n",
      "step: 523739 / episode: 166 / progress: Training / epsilon: 0.5262619999863773 / score: 1136.3668454363942\n",
      "step: 528248 / episode: 167 / progress: Training / epsilon: 0.5217529999862477 / score: 1810.5906012356281\n",
      "step: 532150 / episode: 168 / progress: Training / epsilon: 0.5178509999861355 / score: 2447.6030010804534\n",
      "step: 533049 / episode: 169 / progress: Training / epsilon: 0.5169519999861096 / score: 484.3828638494015\n",
      "step: 533465 / episode: 170 / progress: Training / epsilon: 0.5165359999860977 / score: 296.45535112172365\n",
      "step: 533795 / episode: 171 / progress: Training / epsilon: 0.5162059999860882 / score: 251.82604507356882\n",
      "step: 536445 / episode: 172 / progress: Training / epsilon: 0.513555999986012 / score: 1513.8968358412385\n",
      "step: 540186 / episode: 173 / progress: Training / epsilon: 0.5098149999859044 / score: 2426.652879603207\n",
      "step: 541967 / episode: 174 / progress: Training / epsilon: 0.5080339999858532 / score: 1044.8748370930552\n",
      "step: 545521 / episode: 175 / progress: Training / epsilon: 0.504479999985751 / score: 2608.170235991478\n",
      "step: 549469 / episode: 176 / progress: Training / epsilon: 0.5005319999856375 / score: 2420.415939897299\n",
      "step: 551342 / episode: 177 / progress: Training / epsilon: 0.4986589999856581 / score: 920.1094263792038\n",
      "step: 552815 / episode: 178 / progress: Training / epsilon: 0.4971859999856975 / score: 942.6525583043694\n",
      "step: 556710 / episode: 179 / progress: Training / epsilon: 0.4932909999858017 / score: 2470.5282779037952\n",
      "step: 558302 / episode: 180 / progress: Training / epsilon: 0.4916989999858443 / score: 946.9900346547365\n",
      "step: 560180 / episode: 181 / progress: Training / epsilon: 0.48982099998589457 / score: 1169.7736613675952\n",
      "step: 563441 / episode: 182 / progress: Training / epsilon: 0.4865599999859818 / score: 2039.9172364845872\n",
      "step: 567353 / episode: 183 / progress: Training / epsilon: 0.4826479999860865 / score: 2486.897711329162\n",
      "step: 568722 / episode: 184 / progress: Training / epsilon: 0.4812789999861231 / score: 971.1041900143027\n",
      "step: 572891 / episode: 185 / progress: Training / epsilon: 0.47710999998623466 / score: 2175.1252501904964\n",
      "step: 576908 / episode: 186 / progress: Training / epsilon: 0.47309299998634213 / score: 2359.0562323778868\n",
      "step: 580771 / episode: 187 / progress: Training / epsilon: 0.4692299999864455 / score: 2524.301162607968\n",
      "step: 585240 / episode: 188 / progress: Training / epsilon: 0.46476099998656506 / score: 1865.5041127800941\n",
      "step: 587826 / episode: 189 / progress: Training / epsilon: 0.46217499998663425 / score: 1819.609628111124\n",
      "step: 591773 / episode: 190 / progress: Training / epsilon: 0.45822799998673985 / score: 2411.955145224929\n",
      "step: 596217 / episode: 191 / progress: Training / epsilon: 0.45378399998685875 / score: 1889.5506823509932\n",
      "step: 598840 / episode: 192 / progress: Training / epsilon: 0.45116099998692893 / score: 1344.018078647554\n",
      "step: 599902 / episode: 193 / progress: Training / epsilon: 0.45009899998695735 / score: 668.2040231227875\n",
      "step: 601058 / episode: 194 / progress: Training / epsilon: 0.4489429999869883 / score: 819.8499265015125\n",
      "step: 605016 / episode: 195 / progress: Training / epsilon: 0.4449849999870942 / score: 2417.095354065299\n",
      "step: 607962 / episode: 196 / progress: Training / epsilon: 0.442038999987173 / score: 1529.8758909329772\n",
      "step: 611180 / episode: 197 / progress: Training / epsilon: 0.4388209999872591 / score: 2258.0580268651247\n",
      "step: 613509 / episode: 198 / progress: Training / epsilon: 0.4364919999873214 / score: 1870.0475763231516\n",
      "step: 615962 / episode: 199 / progress: Training / epsilon: 0.43403899998738704 / score: 1524.6719121932983\n",
      "step: 619469 / episode: 200 / progress: Training / epsilon: 0.4305319999874809 / score: 2355.264058060944\n",
      "step: 621606 / episode: 201 / progress: Training / epsilon: 0.42839499998753805 / score: 1757.637531004846\n",
      "step: 623575 / episode: 202 / progress: Training / epsilon: 0.42642599998759073 / score: 1143.1463541686535\n",
      "step: 627434 / episode: 203 / progress: Training / epsilon: 0.422566999987694 / score: 2524.457561261952\n",
      "step: 629568 / episode: 204 / progress: Training / epsilon: 0.4204329999877511 / score: 1308.4002621173859\n",
      "step: 631701 / episode: 205 / progress: Training / epsilon: 0.41829999998780815 / score: 1519.4529374465346\n",
      "step: 631954 / episode: 206 / progress: Training / epsilon: 0.4180469999878149 / score: 213.44999969005585\n",
      "step: 635876 / episode: 207 / progress: Training / epsilon: 0.41412499998791985 / score: 2457.6613442748785\n",
      "step: 636666 / episode: 208 / progress: Training / epsilon: 0.413334999987941 / score: 547.3318830356002\n",
      "step: 641517 / episode: 209 / progress: Training / epsilon: 0.4084839999880708 / score: 1436.1657336726785\n",
      "step: 642786 / episode: 210 / progress: Training / epsilon: 0.40721499998810473 / score: 1123.459480278194\n",
      "step: 644532 / episode: 211 / progress: Training / epsilon: 0.40546899998815145 / score: 1217.246799081564\n",
      "step: 648361 / episode: 212 / progress: Training / epsilon: 0.4016399999882539 / score: 2560.492423541844\n",
      "step: 651422 / episode: 213 / progress: Training / epsilon: 0.3985789999883358 / score: 2015.5723786726594\n",
      "step: 651771 / episode: 214 / progress: Training / epsilon: 0.39822999998834513 / score: 316.90000218153\n",
      "step: 655396 / episode: 215 / progress: Training / epsilon: 0.3946049999884421 / score: 2767.686489753425\n",
      "step: 657506 / episode: 216 / progress: Training / epsilon: 0.39249499998849857 / score: 1539.7995228171349\n",
      "step: 661338 / episode: 217 / progress: Training / epsilon: 0.3886629999886011 / score: 2549.8811340928078\n",
      "step: 665731 / episode: 218 / progress: Training / epsilon: 0.38426999998871864 / score: 1956.5689983591437\n",
      "step: 669577 / episode: 219 / progress: Training / epsilon: 0.38042399998882154 / score: 2523.345163755119\n",
      "step: 672857 / episode: 220 / progress: Training / epsilon: 0.3771439999889093 / score: 2299.931277297437\n",
      "step: 676368 / episode: 221 / progress: Training / epsilon: 0.37363299998900323 / score: 2904.794038183987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 677328 / episode: 222 / progress: Training / epsilon: 0.3726729999890289 / score: 667.5729990974069\n",
      "step: 681031 / episode: 223 / progress: Training / epsilon: 0.368969999989128 / score: 2683.8321270495653\n",
      "step: 685294 / episode: 224 / progress: Training / epsilon: 0.36470699998924205 / score: 2073.8010083585978\n",
      "step: 687082 / episode: 225 / progress: Training / epsilon: 0.3629189999892899 / score: 1305.220741033554\n",
      "step: 688652 / episode: 226 / progress: Training / epsilon: 0.3613489999893319 / score: 955.0421020537615\n",
      "step: 691829 / episode: 227 / progress: Training / epsilon: 0.3581719999894169 / score: 2083.1251241862774\n",
      "step: 695243 / episode: 228 / progress: Training / epsilon: 0.35475799998950824 / score: 3019.53120251745\n",
      "step: 698392 / episode: 229 / progress: Training / epsilon: 0.3516089999895925 / score: 2140.094640098512\n",
      "step: 701296 / episode: 230 / progress: Training / epsilon: 0.3487049999896702 / score: 2048.019129373133\n",
      "step: 704424 / episode: 231 / progress: Training / epsilon: 0.3455769999897539 / score: 1969.552109502256\n",
      "step: 708328 / episode: 232 / progress: Training / epsilon: 0.34167299998985834 / score: 2473.69019395113\n",
      "step: 712338 / episode: 233 / progress: Training / epsilon: 0.33766299998996563 / score: 2378.2805124744773\n",
      "step: 713565 / episode: 234 / progress: Training / epsilon: 0.33643599998999846 / score: 958.5426224023104\n",
      "step: 716176 / episode: 235 / progress: Training / epsilon: 0.3338249999900683 / score: 1693.7483577132225\n",
      "step: 717509 / episode: 236 / progress: Training / epsilon: 0.332491999990104 / score: 954.5789471492171\n",
      "step: 721102 / episode: 237 / progress: Training / epsilon: 0.3288989999902001 / score: 2826.005241431296\n",
      "step: 724209 / episode: 238 / progress: Training / epsilon: 0.32579199999028324 / score: 2171.6128714978695\n",
      "step: 728343 / episode: 239 / progress: Training / epsilon: 0.32165799999039385 / score: 2217.8007956668735\n",
      "step: 729325 / episode: 240 / progress: Training / epsilon: 0.3206759999904201 / score: 585.7688744440675\n",
      "step: 733096 / episode: 241 / progress: Training / epsilon: 0.316904999990521 / score: 1836.7419129237533\n",
      "step: 734455 / episode: 242 / progress: Training / epsilon: 0.3155459999905574 / score: 770.0924510508776\n",
      "step: 735101 / episode: 243 / progress: Training / epsilon: 0.31489999999057466 / score: 586.1223339736462\n",
      "step: 738966 / episode: 244 / progress: Training / epsilon: 0.3110349999906781 / score: 2541.130234517157\n",
      "step: 741781 / episode: 245 / progress: Training / epsilon: 0.3082199999907534 / score: 1247.2058451324701\n",
      "step: 745277 / episode: 246 / progress: Training / epsilon: 0.3047239999908469 / score: 2936.789731733501\n",
      "step: 747689 / episode: 247 / progress: Training / epsilon: 0.30231199999091146 / score: 1582.3739883378148\n",
      "step: 747850 / episode: 248 / progress: Training / epsilon: 0.30215099999091577 / score: 125.8478931337595\n",
      "step: 751580 / episode: 249 / progress: Training / epsilon: 0.29842099999101557 / score: 2670.513049259782\n",
      "step: 752861 / episode: 250 / progress: Training / epsilon: 0.29713999999104984 / score: 518.3546660467982\n",
      "step: 756530 / episode: 251 / progress: Training / epsilon: 0.293470999991148 / score: 2755.9412015527487\n",
      "step: 756956 / episode: 252 / progress: Training / epsilon: 0.2930449999911594 / score: 348.9131329357624\n",
      "step: 760713 / episode: 253 / progress: Training / epsilon: 0.2892879999912599 / score: 2450.363479666412\n",
      "step: 764679 / episode: 254 / progress: Training / epsilon: 0.28532199999136604 / score: 2417.302238278091\n",
      "step: 768263 / episode: 255 / progress: Training / epsilon: 0.28173799999146193 / score: 2782.860007956624\n",
      "step: 771849 / episode: 256 / progress: Training / epsilon: 0.2781519999915579 / score: 2822.981991365552\n",
      "step: 775814 / episode: 257 / progress: Training / epsilon: 0.27418699999166396 / score: 2430.8555086776614\n",
      "step: 779101 / episode: 258 / progress: Training / epsilon: 0.2708999999917519 / score: 2745.164748683572\n",
      "step: 780208 / episode: 259 / progress: Training / epsilon: 0.2697929999917815 / score: 803.377863317728\n",
      "step: 784031 / episode: 260 / progress: Training / epsilon: 0.2659699999918838 / score: 2552.104598067701\n",
      "step: 785736 / episode: 261 / progress: Training / epsilon: 0.26426499999192943 / score: 1347.5320502966642\n",
      "step: 789373 / episode: 262 / progress: Training / epsilon: 0.26062799999202674 / score: 2788.5032300800085\n",
      "step: 791788 / episode: 263 / progress: Training / epsilon: 0.25821299999209135 / score: 1188.268295660615\n",
      "step: 795759 / episode: 264 / progress: Training / epsilon: 0.2542419999921976 / score: 2406.9206448569894\n",
      "step: 799467 / episode: 265 / progress: Training / epsilon: 0.2505339999922968 / score: 2688.8766808882356\n",
      "step: 803525 / episode: 266 / progress: Training / epsilon: 0.24647599999230754 / score: 2299.786689288914\n",
      "step: 805570 / episode: 267 / progress: Training / epsilon: 0.2444309999923055 / score: 1493.1951584145427\n",
      "step: 806348 / episode: 268 / progress: Training / epsilon: 0.24365299999230472 / score: 520.0852805897593\n",
      "step: 807270 / episode: 269 / progress: Training / epsilon: 0.2427309999923038 / score: 321.3749039918184\n",
      "step: 811038 / episode: 270 / progress: Training / epsilon: 0.23896299999230003 / score: 2651.2756417766213\n",
      "step: 811860 / episode: 271 / progress: Training / epsilon: 0.2381409999922992 / score: 307.8607439249754\n",
      "step: 812620 / episode: 272 / progress: Training / epsilon: 0.23738099999229845 / score: 710.9999985694885\n",
      "step: 816631 / episode: 273 / progress: Training / epsilon: 0.23336999999229444 / score: 2392.5875017642975\n",
      "step: 818900 / episode: 274 / progress: Training / epsilon: 0.23110099999229217 / score: 1632.9044367074966\n",
      "step: 820846 / episode: 275 / progress: Training / epsilon: 0.22915499999229022 / score: 1087.69816005975\n",
      "step: 825031 / episode: 276 / progress: Training / epsilon: 0.22496999999228603 / score: 2144.7001723349094\n",
      "step: 828670 / episode: 277 / progress: Training / epsilon: 0.2213309999922824 / score: 2796.637348510325\n",
      "step: 832564 / episode: 278 / progress: Training / epsilon: 0.2174369999922785 / score: 2512.333744890988\n",
      "step: 834650 / episode: 279 / progress: Training / epsilon: 0.21535099999227642 / score: 1521.9316405653954\n",
      "step: 838218 / episode: 280 / progress: Training / epsilon: 0.21178299999227285 / score: 2859.0110111907125\n",
      "step: 842195 / episode: 281 / progress: Training / epsilon: 0.20780599999226887 / score: 2403.216710202396\n",
      "step: 842421 / episode: 282 / progress: Training / epsilon: 0.20757999999226864 / score: 202.1750002503395\n",
      "step: 844471 / episode: 283 / progress: Training / epsilon: 0.2055299999922666 / score: 1375.7775364369154\n",
      "step: 845133 / episode: 284 / progress: Training / epsilon: 0.20486799999226593 / score: 551.0317539051175\n",
      "step: 848734 / episode: 285 / progress: Training / epsilon: 0.20126699999226233 / score: 2178.9385822489858\n",
      "step: 851083 / episode: 286 / progress: Training / epsilon: 0.19891799999225998 / score: 1796.232939913869\n",
      "step: 853643 / episode: 287 / progress: Training / epsilon: 0.19635799999225742 / score: 1838.5003550574183\n",
      "step: 855971 / episode: 288 / progress: Training / epsilon: 0.1940299999922551 / score: 1330.0777314379811\n",
      "step: 857410 / episode: 289 / progress: Training / epsilon: 0.19259099999225365 / score: 1069.7277056127787\n",
      "step: 860995 / episode: 290 / progress: Training / epsilon: 0.18900599999225007 / score: 2837.3554562851787\n",
      "step: 862594 / episode: 291 / progress: Training / epsilon: 0.18740699999224847 / score: 1360.8128394931555\n",
      "step: 865438 / episode: 292 / progress: Training / epsilon: 0.18456299999224562 / score: 2059.723618209362\n",
      "step: 869329 / episode: 293 / progress: Training / epsilon: 0.18067199999224173 / score: 2484.603092573583\n",
      "step: 871860 / episode: 294 / progress: Training / epsilon: 0.1781409999922392 / score: 2280.2384228631854\n",
      "step: 872006 / episode: 295 / progress: Training / epsilon: 0.17799499999223906 / score: 129.90000075101852\n",
      "step: 872379 / episode: 296 / progress: Training / epsilon: 0.17762199999223868 / score: 247.12499545514584\n",
      "step: 875874 / episode: 297 / progress: Training / epsilon: 0.1741269999922352 / score: 2955.645587258041\n",
      "step: 876580 / episode: 298 / progress: Training / epsilon: 0.17342099999223448 / score: 628.24510397017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 880383 / episode: 299 / progress: Training / epsilon: 0.16961799999223068 / score: 2579.2629097625613\n",
      "step: 880859 / episode: 300 / progress: Training / epsilon: 0.1691419999922302 / score: 376.78755339980125\n",
      "step: 883491 / episode: 301 / progress: Training / epsilon: 0.16650999999222757 / score: 2498.6213083416224\n",
      "step: 887305 / episode: 302 / progress: Training / epsilon: 0.16269599999222376 / score: 2608.727791339159\n",
      "step: 888609 / episode: 303 / progress: Training / epsilon: 0.16139199999222245 / score: 1047.116237707436\n",
      "step: 890394 / episode: 304 / progress: Training / epsilon: 0.15960699999222067 / score: 993.8774575665593\n",
      "step: 892512 / episode: 305 / progress: Training / epsilon: 0.15748899999221855 / score: 1258.0361316800117\n",
      "step: 892997 / episode: 306 / progress: Training / epsilon: 0.15700399999221806 / score: 469.32500034570694\n",
      "step: 897075 / episode: 307 / progress: Training / epsilon: 0.15292599999221398 / score: 2274.8281207084656\n",
      "step: 900387 / episode: 308 / progress: Training / epsilon: 0.14961399999221067 / score: 2087.286687411368\n",
      "step: 904461 / episode: 309 / progress: Training / epsilon: 0.1455399999922066 / score: 2322.339828811586\n",
      "step: 905732 / episode: 310 / progress: Training / epsilon: 0.14426899999220533 / score: 966.4404692128301\n",
      "step: 908051 / episode: 311 / progress: Training / epsilon: 0.141949999992203 / score: 1885.6887209936976\n",
      "step: 912107 / episode: 312 / progress: Training / epsilon: 0.13789399999219895 / score: 2313.7178876399994\n",
      "step: 915881 / episode: 313 / progress: Training / epsilon: 0.13411999999219518 / score: 2624.336192302406\n",
      "step: 918016 / episode: 314 / progress: Training / epsilon: 0.13198499999219304 / score: 1876.6364246159792\n",
      "step: 918768 / episode: 315 / progress: Training / epsilon: 0.1312329999921923 / score: 679.3604533076286\n",
      "step: 922315 / episode: 316 / progress: Training / epsilon: 0.12768599999218874 / score: 2894.6259879097342\n",
      "step: 923302 / episode: 317 / progress: Training / epsilon: 0.12669899999218776 / score: 455.877427265048\n",
      "step: 923478 / episode: 318 / progress: Training / epsilon: 0.12652299999218758 / score: 161.4500009417534\n",
      "step: 927371 / episode: 319 / progress: Training / epsilon: 0.12262999999218369 / score: 2343.7286645397544\n",
      "step: 931481 / episode: 320 / progress: Training / epsilon: 0.11851999999217958 / score: 2266.036040082574\n",
      "step: 935303 / episode: 321 / progress: Training / epsilon: 0.11469799999217575 / score: 2580.3711087331176\n",
      "step: 939626 / episode: 322 / progress: Training / epsilon: 0.11037499999217143 / score: 2046.5585933625698\n",
      "step: 942563 / episode: 323 / progress: Training / epsilon: 0.10743799999216849 / score: 2475.3722647577524\n",
      "step: 943384 / episode: 324 / progress: Training / epsilon: 0.10661699999216767 / score: 545.2379243969917\n",
      "step: 945958 / episode: 325 / progress: Training / epsilon: 0.1040429999921651 / score: 2059.644006304443\n",
      "step: 949763 / episode: 326 / progress: Training / epsilon: 0.10023799999216129 / score: 2587.124249972403\n",
      "step: 953414 / episode: 327 / progress: Training / epsilon: 0.09999999999216105 / score: 2784.476993061602\n",
      "step: 957331 / episode: 328 / progress: Training / epsilon: 0.09999999999216105 / score: 2487.8081813007593\n",
      "step: 958603 / episode: 329 / progress: Training / epsilon: 0.09999999999216105 / score: 692.0942289680243\n",
      "step: 962356 / episode: 330 / progress: Training / epsilon: 0.09999999999216105 / score: 2647.61066544801\n",
      "step: 965932 / episode: 331 / progress: Training / epsilon: 0.09999999999216105 / score: 2870.5699831023812\n",
      "step: 969449 / episode: 332 / progress: Training / epsilon: 0.09999999999216105 / score: 2915.9318028837442\n",
      "step: 971048 / episode: 333 / progress: Training / epsilon: 0.09999999999216105 / score: 1321.243750937283\n",
      "step: 972174 / episode: 334 / progress: Training / epsilon: 0.09999999999216105 / score: 788.2299890071154\n",
      "step: 976156 / episode: 335 / progress: Training / epsilon: 0.09999999999216105 / score: 2400.947143353522\n",
      "step: 980143 / episode: 336 / progress: Training / epsilon: 0.09999999999216105 / score: 2401.8511480242014\n",
      "step: 984361 / episode: 337 / progress: Training / epsilon: 0.09999999999216105 / score: 2116.2507416680455\n",
      "step: 984485 / episode: 338 / progress: Training / epsilon: 0.09999999999216105 / score: 108.39332127571106\n",
      "step: 988101 / episode: 339 / progress: Training / epsilon: 0.09999999999216105 / score: 2793.0358338430524\n",
      "step: 990601 / episode: 340 / progress: Training / epsilon: 0.09999999999216105 / score: 2217.8869878202677\n",
      "step: 994305 / episode: 341 / progress: Training / epsilon: 0.09999999999216105 / score: 2706.932512588799\n",
      "step: 997921 / episode: 342 / progress: Training / epsilon: 0.09999999999216105 / score: 2106.875605262816\n",
      "step: 1001754 / episode: 343 / progress: Training / epsilon: 0.09999999999216105 / score: 2578.497164800763\n",
      "step: 1005044 / episode: 344 / progress: Training / epsilon: 0.09999999999216105 / score: 2731.544597171247\n",
      "step: 1005469 / episode: 345 / progress: Training / epsilon: 0.09999999999216105 / score: 399.025487780571\n",
      "step: 1005884 / episode: 346 / progress: Training / epsilon: 0.09999999999216105 / score: 394.89559122920036\n",
      "step: 1006532 / episode: 347 / progress: Training / epsilon: 0.09999999999216105 / score: 603.1512058451772\n",
      "step: 1009161 / episode: 348 / progress: Training / epsilon: 0.09999999999216105 / score: 1817.420182183385\n",
      "step: 1012739 / episode: 349 / progress: Training / epsilon: 0.09999999999216105 / score: 2847.1758409142494\n",
      "step: 1016311 / episode: 350 / progress: Training / epsilon: 0.09999999999216105 / score: 2856.862489722669\n",
      "step: 1017526 / episode: 351 / progress: Training / epsilon: 0.09999999999216105 / score: 798.7264669016004\n",
      "step: 1021923 / episode: 352 / progress: Training / epsilon: 0.09999999999216105 / score: 1930.761426255107\n",
      "step: 1022733 / episode: 353 / progress: Training / epsilon: 0.09999999999216105 / score: 457.56714747846127\n",
      "step: 1025304 / episode: 354 / progress: Training / epsilon: 0.09999999999216105 / score: 1691.6525135561824\n",
      "step: 1025835 / episode: 355 / progress: Training / epsilon: 0.09999999999216105 / score: 476.5169449299574\n",
      "step: 1029656 / episode: 356 / progress: Training / epsilon: 0.09999999999216105 / score: 1858.2913077920675\n",
      "step: 1033553 / episode: 357 / progress: Training / epsilon: 0.09999999999216105 / score: 2518.9698025658727\n",
      "step: 1037058 / episode: 358 / progress: Training / epsilon: 0.09999999999216105 / score: 2933.813046492636\n",
      "step: 1039846 / episode: 359 / progress: Training / epsilon: 0.09999999999216105 / score: 1695.7248921394348\n",
      "step: 1040284 / episode: 360 / progress: Training / epsilon: 0.09999999999216105 / score: 405.8451527506113\n",
      "step: 1042635 / episode: 361 / progress: Training / epsilon: 0.09999999999216105 / score: 2154.5308161750436\n",
      "step: 1045463 / episode: 362 / progress: Training / epsilon: 0.09999999999216105 / score: 1756.3800821751356\n",
      "step: 1049034 / episode: 363 / progress: Training / epsilon: 0.09999999999216105 / score: 2860.619913958013\n",
      "Model saved in file: ../saved_networks/2018-09-13_1_41_QR-DQN_sensor/model.ckpt\n",
      "step: 1052443 / episode: 364 / progress: Testing / epsilon: 0 / score: 3082.155981205404\n",
      "step: 1055751 / episode: 365 / progress: Testing / epsilon: 0 / score: 3211.186845496297\n",
      "step: 1059426 / episode: 366 / progress: Testing / epsilon: 0 / score: 2766.4139950200915\n",
      "step: 1062751 / episode: 367 / progress: Testing / epsilon: 0 / score: 3182.019488237798\n",
      "step: 1066384 / episode: 368 / progress: Testing / epsilon: 0 / score: 2852.9797869473696\n",
      "step: 1070287 / episode: 369 / progress: Testing / epsilon: 0 / score: 2542.3988346382976\n",
      "step: 1074185 / episode: 370 / progress: Testing / epsilon: 0 / score: 2517.5732409209013\n",
      "step: 1075572 / episode: 371 / progress: Testing / epsilon: 0 / score: 823.6066884994507\n",
      "step: 1079372 / episode: 372 / progress: Testing / epsilon: 0 / score: 2645.568254560232\n",
      "step: 1080275 / episode: 373 / progress: Testing / epsilon: 0 / score: 652.1428794264793\n",
      "step: 1083908 / episode: 374 / progress: Testing / epsilon: 0 / score: 2815.768233604729\n",
      "step: 1087390 / episode: 375 / progress: Testing / epsilon: 0 / score: 3001.190909206867\n",
      "step: 1090818 / episode: 376 / progress: Testing / epsilon: 0 / score: 3065.3141555562615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1092190 / episode: 377 / progress: Testing / epsilon: 0 / score: 1150.8639184311032\n",
      "step: 1095671 / episode: 378 / progress: Testing / epsilon: 0 / score: 2993.7196144387126\n",
      "step: 1099352 / episode: 379 / progress: Testing / epsilon: 0 / score: 1576.7600041627884\n",
      "step: 1100188 / episode: 380 / progress: Testing / epsilon: 0 / score: 832.7000004649162\n",
      "step: 1103941 / episode: 381 / progress: Testing / epsilon: 0 / score: 2669.217904523015\n",
      "step: 1106694 / episode: 382 / progress: Testing / epsilon: 0 / score: 2737.1397224366665\n",
      "step: 1110138 / episode: 383 / progress: Testing / epsilon: 0 / score: 3030.0351167470217\n",
      "step: 1112604 / episode: 384 / progress: Testing / epsilon: 0 / score: 2154.855725966394\n",
      "step: 1116357 / episode: 385 / progress: Testing / epsilon: 0 / score: 2707.9528041109443\n",
      "step: 1119978 / episode: 386 / progress: Testing / epsilon: 0 / score: 2796.0446490496397\n",
      "step: 1123456 / episode: 387 / progress: Testing / epsilon: 0 / score: 3006.8735202103853\n",
      "step: 1123858 / episode: 388 / progress: Testing / epsilon: 0 / score: 389.4029904603958\n",
      "step: 1127557 / episode: 389 / progress: Testing / epsilon: 0 / score: 2737.079786323011\n",
      "step: 1131555 / episode: 390 / progress: Testing / epsilon: 0 / score: 2435.0879134237766\n",
      "step: 1135047 / episode: 391 / progress: Testing / epsilon: 0 / score: 2987.0721451044083\n",
      "step: 1138945 / episode: 392 / progress: Testing / epsilon: 0 / score: 2508.720815256238\n",
      "step: 1142928 / episode: 393 / progress: Testing / epsilon: 0 / score: 2402.143189691007\n",
      "step: 1146437 / episode: 394 / progress: Testing / epsilon: 0 / score: 2942.680989652872\n",
      "Finished!!\n"
     ]
    }
   ],
   "source": [
    "check_plot = 0\n",
    "\n",
    "# Training & Testing\n",
    "while True:\n",
    "   \n",
    "    # Get Progress, train mode\n",
    "    progress, train_mode, Epsilon  = get_progress(step, Epsilon)\n",
    "    \n",
    "    # Select Actions \n",
    "    action, Q_value = select_action(progress, sess, state_stack, Epsilon)\n",
    "    action_in = [np.argmax(action)]\n",
    "    \n",
    "    # Get information for plotting\n",
    "    vehicle_speed  = 100 * env_info.vector_observations[0][-8]\n",
    "    num_overtake   = env_info.vector_observations[0][-7]\n",
    "    num_lanechange = env_info.vector_observations[0][-6]\n",
    "    \n",
    "    # Get information for update\n",
    "    env_info = env.step(action_in)[default_brain]\n",
    "\n",
    "    next_state_stack, state_set = resize_state(env_info, state_set) \n",
    "    reward = env_info.rewards[0]\n",
    "    terminal = env_info.local_done[0]\n",
    "    \n",
    "    if progress == 'Training':\n",
    "        # Train!! \n",
    "        train(Replay_memory, sess, step)\n",
    "\n",
    "        # Save the variables to disk.\n",
    "        if step == Num_start_training + Num_training:\n",
    "            save_path = saver.save(sess, '../saved_networks/' + date_time + '_' + algorithm + '_sensor' + \"/model.ckpt\")\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "    # If progress is finished -> close! \n",
    "    if progress == 'Finished':\n",
    "        print('Finished!!')\n",
    "        env.close()\n",
    "        break\n",
    "        \n",
    "    Replay_memory = Experience_Replay(progress, \n",
    "                                      Replay_memory, \n",
    "                                      state_stack,\n",
    "                                      action, \n",
    "                                      reward, \n",
    "                                      next_state_stack,\n",
    "                                      terminal)\n",
    "    \n",
    "    # Update information\n",
    "    step += 1\n",
    "    score += reward\n",
    "    step_per_episode += 1\n",
    "    \n",
    "    state_stack = next_state_stack\n",
    "    \n",
    "    # Update tensorboard\n",
    "    if progress != 'Observing':\n",
    "        speed_list.append(vehicle_speed)\n",
    "        \n",
    "        if episode % Num_plot_episode == 0 and check_plot == 1 and episode != 0:\n",
    "            avg_speed      = sum(speed_list) / len(speed_list)\n",
    "            avg_overtake   = sum(overtake_list) / len(overtake_list)\n",
    "            avg_lanechange = sum(lanechange_list) / len(lanechange_list)\n",
    "            \n",
    "            tensorboard_info = [avg_speed, avg_overtake, avg_lanechange]\n",
    "            for i in range(len(tensorboard_info)):\n",
    "                sess.run(update_ops[i], feed_dict = {summary_placeholders[i]: float(tensorboard_info[i])})\n",
    "            summary_str = sess.run(summary_op)\n",
    "            summary_writer.add_summary(summary_str, step)\n",
    "            score_board = 0\n",
    "            \n",
    "            speed_list = []\n",
    "            overtake_list = []\n",
    "            lanechange_list = []\n",
    "\n",
    "            check_plot = 0\n",
    "            \n",
    "    # If terminal is True\n",
    "    if terminal == True:\n",
    "        # Print informations\n",
    "        print('step: ' + str(step) + ' / '  + 'episode: ' + str(episode) + ' / ' + 'progress: ' + progress  + ' / ' + 'epsilon: ' + str(Epsilon)  +' / ' + 'score: ' + str(score))\n",
    "\n",
    "        check_plot = 1\n",
    "\n",
    "        if progress != 'Observing':\n",
    "            episode += 1\n",
    "            \n",
    "            score_board += score\n",
    "            overtake_list.append(num_overtake)\n",
    "            lanechange_list.append(num_lanechange)\n",
    "        \n",
    "            \n",
    "        score = 0\n",
    "        step_per_episode = 0\n",
    "\n",
    "        # Initialize game state\n",
    "        env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "        state_stack, state_set = state_initialization(env_info)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
