{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRL Based Self Driving Car Control (Image)\n",
    "\n",
    "## DQN\n",
    "\n",
    "This notebook is DRL code for the project 'DRL based Self Driving Car Control' <br>\n",
    "This version uses **Image data from camera** as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Q\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment path\n",
    "\n",
    "Be sure to set `env_name` to the name of the Unity environment file you want to launch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"../environment/jeju_camp\" # Name of the Unity environment to launch\n",
    "train_mode = True # Whether to run the environment in training or inference mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the environment\n",
    "`UnityEnvironment` launches and begins communication with the environment when instantiated.\n",
    "\n",
    "Environments contain _brains_ which are responsible for deciding the actions of their associated _agents_. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: Brain\n",
      "        Number of Visual Observations (per agent): 1\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 373\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 5\n",
      "        Vector Action descriptions: , , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: Brain\n",
      "        Number of Visual Observations (per agent): 1\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 373\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 5\n",
      "        Vector Action descriptions: , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_name)\n",
    "\n",
    "# Examine environment parameters\n",
    "print(str(env))\n",
    "\n",
    "# Set the default brain to work with\n",
    "default_brain = env.brain_names[0]\n",
    "brain = env.brains[default_brain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the observation and state spaces\n",
    "We can reset the environment to be provided with an initial set of observations and states for all the agents within the environment. In ML-Agents, _states_ refer to a vector of variables corresponding to relevant aspects of the environment for an agent. Likewise, _observations_ refer to a set of relevant pixel-wise visuals for an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor data (LIDAR): \n",
      "[  1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   0.9755246    0.91600198   0.86357307   0.81705666   0.77551937\n",
      "   0.73821479   0.70453942   0.67399871   0.64618438   0.62075633\n",
      "   0.59742886   0.57596022   0.5561446    0.53780544   0.52079082\n",
      "   0.50496876   0.49022466   0.47645816   0.46358114   0.45151567\n",
      "   0.44019303   0.42955208   0.41953811   0.41010255   0.40120158\n",
      "   0.39279586   0.38485005   0.37733197   0.37021253   0.36346549\n",
      "   0.35706681   0.35099453   0.34522879   0.33975118   0.33454502\n",
      "   0.32959491   0.32488668   0.32040724   0.31614468   0.31208783\n",
      "   0.30822647   0.30455115   0.30105308   0.29772413   0.29455668\n",
      "   0.29154381   0.288679     0.28595623   0.28336981   0.2809146\n",
      "   0.27858567   0.27637851   0.27428898   0.27231315   0.27044734\n",
      "   0.26868826   0.26703268   0.26547778   0.26402083   0.26265934\n",
      "   0.26139107   0.26021382   0.25912577   0.25812501   0.25721005\n",
      "   0.25637937   0.25563163   0.25496569   0.25438049   0.25387514\n",
      "   0.25344881   0.25310093   0.25283089   0.25263828   0.25252286\n",
      "   0.25248438   0.25252286   0.25263828   0.25283089   0.25310093\n",
      "   0.25344881   0.25387514   0.25438049   0.25496572   0.25563163\n",
      "   0.25637937   0.25721005   0.25812504   0.25912577   0.26021382\n",
      "   0.2613911    0.26265937   0.26402086   0.26547781   0.26703271\n",
      "   0.26868829   0.27044743   0.27231318   0.27428904   0.27637854\n",
      "   0.27858567   0.28091457   0.28336984   0.2859562    0.28867906\n",
      "   0.29154381   0.29455668   0.29772413   0.30105308   0.30455118\n",
      "   0.3082265    0.3120878    0.31614468   0.32040721   0.32488671\n",
      "   0.32959491   0.33454508   0.33975121   0.34522879   0.35099462\n",
      "   0.35706681   0.36346555   0.37021261   0.37733203   0.38485011\n",
      "   0.39279595   0.40120178   0.41010267   0.4195382    0.42955217\n",
      "   0.44019303   0.45151576   0.46358114   0.47645825   0.49022475\n",
      "   0.50496876   0.52079082   0.53780544   0.8056162    0.79863602\n",
      "   0.79201484   0.78574008   0.77979958   0.7741822    0.7688778\n",
      "   0.76387662   0.75916994   0.7547493    0.75060725   0.74673665\n",
      "   0.7431308    0.739784     0.73669058   0.73384559   0.73124427\n",
      "   0.72888267   0.72675687   0.72486359   0.7231999    0.72176319\n",
      "   0.72055119   0.71956211   0.71879435   0.71824682   0.71791863\n",
      "   0.71780932   1.           0.73828739   0.73885024   0.7396394\n",
      "   0.74065602   0.74190187   0.74337864   0.74508876   0.74703485\n",
      "   0.72526538   0.72761542   0.73020375   0.73303467   0.73611271\n",
      "   0.73944294   0.74303085   0.74688226   0.7510038    0.75540245\n",
      "   0.76008582   0.76506215   0.77034026   0.77592981   0.78184074\n",
      "   0.78808439   0.79467267   0.80161822   0.80893487   0.52898562\n",
      "   0.51291454   0.49793857   0.48395553   0.47087574   0.45862055\n",
      "   0.44711965   0.4363113    0.42613983   0.41655573   0.40751475\n",
      "   0.399611     0.38823813   0.3806538    0.3734718    0.3666653\n",
      "   0.36021024   0.35408458   0.34826803   0.34274226   0.33749029\n",
      "   0.33249652   0.32774684   0.32322803   0.31892782   0.31483531\n",
      "   0.31093997   0.30723232   0.30370349   0.30034512   0.29714981\n",
      "   0.29411048   0.29122046   0.2884737    0.28881615   0.29910675\n",
      "   0.31025571   0.32237002   0.33557519   0.35001999   0.36588031\n",
      "   0.38336843   0.40274113   0.42431211   0.44846955   0.24207902\n",
      "   0.24091013   0.2398251    0.2388223    0.25435534   0.71093136\n",
      "   0.70863533   0.7065686    0.70472795   0.70311046   0.70171368\n",
      "   0.70053536   0.69957376   0.69882733   0.698295     0.69797587\n",
      "   0.6978696    1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   0.46766621   0.39589906   0.38227844   0.36967266   0.35797733\n",
      "   0.34710175   0.33696681   0.32750422   0.3186529    0.31535536\n",
      "   0.31916118   0.32315952   0.32736021   0.33177397   0.33641231\n",
      "   0.34128767   0.34641343   0.35180423   0.35747606   0.36344635\n",
      "   0.36973414   0.37635988   0.3833462    0.39071813   0.39850292\n",
      "   0.40673083   0.418935     0.41482678   0.42437106   0.43450052\n",
      "   0.44526401   0.45671701   0.46892133   0.48194665   0.49587208\n",
      "   0.51078594   0.59662944   0.57361192   0.57813853   0.58058214\n",
      "   0.57576889   0.57120734   0.58600146   0.61122501   0.63892192\n",
      "   0.66946077   0.78772271   0.8299135    0.89621913   0.95063126\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   1.           1.           1.           1.           1.\n",
      "   0.           0.           0.           1.           0.\n",
      "   0.60000002   0.           0.           0.           0.\n",
      "   0.           0.         -10.        ]\n",
      "Image data (Front Camera): \n",
      "{}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reset the environment\n",
    "env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "\n",
    "# Examine the state space for the default brain\n",
    "print(\"Sensor data (LIDAR): \\n{}\".format(env_info.vector_observations[0]))\n",
    "\n",
    "# Examine the observation space for the default brain\n",
    "Num_obs = len(env_info.visual_observations)\n",
    "\n",
    "print(\"Image data (Front Camera): \\n{}\")\n",
    "if Num_obs > 1:\n",
    "    f, axarr = plt.subplots(1, Num_obs, figsize=(20,10))\n",
    "    for i, observation in enumerate(env_info.visual_observations):\n",
    "        if observation.shape[3] == 3:\n",
    "            axarr[i].imshow(observation[0,:,:,:])\n",
    "            axarr[i].axis('off')\n",
    "        else:\n",
    "            axarr[i].imshow(observation[0,:,:,0])\n",
    "            axarr[i].axis('off')\n",
    "else:\n",
    "    f, axarr = plt.subplots(1, Num_obs)\n",
    "    for i, observation in enumerate(env_info.visual_observations):\n",
    "        if observation.shape[3] == 3:\n",
    "            axarr.imshow(observation[0,:,:,:])\n",
    "            axarr.axis('off')\n",
    "        else:\n",
    "            axarr.imshow(observation[0,:,:,0])\n",
    "            axarr.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "algorithm = 'DQN'\n",
    "Num_action = brain.vector_action_space_size\n",
    "\n",
    "# parameter for DQN\n",
    "Num_replay_memory = 100000\n",
    "Num_start_training = 50000\n",
    "Num_training = 1000000\n",
    "Num_update = 10000\n",
    "Num_batch = 32\n",
    "Num_test = 100000\n",
    "Num_skipFrame = 4\n",
    "Num_stackFrame = 4\n",
    "Num_colorChannel = 1\n",
    "\n",
    "Epsilon = 1.0\n",
    "Final_epsilon = 0.1\n",
    "Gamma = 0.99\n",
    "Learning_rate = 0.00025\n",
    "\n",
    "# Parameters for network\n",
    "img_size = 80\n",
    "sensor_size = 360\n",
    "\n",
    "first_conv   = [8,8,Num_colorChannel * Num_stackFrame * Num_obs,32]\n",
    "second_conv  = [4,4,32,64]\n",
    "third_conv   = [3,3,64,64]\n",
    "first_dense  = [10*10*64, 512]\n",
    "second_dense = [first_dense[1], Num_action]\n",
    "\n",
    "# Path of the network model\n",
    "load_path = ''\n",
    "\n",
    "# Parameters for session\n",
    "Num_plot_episode = 5\n",
    "Num_step_save = 50000\n",
    "\n",
    "GPU_fraction = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(xavier_initializer(shape))\n",
    "\n",
    "def bias_variable(shape):\n",
    "\treturn tf.Variable(xavier_initializer(shape))\n",
    "\n",
    "# Xavier Weights initializer\n",
    "def xavier_initializer(shape):\n",
    "\tdim_sum = np.sum(shape)\n",
    "\tif len(shape) == 1:\n",
    "\t\tdim_sum += 1\n",
    "\tbound = np.sqrt(2.0 / dim_sum)\n",
    "\treturn tf.random_uniform(shape, minval=-bound, maxval=bound)\n",
    "\n",
    "# Convolution function\n",
    "def conv2d(x,w, stride):\n",
    "\treturn tf.nn.conv2d(x,w,strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "# Assign network variables to target network\n",
    "def assign_network_to_target():\n",
    "\t# Get trainable variables\n",
    "\ttrainable_variables = tf.trainable_variables()\n",
    "\t# network lstm variables\n",
    "\ttrainable_variables_network = [var for var in trainable_variables if var.name.startswith('network')]\n",
    "\n",
    "\t# target lstm variables\n",
    "\ttrainable_variables_target = [var for var in trainable_variables if var.name.startswith('target')]\n",
    "\n",
    "    # assign network variables to target network\n",
    "\tfor i in range(len(trainable_variables_network)):\n",
    "\t\tsess.run(tf.assign(trainable_variables_target[i], trainable_variables_network[i]))\n",
    "\n",
    "# Code for tensorboard\n",
    "def setup_summary():\n",
    "    episode_speed      = tf.Variable(0.)\n",
    "    episode_overtake   = tf.Variable(0.)\n",
    "    episode_lanechange = tf.Variable(0.)\n",
    "\n",
    "    tf.summary.scalar('Average_Speed/' + str(Num_plot_episode) + 'episodes', episode_speed)\n",
    "    tf.summary.scalar('Average_overtake/' + str(Num_plot_episode) + 'episodes', episode_overtake)\n",
    "    tf.summary.scalar('Average_lanechange/' + str(Num_plot_episode) + 'episodes', episode_lanechange)\n",
    "\n",
    "    summary_vars = [episode_speed, episode_overtake, episode_lanechange]\n",
    "    summary_placeholders = [tf.placeholder(tf.float32) for _ in range(len(summary_vars))]\n",
    "    update_ops = [summary_vars[i].assign(summary_placeholders[i]) for i in range(len(summary_vars))]\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    return summary_placeholders, update_ops, summary_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Input\n",
    "x_image = tf.placeholder(tf.float32, shape = [None, img_size, img_size, Num_colorChannel * Num_stackFrame * Num_obs])\n",
    "x_normalize = (x_image - (255.0/2)) / (255.0/2)\n",
    "\n",
    "with tf.variable_scope('network'):\n",
    "    # Convolution variables\n",
    "    w_conv1 = weight_variable(first_conv)\n",
    "    b_conv1 = bias_variable([first_conv[3]])\n",
    "\n",
    "    w_conv2 = weight_variable(second_conv)\n",
    "    b_conv2 = bias_variable([second_conv[3]])\n",
    "\n",
    "    w_conv3 = weight_variable(third_conv)\n",
    "    b_conv3 = bias_variable([third_conv[3]])\n",
    "\n",
    "    # Densely connect layer variables\n",
    "    w_fc1 = weight_variable(first_dense)\n",
    "    b_fc1 = bias_variable([first_dense[1]])\n",
    "\n",
    "    w_fc2 = weight_variable(second_dense)\n",
    "    b_fc2 = bias_variable([second_dense[1]])\n",
    "    \n",
    "# Network\n",
    "h_conv1 = tf.nn.relu(conv2d(x_normalize, w_conv1, 4) + b_conv1)\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, w_conv2, 2) + b_conv2)\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, w_conv3, 1) + b_conv3)\n",
    "\n",
    "h_conv3_flat = tf.reshape(h_conv3, [-1, 10 * 10 * 64])\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv3_flat, w_fc1)+b_fc1)\n",
    "output = tf.matmul(h_fc1,  w_fc2)+b_fc2\n",
    "\n",
    "with tf.variable_scope('target'):\n",
    "    # Convolution variables target\n",
    "    w_conv1_target = weight_variable(first_conv)\n",
    "    b_conv1_target = bias_variable([first_conv[3]])\n",
    "\n",
    "    w_conv2_target = weight_variable(second_conv)\n",
    "    b_conv2_target = bias_variable([second_conv[3]])\n",
    "\n",
    "    w_conv3_target = weight_variable(third_conv)\n",
    "    b_conv3_target = bias_variable([third_conv[3]])\n",
    "\n",
    "    # Densely connect layer variables target\n",
    "    w_fc1_target = weight_variable(first_dense)\n",
    "    b_fc1_target = bias_variable([first_dense[1]])\n",
    "\n",
    "    w_fc2_target = weight_variable(second_dense)\n",
    "    b_fc2_target = bias_variable([second_dense[1]])\n",
    "\n",
    "    \n",
    "# Target Network\n",
    "h_conv1_target = tf.nn.relu(conv2d(x_normalize, w_conv1_target, 4) + b_conv1_target)\n",
    "h_conv2_target = tf.nn.relu(conv2d(h_conv1_target, w_conv2_target, 2) + b_conv2_target)\n",
    "h_conv3_target = tf.nn.relu(conv2d(h_conv2_target, w_conv3_target, 1) + b_conv3_target)\n",
    "\n",
    "h_conv3_flat_target = tf.reshape(h_conv3_target, [-1, 10 * 10 * 64])\n",
    "\n",
    "h_fc1_target  = tf.nn.relu(tf.matmul(h_conv3_flat_target, w_fc1_target)+b_fc1_target)\n",
    "output_target = tf.matmul(h_fc1_target,  w_fc2_target)+b_fc2_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and Train\n",
    "action_target = tf.placeholder(tf.float32, shape = [None, Num_action])\n",
    "y_target = tf.placeholder(tf.float32, shape = [None])\n",
    "\n",
    "y_prediction = tf.reduce_sum(tf.multiply(output, action_target), reduction_indices = 1)\n",
    "Loss = tf.reduce_mean(tf.square(y_prediction - y_target))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate = Learning_rate, epsilon = 1e-02).minimize(Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize variables\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = GPU_fraction\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training or Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference? / Training?(1=Inference/2=Training): 2\n"
     ]
    }
   ],
   "source": [
    "# Load the file if the saved file exists\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# check_save = 1\n",
    "check_save = input('Inference? / Training?(1=Inference/2=Training): ')\n",
    "\n",
    "if check_save == '1':\n",
    "    # Directly start inference\n",
    "    Num_start_training = 0\n",
    "    Num_training = 0\n",
    "    \n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, load_path)\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "# date - hour - minute of training time\n",
    "date_time = str(datetime.date.today()) + '_' + str(datetime.datetime.now().hour) + '_' + str(datetime.datetime.now().minute)\n",
    "\n",
    "# Make folder for save data\n",
    "os.makedirs('../saved_networks/' + date_time + '_' + algorithm + '_image')\n",
    "\n",
    "# Summary for tensorboard\n",
    "summary_placeholders, update_ops, summary_op = setup_summary()\n",
    "summary_writer = tf.summary.FileWriter('../saved_networks/' + date_time + '_' + algorithm + '_image', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize input \n",
    "def input_initialization(env_info):\n",
    "    # Observation\n",
    "    observation_stack_obs = np.zeros([img_size, img_size, Num_colorChannel * Num_obs])\n",
    "    \n",
    "    for i in range(Num_obs):\n",
    "        observation = 255 * env_info.visual_observations[i]\n",
    "        observation = np.uint8(observation)\n",
    "        observation = np.reshape(observation, (observation.shape[1], observation.shape[2], 3))\n",
    "        observation = cv2.resize(observation, (img_size, img_size))\n",
    "\n",
    "        if Num_colorChannel == 1:\n",
    "            observation = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY)\n",
    "            observation = np.reshape(observation, (img_size, img_size))\n",
    "\n",
    "        if Num_colorChannel == 3:\n",
    "            observation_stack_obs[:,:, Num_colorChannel * i: Num_colorChannel * (i+1)] = observation\n",
    "        else:\n",
    "            observation_stack_obs[:,:, i] = observation\n",
    "\n",
    "    observation_set = []\n",
    "      \n",
    "    for i in range(Num_skipFrame * Num_stackFrame):\n",
    "        observation_set.append(observation_stack_obs)\n",
    "        \n",
    "    # Stack the frame according to the number of skipping and stacking frames using observation set\n",
    "    observation_stack = np.zeros((img_size, img_size, Num_colorChannel * Num_stackFrame * Num_obs))\n",
    "    \n",
    "    for stack_frame in range(Num_stackFrame):\n",
    "        observation_stack[:,:,Num_obs * stack_frame: Num_obs * (stack_frame+1)] = observation_set[-1 - (Num_skipFrame * stack_frame)]\n",
    "    \n",
    "    observation_stack = np.uint8(observation_stack)\n",
    "    \n",
    "    return observation_stack, observation_set\n",
    "\n",
    "# Resize input information \n",
    "def resize_input(env_info, observation_set):\n",
    "    # Stack observation according to the number of observations\n",
    "    observation_stack_obs = np.zeros([img_size, img_size, Num_colorChannel * Num_obs])\n",
    "\n",
    "    for i in range(Num_obs):\n",
    "        observation = 255 * env_info.visual_observations[i]\n",
    "        observation = np.uint8(observation)\n",
    "        observation = np.reshape(observation, (observation.shape[1], observation.shape[2], 3))\n",
    "        observation = cv2.resize(observation, (img_size, img_size))\n",
    "        \n",
    "        if Num_colorChannel == 1:\n",
    "            observation = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY)\n",
    "            observation = np.reshape(observation, (img_size, img_size))\n",
    "\n",
    "        if Num_colorChannel == 3:\n",
    "            observation_stack_obs[:,:, Num_colorChannel * i: Num_colorChannel * (i+1)] = observation\n",
    "        else:\n",
    "            observation_stack_obs[:,:,i] = observation\n",
    "    \n",
    "    # Add observations to the observation_set\n",
    "    observation_set.append(observation_stack_obs)\n",
    "    \n",
    "    # Stack the frame according to the number of skipping and stacking frames using observation set\n",
    "    observation_stack = np.zeros((img_size, img_size, Num_colorChannel * Num_stackFrame * Num_obs))\n",
    "\n",
    "    for stack_frame in range(Num_stackFrame):\n",
    "        observation_stack[:,:,Num_obs * stack_frame: Num_obs * (stack_frame+1)] = observation_set[-1 - (Num_skipFrame * stack_frame)]\n",
    "\n",
    "    del observation_set[0]\n",
    "    \n",
    "    observation_stack = np.uint8(observation_stack)\n",
    "        \n",
    "    return observation_stack, observation_set\n",
    "\n",
    "# Get progress according to the number of steps\n",
    "def get_progress(step, Epsilon):\n",
    "    if step <= Num_start_training:\n",
    "        # Observation\n",
    "        progress = 'Observing'\n",
    "        train_mode = True\n",
    "        Epsilon = 1\n",
    "    elif step <= Num_start_training + Num_training:\n",
    "        # Training\n",
    "        progress = 'Training'\n",
    "        train_mode = True\n",
    "        \n",
    "        # Decrease the epsilon value\n",
    "        if Epsilon > Final_epsilon:\n",
    "            Epsilon -= 1.0/Num_training\n",
    "    elif step < Num_start_training + Num_training + Num_test:\n",
    "        # Testing\n",
    "        progress = 'Testing'\n",
    "        train_mode = False\n",
    "        Epsilon = 0\n",
    "    else:\n",
    "        # Finished\n",
    "        progress = 'Finished'\n",
    "        train_mode = False\n",
    "        Epsilon = 0\n",
    "        \n",
    "    return progress, train_mode, Epsilon \n",
    "\n",
    "# Select action according to the progress of training\n",
    "def select_action(progress, sess, observation_stack, Epsilon):\n",
    "    if progress == \"Observing\":\n",
    "        # Random action \n",
    "        Q_value = 0\n",
    "        action = np.zeros([Num_action])\n",
    "        action[random.randint(0, Num_action - 1)] = 1.0\n",
    "    elif progress == \"Training\":\n",
    "        # if random value(0-1) is smaller than Epsilon, action is random. \n",
    "        # Otherwise, action is the one which has the max Q value\n",
    "        if random.random() < Epsilon:\n",
    "            Q_value = 0\n",
    "            action = np.zeros([Num_action])\n",
    "            action[random.randint(0, Num_action - 1)] = 1\n",
    "        else:\n",
    "            Q_value = output.eval(feed_dict={x_image: [observation_stack]})\n",
    "            action = np.zeros([Num_action])\n",
    "            action[np.argmax(Q_value)] = 1\n",
    "    else:\n",
    "        # Max Q action \n",
    "        Q_value = output.eval(feed_dict={x_image: [observation_stack]})\n",
    "        action = np.zeros([Num_action])\n",
    "        action[np.argmax(Q_value)] = 1\n",
    "        \n",
    "    return action, Q_value\n",
    "\n",
    "def train(Replay_memory, sess, step):\n",
    "    # Select minibatch\n",
    "    minibatch =  random.sample(Replay_memory, Num_batch)\n",
    "\n",
    "    # Save the each batch data\n",
    "    observation_batch      = [batch[0] for batch in minibatch]\n",
    "    action_batch           = [batch[1] for batch in minibatch]\n",
    "    reward_batch           = [batch[2] for batch in minibatch]\n",
    "    observation_next_batch = [batch[3] for batch in minibatch]\n",
    "    terminal_batch \t       = [batch[4] for batch in minibatch]\n",
    "\n",
    "    # Update target network according to the Num_update value\n",
    "    if step % Num_update == 0:\n",
    "        assign_network_to_target()\n",
    "    \n",
    "    # Get y_target\n",
    "    y_batch = []\n",
    "    Q_target = output_target.eval(feed_dict = {x_image: observation_next_batch})\n",
    "\n",
    "    # Get target values\n",
    "    for i in range(len(minibatch)):\n",
    "        if terminal_batch[i] == True:\n",
    "            y_batch.append(reward_batch[i])\n",
    "        else:\n",
    "            y_batch.append(reward_batch[i] + Gamma * np.max(Q_target[i]))\n",
    "\n",
    "    _, loss = sess.run([train_step, Loss], feed_dict = {action_target: action_batch, \n",
    "                                                        y_target: y_batch, \n",
    "                                                        x_image: observation_batch})\n",
    "\n",
    "# Experience Replay \n",
    "def Experience_Replay(progress, Replay_memory, obs_stack, action, reward, next_obs_stack, terminal):\n",
    "    if progress != 'Testing':\n",
    "        # If length of replay memeory is more than the setting value then remove the first one\n",
    "        if len(Replay_memory) > Num_replay_memory:\n",
    "            del Replay_memory[0]\n",
    "\n",
    "        # Save experience to the Replay memory\n",
    "        Replay_memory.append([obs_stack, action, reward, next_obs_stack, terminal])\n",
    "    else:\n",
    "        # Empty the replay memory if testing\n",
    "        Replay_memory = []\n",
    "    \n",
    "    return Replay_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "Replay_memory = []\n",
    "\n",
    "step = 1\n",
    "score = 0\n",
    "score_board = 0\n",
    "\n",
    "episode = 0\n",
    "step_per_episode = 0\n",
    "\n",
    "speed_list = []\n",
    "overtake_list = []\n",
    "lanechange_list = []\n",
    "\n",
    "train_mode = True\n",
    "env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "\n",
    "observation_stack, observation_set = input_initialization(env_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 4907 / episode: 0 / progress: Observing / epsilon: 1 / score: 990.0109669491649\n",
      "step: 9608 / episode: 0 / progress: Observing / epsilon: 1 / score: 1145.9446742013097\n",
      "step: 14289 / episode: 0 / progress: Observing / epsilon: 1 / score: 1098.9082214608788\n",
      "step: 18879 / episode: 0 / progress: Observing / epsilon: 1 / score: 1289.8384655714035\n",
      "step: 23504 / episode: 0 / progress: Observing / epsilon: 1 / score: 1173.5075749009848\n",
      "step: 27162 / episode: 0 / progress: Observing / epsilon: 1 / score: 830.3676781132817\n",
      "step: 31849 / episode: 0 / progress: Observing / epsilon: 1 / score: 1138.4457378536463\n",
      "step: 36666 / episode: 0 / progress: Observing / epsilon: 1 / score: 1078.5131687819958\n",
      "step: 41264 / episode: 0 / progress: Observing / epsilon: 1 / score: 1298.6421379745007\n",
      "step: 46016 / episode: 0 / progress: Observing / epsilon: 1 / score: 1302.6423847004771\n",
      "step: 50494 / episode: 0 / progress: Training / epsilon: 0.9995069999999858 / score: 1412.0681159570813\n",
      "step: 54793 / episode: 1 / progress: Training / epsilon: 0.9952079999998622 / score: 1337.5509244427085\n",
      "step: 57164 / episode: 2 / progress: Training / epsilon: 0.992836999999794 / score: 576.6981246694922\n",
      "step: 59979 / episode: 3 / progress: Training / epsilon: 0.9900219999997131 / score: 719.4306420907378\n",
      "step: 63670 / episode: 4 / progress: Training / epsilon: 0.9863309999996069 / score: 965.284912340343\n",
      "step: 68241 / episode: 5 / progress: Training / epsilon: 0.9817599999994755 / score: 1375.0552557632327\n",
      "step: 72663 / episode: 6 / progress: Training / epsilon: 0.9773379999993483 / score: 1531.1236518025398\n",
      "step: 77155 / episode: 7 / progress: Training / epsilon: 0.9728459999992192 / score: 1547.9949707910419\n",
      "step: 79366 / episode: 8 / progress: Training / epsilon: 0.9706349999991556 / score: 605.3182966336608\n",
      "step: 83987 / episode: 9 / progress: Training / epsilon: 0.9660139999990227 / score: 1350.987076856196\n",
      "step: 88556 / episode: 10 / progress: Training / epsilon: 0.9614449999988913 / score: 1445.823119148612\n",
      "step: 89695 / episode: 11 / progress: Training / epsilon: 0.9603059999988586 / score: 312.9327535107732\n",
      "step: 93407 / episode: 12 / progress: Training / epsilon: 0.9565939999987518 / score: 1622.2475553378463\n",
      "step: 95391 / episode: 13 / progress: Training / epsilon: 0.9546099999986948 / score: 801.6212739944458\n",
      "step: 100170 / episode: 14 / progress: Training / epsilon: 0.9498309999985574 / score: 1225.3614144995809\n",
      "step: 104570 / episode: 15 / progress: Training / epsilon: 0.9454309999984308 / score: 1477.5151657164097\n",
      "step: 109094 / episode: 16 / progress: Training / epsilon: 0.9409069999983007 / score: 1427.2225086987019\n",
      "step: 113620 / episode: 17 / progress: Training / epsilon: 0.9363809999981706 / score: 1492.0147866532207\n",
      "step: 118216 / episode: 18 / progress: Training / epsilon: 0.9317849999980384 / score: 1348.2530648335814\n",
      "step: 120277 / episode: 19 / progress: Training / epsilon: 0.9297239999979792 / score: 755.58574526757\n",
      "step: 121135 / episode: 20 / progress: Training / epsilon: 0.9288659999979545 / score: 77.33127807825804\n",
      "step: 123821 / episode: 21 / progress: Training / epsilon: 0.9261799999978773 / score: 1113.4537579640746\n",
      "step: 128029 / episode: 22 / progress: Training / epsilon: 0.9219719999977563 / score: 1512.2280392199755\n",
      "step: 132580 / episode: 23 / progress: Training / epsilon: 0.9174209999976254 / score: 1550.972560055554\n",
      "step: 136772 / episode: 24 / progress: Training / epsilon: 0.9132289999975048 / score: 1941.7732369452715\n",
      "step: 141367 / episode: 25 / progress: Training / epsilon: 0.9086339999973727 / score: 1396.2367947548628\n",
      "step: 145489 / episode: 26 / progress: Training / epsilon: 0.9045119999972542 / score: 1847.2721278890967\n",
      "step: 149815 / episode: 27 / progress: Training / epsilon: 0.9001859999971298 / score: 1663.3053870648146\n",
      "step: 153593 / episode: 28 / progress: Training / epsilon: 0.8964079999970211 / score: 1804.8495889753103\n",
      "step: 154325 / episode: 29 / progress: Training / epsilon: 0.8956759999970001 / score: 404.0317936092615\n",
      "step: 158410 / episode: 30 / progress: Training / epsilon: 0.8915909999968826 / score: 1903.8437441140413\n",
      "step: 162563 / episode: 31 / progress: Training / epsilon: 0.8874379999967632 / score: 1848.2606365829706\n",
      "step: 166678 / episode: 32 / progress: Training / epsilon: 0.8833229999966449 / score: 1932.613076530397\n",
      "step: 171331 / episode: 33 / progress: Training / epsilon: 0.8786699999965111 / score: 1237.446305833757\n",
      "step: 175784 / episode: 34 / progress: Training / epsilon: 0.874216999996383 / score: 1728.799573585391\n",
      "step: 180762 / episode: 35 / progress: Training / epsilon: 0.8692389999962399 / score: 1110.171966738999\n",
      "step: 183501 / episode: 36 / progress: Training / epsilon: 0.8664999999961611 / score: 1490.5929508134723\n",
      "step: 187495 / episode: 37 / progress: Training / epsilon: 0.8625059999960463 / score: 2145.8846000880003\n",
      "step: 191491 / episode: 38 / progress: Training / epsilon: 0.8585099999959314 / score: 2107.8296980708838\n",
      "step: 191794 / episode: 39 / progress: Training / epsilon: 0.8582069999959226 / score: 158.83385986089706\n",
      "step: 194719 / episode: 40 / progress: Training / epsilon: 0.8552819999958385 / score: 1239.8741145953536\n",
      "step: 198704 / episode: 41 / progress: Training / epsilon: 0.851296999995724 / score: 2161.004738725722\n",
      "step: 201956 / episode: 42 / progress: Training / epsilon: 0.8480449999956304 / score: 1435.762511625886\n",
      "step: 203757 / episode: 43 / progress: Training / epsilon: 0.8462439999955786 / score: 727.9708569720387\n",
      "step: 207770 / episode: 44 / progress: Training / epsilon: 0.8422309999954632 / score: 2153.212774068117\n",
      "step: 209834 / episode: 45 / progress: Training / epsilon: 0.8401669999954039 / score: 825.988288000226\n",
      "step: 214043 / episode: 46 / progress: Training / epsilon: 0.8359579999952829 / score: 1839.5635432302952\n",
      "step: 218160 / episode: 47 / progress: Training / epsilon: 0.8318409999951645 / score: 1973.184846252203\n",
      "step: 219420 / episode: 48 / progress: Training / epsilon: 0.8305809999951282 / score: 714.4346248656511\n",
      "step: 223544 / episode: 49 / progress: Training / epsilon: 0.8264569999950097 / score: 1994.2871408462524\n",
      "step: 224608 / episode: 50 / progress: Training / epsilon: 0.8253929999949791 / score: 673.194807857275\n",
      "step: 229007 / episode: 51 / progress: Training / epsilon: 0.8209939999948526 / score: 1779.126026056707\n",
      "step: 231067 / episode: 52 / progress: Training / epsilon: 0.8189339999947933 / score: 1091.233738847077\n",
      "step: 234708 / episode: 53 / progress: Training / epsilon: 0.8152929999946886 / score: 1883.5609190315008\n",
      "step: 238594 / episode: 54 / progress: Training / epsilon: 0.8114069999945769 / score: 2235.9822065383196\n",
      "step: 242718 / episode: 55 / progress: Training / epsilon: 0.8072829999944583 / score: 2034.9969246312976\n",
      "step: 247032 / episode: 56 / progress: Training / epsilon: 0.8029689999943342 / score: 1833.1965060457587\n",
      "step: 247862 / episode: 57 / progress: Training / epsilon: 0.8021389999943104 / score: 551.8927555009723\n",
      "step: 249693 / episode: 58 / progress: Training / epsilon: 0.8003079999942577 / score: 569.3166455253959\n",
      "step: 249937 / episode: 59 / progress: Training / epsilon: 0.8000639999942507 / score: 156.23818770051003\n",
      "step: 254148 / episode: 60 / progress: Training / epsilon: 0.7958529999941296 / score: 1949.8274522051215\n",
      "step: 258062 / episode: 61 / progress: Training / epsilon: 0.7919389999940171 / score: 2212.176565527916\n",
      "step: 262288 / episode: 62 / progress: Training / epsilon: 0.7877129999938955 / score: 1940.5082930997014\n",
      "step: 265797 / episode: 63 / progress: Training / epsilon: 0.7842039999937946 / score: 2007.4866428375244\n",
      "step: 270038 / episode: 64 / progress: Training / epsilon: 0.7799629999936727 / score: 1899.8281952887774\n",
      "step: 274158 / episode: 65 / progress: Training / epsilon: 0.7758429999935542 / score: 2048.7249597534537\n",
      "step: 275011 / episode: 66 / progress: Training / epsilon: 0.7749899999935297 / score: 454.24230882525444\n",
      "step: 275939 / episode: 67 / progress: Training / epsilon: 0.774061999993503 / score: 596.1966855078936\n",
      "step: 277898 / episode: 68 / progress: Training / epsilon: 0.7721029999934467 / score: 1416.246089592576\n",
      "step: 281735 / episode: 69 / progress: Training / epsilon: 0.7682659999933363 / score: 2263.6049839630723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 285886 / episode: 70 / progress: Training / epsilon: 0.764114999993217 / score: 2045.6945526376367\n",
      "step: 288208 / episode: 71 / progress: Training / epsilon: 0.7617929999931502 / score: 1581.7964196652174\n",
      "step: 288720 / episode: 72 / progress: Training / epsilon: 0.7612809999931355 / score: 295.07415606081486\n",
      "step: 289973 / episode: 73 / progress: Training / epsilon: 0.7600279999930994 / score: 701.5243927389383\n",
      "step: 293689 / episode: 74 / progress: Training / epsilon: 0.7563119999929926 / score: 2061.787966236472\n",
      "step: 295238 / episode: 75 / progress: Training / epsilon: 0.754762999992948 / score: 1078.467016518116\n",
      "step: 298620 / episode: 76 / progress: Training / epsilon: 0.7513809999928508 / score: 1486.1338623389602\n",
      "step: 298767 / episode: 77 / progress: Training / epsilon: 0.7512339999928466 / score: 93.39466515183449\n",
      "step: 302493 / episode: 78 / progress: Training / epsilon: 0.7475079999927394 / score: 2421.6355665028095\n",
      "step: 306961 / episode: 79 / progress: Training / epsilon: 0.7430399999926109 / score: 1772.2887676656246\n",
      "step: 311087 / episode: 80 / progress: Training / epsilon: 0.7389139999924923 / score: 2101.165181286633\n",
      "step: 314866 / episode: 81 / progress: Training / epsilon: 0.7351349999923836 / score: 2425.9458858072758\n",
      "step: 318849 / episode: 82 / progress: Training / epsilon: 0.7311519999922691 / score: 2220.5120045617223\n",
      "step: 323010 / episode: 83 / progress: Training / epsilon: 0.7269909999921494 / score: 1844.3230076432228\n",
      "step: 325719 / episode: 84 / progress: Training / epsilon: 0.7242819999920715 / score: 1334.260343581438\n",
      "step: 329450 / episode: 85 / progress: Training / epsilon: 0.7205509999919643 / score: 2451.577089764178\n",
      "step: 330259 / episode: 86 / progress: Training / epsilon: 0.719741999991941 / score: 318.8451548740268\n",
      "step: 332725 / episode: 87 / progress: Training / epsilon: 0.7172759999918701 / score: 583.902730435133\n",
      "step: 333514 / episode: 88 / progress: Training / epsilon: 0.7164869999918474 / score: 331.55218122154474\n",
      "step: 337635 / episode: 89 / progress: Training / epsilon: 0.7123659999917289 / score: 2118.7142946347594\n",
      "step: 339116 / episode: 90 / progress: Training / epsilon: 0.7108849999916863 / score: 615.0299041569233\n",
      "step: 342352 / episode: 91 / progress: Training / epsilon: 0.7076489999915933 / score: 1759.7868868261576\n",
      "step: 346161 / episode: 92 / progress: Training / epsilon: 0.7038399999914837 / score: 2327.0998648926616\n",
      "step: 349994 / episode: 93 / progress: Training / epsilon: 0.7000069999913735 / score: 2338.544283479452\n",
      "step: 354267 / episode: 94 / progress: Training / epsilon: 0.6957339999912506 / score: 1937.9007506296039\n",
      "step: 358154 / episode: 95 / progress: Training / epsilon: 0.6918469999911389 / score: 2253.813156351447\n",
      "step: 359118 / episode: 96 / progress: Training / epsilon: 0.6908829999911111 / score: 728.8894156515598\n",
      "step: 359640 / episode: 97 / progress: Training / epsilon: 0.6903609999910961 / score: 282.4579280167818\n",
      "step: 363556 / episode: 98 / progress: Training / epsilon: 0.6864449999909835 / score: 2264.219527184963\n",
      "step: 368122 / episode: 99 / progress: Training / epsilon: 0.6818789999908522 / score: 1601.3322034403682\n",
      "step: 372621 / episode: 100 / progress: Training / epsilon: 0.6773799999907228 / score: 1736.632388368249\n",
      "step: 376398 / episode: 101 / progress: Training / epsilon: 0.6736029999906142 / score: 2388.172208867967\n",
      "step: 378360 / episode: 102 / progress: Training / epsilon: 0.6716409999905578 / score: 1310.346551887691\n",
      "step: 382192 / episode: 103 / progress: Training / epsilon: 0.6678089999904476 / score: 2310.7050899863243\n",
      "step: 385919 / episode: 104 / progress: Training / epsilon: 0.6640819999903405 / score: 2452.580177359283\n",
      "step: 389691 / episode: 105 / progress: Training / epsilon: 0.660309999990232 / score: 2380.4535108208656\n",
      "step: 391079 / episode: 106 / progress: Training / epsilon: 0.6589219999901921 / score: 824.0753052830696\n",
      "step: 394979 / episode: 107 / progress: Training / epsilon: 0.6550219999900799 / score: 2238.7602454051375\n",
      "step: 399385 / episode: 108 / progress: Training / epsilon: 0.6506159999899532 / score: 1783.5235244333744\n",
      "step: 399589 / episode: 109 / progress: Training / epsilon: 0.6504119999899474 / score: 140.20789915323257\n",
      "step: 399779 / episode: 110 / progress: Training / epsilon: 0.6502219999899419 / score: 120.73131434619427\n",
      "step: 404024 / episode: 111 / progress: Training / epsilon: 0.6459769999898198 / score: 2037.2621644586325\n",
      "step: 408520 / episode: 112 / progress: Training / epsilon: 0.6414809999896905 / score: 1739.0535493418574\n",
      "step: 412376 / episode: 113 / progress: Training / epsilon: 0.6376249999895797 / score: 2330.6404277160764\n",
      "step: 414007 / episode: 114 / progress: Training / epsilon: 0.6359939999895328 / score: 1084.8373196870089\n",
      "step: 417724 / episode: 115 / progress: Training / epsilon: 0.6322769999894259 / score: 2472.99293217808\n",
      "step: 421672 / episode: 116 / progress: Training / epsilon: 0.6283289999893124 / score: 2223.2776254713535\n",
      "step: 425788 / episode: 117 / progress: Training / epsilon: 0.624212999989194 / score: 2148.7641183808446\n",
      "step: 426700 / episode: 118 / progress: Training / epsilon: 0.6233009999891678 / score: 597.5110010802746\n",
      "step: 430340 / episode: 119 / progress: Training / epsilon: 0.6196609999890631 / score: 2560.2070352733135\n",
      "step: 434356 / episode: 120 / progress: Training / epsilon: 0.6156449999889476 / score: 2219.3693212494254\n",
      "step: 438075 / episode: 121 / progress: Training / epsilon: 0.6119259999888407 / score: 2493.6739392727613\n",
      "step: 438226 / episode: 122 / progress: Training / epsilon: 0.6117749999888363 / score: 108.43320196866989\n",
      "step: 442474 / episode: 123 / progress: Training / epsilon: 0.6075269999887142 / score: 1994.995329029858\n",
      "step: 446401 / episode: 124 / progress: Training / epsilon: 0.6035999999886013 / score: 2303.244564861059\n",
      "step: 450439 / episode: 125 / progress: Training / epsilon: 0.5995619999884851 / score: 2181.6208979412913\n",
      "step: 453992 / episode: 126 / progress: Training / epsilon: 0.596008999988383 / score: 2349.2432749420404\n",
      "step: 458455 / episode: 127 / progress: Training / epsilon: 0.5915459999882546 / score: 1734.2068802565336\n",
      "step: 462164 / episode: 128 / progress: Training / epsilon: 0.587836999988148 / score: 2525.8806011527777\n",
      "step: 466096 / episode: 129 / progress: Training / epsilon: 0.5839049999880349 / score: 1889.7120617628098\n",
      "step: 470630 / episode: 130 / progress: Training / epsilon: 0.5793709999879045 / score: 1722.4379444494843\n",
      "step: 475197 / episode: 131 / progress: Training / epsilon: 0.5748039999877732 / score: 1663.9422708824277\n",
      "step: 477309 / episode: 132 / progress: Training / epsilon: 0.5726919999877125 / score: 1395.9273641780019\n",
      "step: 477877 / episode: 133 / progress: Training / epsilon: 0.5721239999876961 / score: 399.17625273019075\n",
      "step: 481635 / episode: 134 / progress: Training / epsilon: 0.5683659999875881 / score: 2488.0111488625407\n",
      "step: 484370 / episode: 135 / progress: Training / epsilon: 0.5656309999875094 / score: 1966.902891434729\n",
      "step: 488603 / episode: 136 / progress: Training / epsilon: 0.5613979999873877 / score: 1969.5975209772587\n",
      "step: 490656 / episode: 137 / progress: Training / epsilon: 0.5593449999873287 / score: 1619.3677909895778\n",
      "step: 494353 / episode: 138 / progress: Training / epsilon: 0.5556479999872224 / score: 2563.528896793723\n",
      "step: 495360 / episode: 139 / progress: Training / epsilon: 0.5546409999871934 / score: 487.0179069414735\n",
      "step: 495781 / episode: 140 / progress: Training / epsilon: 0.5542199999871813 / score: 304.0949065387249\n",
      "step: 497390 / episode: 141 / progress: Training / epsilon: 0.552610999987135 / score: 754.1972624883056\n",
      "step: 501019 / episode: 142 / progress: Training / epsilon: 0.5489819999870307 / score: 2568.423972822726\n",
      "step: 504874 / episode: 143 / progress: Training / epsilon: 0.5451269999869198 / score: 2430.190426617861\n",
      "step: 509061 / episode: 144 / progress: Training / epsilon: 0.5409399999867994 / score: 1992.8326683044434\n",
      "step: 512963 / episode: 145 / progress: Training / epsilon: 0.5370379999866872 / score: 2327.0178369507194\n",
      "step: 516683 / episode: 146 / progress: Training / epsilon: 0.5333179999865802 / score: 2512.7537644430995\n",
      "step: 520387 / episode: 147 / progress: Training / epsilon: 0.5296139999864737 / score: 2558.661764636636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 520856 / episode: 148 / progress: Training / epsilon: 0.5291449999864603 / score: 381.46809646487236\n",
      "step: 524870 / episode: 149 / progress: Training / epsilon: 0.5251309999863448 / score: 2226.180378526449\n",
      "step: 528760 / episode: 150 / progress: Training / epsilon: 0.521240999986233 / score: 2351.795525588095\n",
      "step: 532611 / episode: 151 / progress: Training / epsilon: 0.5173899999861222 / score: 2394.949269115925\n",
      "step: 533937 / episode: 152 / progress: Training / epsilon: 0.5160639999860841 / score: 978.9600025713444\n",
      "step: 537680 / episode: 153 / progress: Training / epsilon: 0.5123209999859765 / score: 2503.7959981635213\n",
      "step: 541315 / episode: 154 / progress: Training / epsilon: 0.5086859999858719 / score: 2553.1942759007215\n",
      "step: 541669 / episode: 155 / progress: Training / epsilon: 0.5083319999858618 / score: 294.12499636411667\n",
      "step: 545475 / episode: 156 / progress: Training / epsilon: 0.5045259999857523 / score: 2422.5647248849273\n",
      "step: 545834 / episode: 157 / progress: Training / epsilon: 0.504166999985742 / score: 257.7933880239725\n",
      "step: 549519 / episode: 158 / progress: Training / epsilon: 0.500481999985636 / score: 2562.885047905147\n",
      "step: 553627 / episode: 159 / progress: Training / epsilon: 0.49637399998571924 / score: 2118.247764185071\n",
      "step: 557679 / episode: 160 / progress: Training / epsilon: 0.49232199998582765 / score: 2167.4919278025627\n",
      "step: 561521 / episode: 161 / progress: Training / epsilon: 0.48847999998593045 / score: 2455.7417453974485\n",
      "step: 565131 / episode: 162 / progress: Training / epsilon: 0.48486999998602703 / score: 2708.498783029616\n",
      "step: 568959 / episode: 163 / progress: Training / epsilon: 0.48104199998612945 / score: 2407.45673019439\n",
      "step: 573064 / episode: 164 / progress: Training / epsilon: 0.4769369999862393 / score: 2116.8531809449196\n",
      "step: 574981 / episode: 165 / progress: Training / epsilon: 0.4750199999862906 / score: 1665.049354404211\n",
      "step: 578573 / episode: 166 / progress: Training / epsilon: 0.4714279999863867 / score: 2677.815313577652\n",
      "step: 578851 / episode: 167 / progress: Training / epsilon: 0.4711499999863941 / score: 221.3749961256981\n",
      "step: 581036 / episode: 168 / progress: Training / epsilon: 0.4689649999864526 / score: 1603.1721456423402\n",
      "step: 581420 / episode: 169 / progress: Training / epsilon: 0.46858099998646285 / score: 293.4354475289583\n",
      "step: 585304 / episode: 170 / progress: Training / epsilon: 0.46469699998656677 / score: 2338.98928591609\n",
      "step: 588461 / episode: 171 / progress: Training / epsilon: 0.46153999998665124 / score: 1691.4936938211322\n",
      "step: 592777 / episode: 172 / progress: Training / epsilon: 0.4572239999867667 / score: 1945.1573352143168\n",
      "step: 593316 / episode: 173 / progress: Training / epsilon: 0.45668499998678114 / score: 436.4045749306679\n",
      "step: 597354 / episode: 174 / progress: Training / epsilon: 0.4526469999868892 / score: 2243.794932693243\n",
      "step: 598116 / episode: 175 / progress: Training / epsilon: 0.45188499998690956 / score: 521.3816549405456\n",
      "step: 602073 / episode: 176 / progress: Training / epsilon: 0.44792799998701543 / score: 2251.900842271745\n",
      "step: 604184 / episode: 177 / progress: Training / epsilon: 0.4458169999870719 / score: 1664.236017897725\n",
      "step: 605614 / episode: 178 / progress: Training / epsilon: 0.4443869999871102 / score: 1060.476980380714\n",
      "step: 606299 / episode: 179 / progress: Training / epsilon: 0.4437019999871285 / score: 548.8592659235001\n",
      "step: 610222 / episode: 180 / progress: Training / epsilon: 0.43977899998723347 / score: 2330.763098537922\n",
      "step: 614407 / episode: 181 / progress: Training / epsilon: 0.43559399998734544 / score: 2091.860934756696\n",
      "step: 618214 / episode: 182 / progress: Training / epsilon: 0.4317869999874473 / score: 2451.1298378631473\n",
      "step: 620462 / episode: 183 / progress: Training / epsilon: 0.42953899998750744 / score: 1399.7142499908805\n",
      "step: 621071 / episode: 184 / progress: Training / epsilon: 0.42892999998752374 / score: 444.97740887850523\n",
      "step: 625007 / episode: 185 / progress: Training / epsilon: 0.42499399998762905 / score: 2338.8276962935925\n",
      "step: 628645 / episode: 186 / progress: Training / epsilon: 0.4213559999877264 / score: 2607.2373890653253\n",
      "step: 632214 / episode: 187 / progress: Training / epsilon: 0.41778699998782187 / score: 2696.7048907876015\n",
      "step: 636331 / episode: 188 / progress: Training / epsilon: 0.413669999987932 / score: 2131.3098339140415\n",
      "step: 638419 / episode: 189 / progress: Training / epsilon: 0.4115819999879879 / score: 965.7244569137692\n",
      "step: 641296 / episode: 190 / progress: Training / epsilon: 0.40870499998806487 / score: 1776.5945354923606\n",
      "step: 645366 / episode: 191 / progress: Training / epsilon: 0.40463499998817376 / score: 2170.8162500187755\n",
      "step: 648957 / episode: 192 / progress: Training / epsilon: 0.40104399998826984 / score: 2701.8522530198097\n",
      "step: 652278 / episode: 193 / progress: Training / epsilon: 0.3977229999883587 / score: 2109.587929941714\n",
      "step: 657129 / episode: 194 / progress: Training / epsilon: 0.3928719999884885 / score: 1400.6605968400836\n",
      "step: 660893 / episode: 195 / progress: Training / epsilon: 0.3891079999885892 / score: 2308.090896502137\n",
      "step: 664846 / episode: 196 / progress: Training / epsilon: 0.38515499998869496 / score: 2329.5638122707605\n",
      "step: 668976 / episode: 197 / progress: Training / epsilon: 0.38102499998880546 / score: 2130.863348506391\n",
      "step: 670932 / episode: 198 / progress: Training / epsilon: 0.3790689999888578 / score: 1336.6436209008098\n",
      "step: 673352 / episode: 199 / progress: Training / epsilon: 0.37664899998892254 / score: 1959.1678175255656\n",
      "step: 677099 / episode: 200 / progress: Training / epsilon: 0.3729019999890228 / score: 2561.333796955645\n",
      "step: 678239 / episode: 201 / progress: Training / epsilon: 0.3717619999890533 / score: 874.5195340961218\n",
      "step: 682024 / episode: 202 / progress: Training / epsilon: 0.36797699998915456 / score: 2490.367225460708\n",
      "step: 683938 / episode: 203 / progress: Training / epsilon: 0.3660629999892058 / score: 942.7933492437005\n",
      "step: 687794 / episode: 204 / progress: Training / epsilon: 0.36220699998930894 / score: 2430.0129816681147\n",
      "step: 690703 / episode: 205 / progress: Training / epsilon: 0.3592979999893868 / score: 2276.1937791481614\n",
      "step: 693178 / episode: 206 / progress: Training / epsilon: 0.356822999989453 / score: 1770.957107707858\n",
      "step: 694295 / episode: 207 / progress: Training / epsilon: 0.3557059999894829 / score: 582.7953174337745\n",
      "step: 695833 / episode: 208 / progress: Training / epsilon: 0.35416799998952403 / score: 952.1559763029218\n",
      "step: 699693 / episode: 209 / progress: Training / epsilon: 0.3503079999896273 / score: 2380.64289162308\n",
      "step: 703476 / episode: 210 / progress: Training / epsilon: 0.3465249999897285 / score: 2480.1839932128787\n",
      "step: 706982 / episode: 211 / progress: Training / epsilon: 0.3430189999898223 / score: 2812.8966657221317\n",
      "step: 711010 / episode: 212 / progress: Training / epsilon: 0.3389909999899301 / score: 2207.794123761356\n",
      "step: 713390 / episode: 213 / progress: Training / epsilon: 0.3366109999899938 / score: 1642.9185691326857\n",
      "step: 717213 / episode: 214 / progress: Training / epsilon: 0.33278799999009606 / score: 2457.172353245318\n",
      "step: 720942 / episode: 215 / progress: Training / epsilon: 0.32905899999019583 / score: 2575.4331022799015\n",
      "step: 724697 / episode: 216 / progress: Training / epsilon: 0.3253039999902963 / score: 2510.066750586033\n",
      "step: 728269 / episode: 217 / progress: Training / epsilon: 0.32173199999039187 / score: 2713.1514771431684\n",
      "step: 730815 / episode: 218 / progress: Training / epsilon: 0.31918599999046 / score: 1686.3295243233442\n",
      "step: 732523 / episode: 219 / progress: Training / epsilon: 0.3174779999905057 / score: 1477.122295498848\n",
      "step: 736757 / episode: 220 / progress: Training / epsilon: 0.31324399999061897 / score: 2008.6378637328744\n",
      "step: 739476 / episode: 221 / progress: Training / epsilon: 0.3105249999906917 / score: 1652.545482866466\n",
      "step: 742323 / episode: 222 / progress: Training / epsilon: 0.3076779999907679 / score: 2363.727668374777\n",
      "step: 742888 / episode: 223 / progress: Training / epsilon: 0.307112999990783 / score: 469.98524732887745\n",
      "step: 746898 / episode: 224 / progress: Training / epsilon: 0.3031029999908903 / score: 2261.088507436216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 751143 / episode: 225 / progress: Training / epsilon: 0.2988579999910039 / score: 2037.313054524362\n",
      "step: 754682 / episode: 226 / progress: Training / epsilon: 0.29531899999109856 / score: 2765.2912191674113\n",
      "step: 758570 / episode: 227 / progress: Training / epsilon: 0.2914309999912026 / score: 2406.816291898489\n",
      "step: 762435 / episode: 228 / progress: Training / epsilon: 0.287565999991306 / score: 2407.9417783766985\n",
      "step: 765398 / episode: 229 / progress: Training / epsilon: 0.2846029999913853 / score: 2165.5944825708866\n",
      "step: 769307 / episode: 230 / progress: Training / epsilon: 0.28069399999148986 / score: 2371.9341083541512\n",
      "step: 773221 / episode: 231 / progress: Training / epsilon: 0.2767799999915946 / score: 2365.342923782766\n",
      "step: 775186 / episode: 232 / progress: Training / epsilon: 0.27481499999164716 / score: 1560.3569694906473\n",
      "step: 779048 / episode: 233 / progress: Training / epsilon: 0.2709529999917505 / score: 2399.4600171893835\n",
      "step: 779529 / episode: 234 / progress: Training / epsilon: 0.27047199999176336 / score: 408.92704832553864\n",
      "step: 781496 / episode: 235 / progress: Training / epsilon: 0.268504999991816 / score: 1274.6942786499858\n",
      "step: 784746 / episode: 236 / progress: Training / epsilon: 0.26525499999190294 / score: 2148.433455877006\n",
      "step: 785479 / episode: 237 / progress: Training / epsilon: 0.26452199999192255 / score: 628.0064834058285\n",
      "step: 789055 / episode: 238 / progress: Training / epsilon: 0.26094599999201823 / score: 2182.788549296558\n",
      "step: 793392 / episode: 239 / progress: Training / epsilon: 0.25660899999213427 / score: 1957.0899773910642\n",
      "step: 797457 / episode: 240 / progress: Training / epsilon: 0.25254399999224303 / score: 2206.3715094923973\n",
      "step: 801532 / episode: 241 / progress: Training / epsilon: 0.24846899999230954 / score: 2195.8018284142017\n",
      "step: 802715 / episode: 242 / progress: Training / epsilon: 0.24728599999230835 / score: 743.3873618543148\n",
      "step: 804900 / episode: 243 / progress: Training / epsilon: 0.24510099999230617 / score: 1864.7691605389118\n",
      "step: 808727 / episode: 244 / progress: Training / epsilon: 0.24127399999230234 / score: 2470.980659171939\n",
      "step: 811196 / episode: 245 / progress: Training / epsilon: 0.23880499999229987 / score: 1884.1791978031397\n",
      "step: 814673 / episode: 246 / progress: Training / epsilon: 0.2353279999922964 / score: 2556.481296814978\n",
      "step: 818577 / episode: 247 / progress: Training / epsilon: 0.2314239999922925 / score: 2402.1181595027447\n",
      "step: 822351 / episode: 248 / progress: Training / epsilon: 0.22764999999228872 / score: 2515.9335284754634\n",
      "step: 822755 / episode: 249 / progress: Training / epsilon: 0.2272459999922883 / score: 337.7335487306118\n",
      "step: 824575 / episode: 250 / progress: Training / epsilon: 0.2254259999922865 / score: 1242.2707668319345\n",
      "step: 825770 / episode: 251 / progress: Training / epsilon: 0.2242309999922853 / score: 877.8572601675987\n",
      "step: 829637 / episode: 252 / progress: Training / epsilon: 0.22036399999228143 / score: 2440.017199188471\n",
      "step: 829967 / episode: 253 / progress: Training / epsilon: 0.2200339999922811 / score: 245.4522122144699\n",
      "step: 833741 / episode: 254 / progress: Training / epsilon: 0.21625999999227732 / score: 1996.1789258494973\n",
      "step: 838002 / episode: 255 / progress: Training / epsilon: 0.21199899999227306 / score: 2008.2238845527172\n",
      "step: 839495 / episode: 256 / progress: Training / epsilon: 0.21050599999227157 / score: 788.4127546995878\n",
      "step: 841450 / episode: 257 / progress: Training / epsilon: 0.20855099999226961 / score: 1622.1317264959216\n",
      "step: 844875 / episode: 258 / progress: Training / epsilon: 0.2051259999922662 / score: 1580.0442882999778\n",
      "step: 847621 / episode: 259 / progress: Training / epsilon: 0.20237999999226344 / score: 1996.762045815587\n",
      "step: 851014 / episode: 260 / progress: Training / epsilon: 0.19898699999226005 / score: 2840.858450420201\n",
      "step: 855314 / episode: 261 / progress: Training / epsilon: 0.19468699999225575 / score: 2001.9114665612578\n",
      "step: 858942 / episode: 262 / progress: Training / epsilon: 0.19105899999225212 / score: 2664.587957419455\n",
      "step: 863274 / episode: 263 / progress: Training / epsilon: 0.1867269999922478 / score: 2004.8111263215542\n",
      "step: 866832 / episode: 264 / progress: Training / epsilon: 0.18316899999224423 / score: 2786.623263821006\n",
      "step: 871214 / episode: 265 / progress: Training / epsilon: 0.17878699999223985 / score: 1908.674888126552\n",
      "step: 875322 / episode: 266 / progress: Training / epsilon: 0.17467899999223574 / score: 2197.5902860686183\n",
      "step: 878993 / episode: 267 / progress: Training / epsilon: 0.17100799999223207 / score: 2668.323885373771\n",
      "step: 879548 / episode: 268 / progress: Training / epsilon: 0.1704529999922315 / score: 347.22840620577335\n",
      "step: 883679 / episode: 269 / progress: Training / epsilon: 0.16632199999222738 / score: 2156.744718402624\n",
      "step: 887421 / episode: 270 / progress: Training / epsilon: 0.16257999999222364 / score: 2585.7697588279843\n",
      "step: 890507 / episode: 271 / progress: Training / epsilon: 0.15949399999222055 / score: 2063.1851714476943\n",
      "step: 894335 / episode: 272 / progress: Training / epsilon: 0.15566599999221672 / score: 2501.401947721839\n",
      "step: 897928 / episode: 273 / progress: Training / epsilon: 0.15207299999221313 / score: 2733.845409594476\n",
      "step: 900468 / episode: 274 / progress: Training / epsilon: 0.1495329999922106 / score: 1631.1017348021269\n"
     ]
    }
   ],
   "source": [
    "check_plot = 0\n",
    "\n",
    "# Training & Testing\n",
    "while True:\n",
    "   \n",
    "    # Get Progress, train mode\n",
    "    progress, train_mode, Epsilon  = get_progress(step, Epsilon)\n",
    "    \n",
    "    # Select Actions \n",
    "    action, Q_value = select_action(progress, sess, observation_stack, Epsilon)\n",
    "    action_in = [np.argmax(action)]\n",
    "    \n",
    "    # Get information for plotting\n",
    "    vehicle_speed  = 100 * env_info.vector_observations[0][-8]\n",
    "    num_overtake   = env_info.vector_observations[0][-7]\n",
    "    num_lanechange = env_info.vector_observations[0][-6]\n",
    "    \n",
    "    # Get information for update\n",
    "    env_info = env.step(action_in)[default_brain]\n",
    "\n",
    "    next_observation_stack, observation_set = resize_input(env_info, observation_set) \n",
    "    reward = env_info.rewards[0]\n",
    "    terminal = env_info.local_done[0]\n",
    "    \n",
    "    if progress == 'Training':\n",
    "        # Train!! \n",
    "        train(Replay_memory, sess, step)\n",
    "\n",
    "        # Save the variables to disk.\n",
    "        if step == Num_start_training + Num_training:\n",
    "            save_path = saver.save(sess, '../saved_networks/' + date_time + '_' + algorithm + '_image' + \"/model.ckpt\")\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "    # If progress is finished -> close! \n",
    "    if progress == 'Finished':\n",
    "        print('Finished!!')\n",
    "        env.close()\n",
    "        break\n",
    "        \n",
    "    Replay_memory = Experience_Replay(progress, \n",
    "                                      Replay_memory, \n",
    "                                      observation_stack,\n",
    "                                      action, \n",
    "                                      reward, \n",
    "                                      next_observation_stack,\n",
    "                                      terminal)\n",
    "    \n",
    "    # Update information\n",
    "    step += 1\n",
    "    score += reward\n",
    "    step_per_episode += 1\n",
    "    \n",
    "    observation_stack = next_observation_stack\n",
    "    \n",
    "    # Update tensorboard\n",
    "    if progress != 'Observing':\n",
    "        speed_list.append(vehicle_speed)\n",
    "        \n",
    "        if episode % Num_plot_episode == 0 and check_plot == 1 and episode != 0:\n",
    "            avg_speed      = sum(speed_list) / len(speed_list)\n",
    "            avg_overtake   = sum(overtake_list) / len(overtake_list)\n",
    "            avg_lanechange = sum(lanechange_list) / len(lanechange_list)\n",
    "            \n",
    "            tensorboard_info = [avg_speed, avg_overtake, avg_lanechange]\n",
    "            for i in range(len(tensorboard_info)):\n",
    "                sess.run(update_ops[i], feed_dict = {summary_placeholders[i]: float(tensorboard_info[i])})\n",
    "            summary_str = sess.run(summary_op)\n",
    "            summary_writer.add_summary(summary_str, step)\n",
    "            score_board = 0\n",
    "            \n",
    "            speed_list = []\n",
    "            overtake_list = []\n",
    "            lanechange_list = []\n",
    "\n",
    "            check_plot = 0\n",
    "            \n",
    "    # If terminal is True\n",
    "    if terminal == True:\n",
    "        # Print informations\n",
    "        print('step: ' + str(step) + ' / '  + 'episode: ' + str(episode) + ' / ' + 'progress: ' + progress  + ' / ' + 'epsilon: ' + str(Epsilon)  +' / ' + 'score: ' + str(score))\n",
    "\n",
    "        check_plot = 1\n",
    "\n",
    "        if progress != 'Observing':\n",
    "            episode += 1\n",
    "            \n",
    "            score_board += score\n",
    "            overtake_list.append(num_overtake)\n",
    "            lanechange_list.append(num_lanechange)\n",
    "        \n",
    "            \n",
    "        score = 0\n",
    "        step_per_episode = 0\n",
    "\n",
    "        # Initialize game state\n",
    "        env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "        observation_stack, observation_set = input_initialization(env_info)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
